{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a28a4aff-6905-42a8-ae17-c007acbc8077",
   "metadata": {},
   "source": [
    "# Démonstration du modèle TensorRT en temps réel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8da7f2-ebf7-4ccf-9a39-83c0fd5aeff2",
   "metadata": {},
   "source": [
    "### Classe de capture et de traitement du flux vidéo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ea398c-dd29-45e7-b02a-b8eac796c436",
   "metadata": {},
   "source": [
    "La classe suivante est hérité des Threading et prend en charge :\n",
    "\n",
    "- L'initialisation de la caméra et du moteur TensorRT\n",
    "- La capture du flux vidéo et son traitement avec le modèle, exécuté dans le programme principal du thread"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65d78c4-6703-49b7-bdc7-20e8a801e8bf",
   "metadata": {},
   "source": [
    "**Pour réinitialiser la caméra :** sudo systemctl restart nvargus-daemon.service "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c15bbf1f-982d-451f-931e-cbe57d16739d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo /home/jetson/notebook/ResetCam.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8803d279-450b-4f1e-9b21-33f2265974e5",
   "metadata": {},
   "source": [
    "**Affiche les caméras disponnibles :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "085f4723-b2c2-4a1c-896b-2ec924521f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vi-output, imx219 7-0010 (platform:54080000.vi:0):\n",
      "\t/dev/video0\n",
      "\n",
      "USB 2.0 Camera (usb-70090000.xusb-2.1):\n",
      "\t/dev/video1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!v4l2-ctl --list-devices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c8cbaa-da61-4e90-8458-33f5138c6a17",
   "metadata": {},
   "source": [
    "**Affiche les informations sur la caméra USB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d344ca0-a045-4b27-90c3-0c80997af016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Driver Info (not using libv4l2):\n",
      "\tDriver name   : uvcvideo\n",
      "\tCard type     : USB 2.0 Camera\n",
      "\tBus info      : usb-70090000.xusb-2.1\n",
      "\tDriver version: 4.9.255\n",
      "\tCapabilities  : 0x84200001\n",
      "\t\tVideo Capture\n",
      "\t\tStreaming\n",
      "\t\tExtended Pix Format\n",
      "\t\tDevice Capabilities\n",
      "\tDevice Caps   : 0x04200001\n",
      "\t\tVideo Capture\n",
      "\t\tStreaming\n",
      "\t\tExtended Pix Format\n",
      "Priority: 2\n",
      "Video input : 0 (Camera 1: ok)\n",
      "Format Video Capture:\n",
      "\tWidth/Height      : 1280/960\n",
      "\tPixel Format      : 'YUYV'\n",
      "\tField             : None\n",
      "\tBytes per Line    : 2560\n",
      "\tSize Image        : 2457600\n",
      "\tColorspace        : sRGB\n",
      "\tTransfer Function : Default (maps to sRGB)\n",
      "\tYCbCr/HSV Encoding: Default (maps to ITU-R 601)\n",
      "\tQuantization      : Default (maps to Limited Range)\n",
      "\tFlags             : \n",
      "Crop Capability Video Capture:\n",
      "\tBounds      : Left 0, Top 0, Width 1280, Height 960\n",
      "\tDefault     : Left 0, Top 0, Width 1280, Height 960\n",
      "\tPixel Aspect: 1/1\n",
      "Selection: crop_default, Left 0, Top 0, Width 1280, Height 960\n",
      "Selection: crop_bounds, Left 0, Top 0, Width 1280, Height 960\n",
      "Streaming Parameters Video Capture:\n",
      "\tCapabilities     : timeperframe\n",
      "\tFrames per second: 30.000 (30/1)\n",
      "\tRead buffers     : 0\n",
      "                     brightness 0x00980900 (int)    : min=-255 max=255 step=1 default=0 value=0\n",
      "                       contrast 0x00980901 (int)    : min=0 max=30 step=1 default=16 value=16\n",
      "                     saturation 0x00980902 (int)    : min=0 max=127 step=1 default=36 value=36\n",
      "                            hue 0x00980903 (int)    : min=-16000 max=16000 step=1 default=0 value=0\n",
      " white_balance_temperature_auto 0x0098090c (bool)   : default=1 value=1\n",
      "                          gamma 0x00980910 (int)    : min=20 max=250 step=10 default=100 value=100\n",
      "           power_line_frequency 0x00980918 (menu)   : min=0 max=2 default=1 value=1\n",
      "      white_balance_temperature 0x0098091a (int)    : min=2500 max=7000 step=1 default=5000 value=5000 flags=inactive\n",
      "                      sharpness 0x0098091b (int)    : min=0 max=15 step=1 default=4 value=4\n",
      "         backlight_compensation 0x0098091c (int)    : min=0 max=2 step=1 default=1 value=1\n"
     ]
    }
   ],
   "source": [
    "!v4l2-ctl --all -d /dev/video1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2f26b1-6c0c-45d7-a00e-ba604bac1eb9",
   "metadata": {},
   "source": [
    "**Affiche les informations sur les résolutions disponnibles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4966d309-c95b-456a-9333-9b014f16dd5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ioctl: VIDIOC_ENUM_FMT\n",
      "\tIndex       : 0\n",
      "\tType        : Video Capture\n",
      "\tPixel Format: 'YUYV'\n",
      "\tName        : YUYV 4:2:2\n",
      "\t\tSize: Discrete 640x480\n",
      "\t\t\tInterval: Discrete 0.033s (30.000 fps)\n",
      "\t\tSize: Discrete 352x288\n",
      "\t\t\tInterval: Discrete 0.033s (30.000 fps)\n",
      "\t\tSize: Discrete 320x240\n",
      "\t\t\tInterval: Discrete 0.033s (30.000 fps)\n",
      "\t\tSize: Discrete 160x120\n",
      "\t\t\tInterval: Discrete 0.033s (30.000 fps)\n",
      "\t\tSize: Discrete 1280x720\n",
      "\t\t\tInterval: Discrete 0.033s (30.000 fps)\n",
      "\t\tSize: Discrete 1280x960\n",
      "\t\t\tInterval: Discrete 0.033s (30.000 fps)\n",
      "\n",
      "\tIndex       : 1\n",
      "\tType        : Video Capture\n",
      "\tPixel Format: 'MJPG' (compressed)\n",
      "\tName        : Motion-JPEG\n",
      "\t\tSize: Discrete 640x480\n",
      "\t\t\tInterval: Discrete 0.033s (30.000 fps)\n",
      "\t\tSize: Discrete 352x288\n",
      "\t\t\tInterval: Discrete 0.033s (30.000 fps)\n",
      "\t\tSize: Discrete 320x240\n",
      "\t\t\tInterval: Discrete 0.033s (30.000 fps)\n",
      "\t\tSize: Discrete 160x120\n",
      "\t\t\tInterval: Discrete 0.033s (30.000 fps)\n",
      "\t\tSize: Discrete 1280x720\n",
      "\t\t\tInterval: Discrete 0.033s (30.000 fps)\n",
      "\t\tSize: Discrete 1280x960\n",
      "\t\t\tInterval: Discrete 0.033s (30.000 fps)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!v4l2-ctl --list-formats-ext -d /dev/video1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "414c601c-13b0-461c-9f6e-14425b489cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt\n",
    "import numpy as np\n",
    "import pycuda.driver as cuda\n",
    "import threading\n",
    "import ctypes\n",
    "import time\n",
    "import traitlets\n",
    "import atexit\n",
    "import cv2\n",
    "\n",
    "class TRTInference(threading.Thread):\n",
    "    def __init__(self,repertoire_engine, widget_image,type_camera,capture_device,capture_width,capture_height,display_width,display_height,fps,flip=0):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.widget_image = widget_image\n",
    "        self.type_camera = type_camera\n",
    "        self.capture_device = capture_device\n",
    "        self.capture_width = capture_width\n",
    "        self.capture_height = capture_height\n",
    "        self.display_width = display_width\n",
    "        self.display_height = display_height\n",
    "        self.fps = fps\n",
    "        self.flip = flip\n",
    "        self.camera_on = False\n",
    "\n",
    "        # Initialisation des variables de la caméra\n",
    "        self._running = False\n",
    "        self.image_pour_widget = np.zeros((capture_width, capture_height, 3), dtype=np.int32)\n",
    "        self.image = np.zeros((256, 256, 3), dtype=np.int32)\n",
    "        \n",
    "        if self.type_camera.find(\"CSI\")>=0:\n",
    "            self.cap = cv2.VideoCapture(self._gstreamer_pipeline_CSI(),cv2.CAP_GSTREAMER)\n",
    "        else:\n",
    "            self.cap = cv2.VideoCapture(self._gstreamer_pipeline_USB(),cv2.CAP_GSTREAMER)\n",
    "        if self.cap.isOpened():\n",
    "            print(\"Caméra initialisée\")\n",
    "        else:\n",
    "            print(\"Erreur d'ouverture du flux vidéo\")\n",
    "        atexit.register(self.cap.release)\n",
    "\n",
    "        # Initialisation du runtime TensorRT\n",
    "        #self.logger = MyLogger()\n",
    "        self.logger = trt.Logger(trt.Logger.INFO)\n",
    "        trt.init_libnvinfer_plugins(self.logger, namespace=\"\")\n",
    "        self.runtime = trt.Runtime(self.logger)\n",
    "        \n",
    "        # Chargement du moteur\n",
    "        print(\"Chargement du moteur...\")\n",
    "        with open(repertoire_engine, \"rb\") as f:\n",
    "            self.engine = self.runtime.deserialize_cuda_engine(f.read())\n",
    "        \n",
    "        self.context = self.engine.create_execution_context()\n",
    " \n",
    "        #Initialisation du context Cuda et du contexte TensorRT \n",
    "        cuda.init()\n",
    "        self.cudactx = cuda.Device(0).retain_primary_context()\n",
    "        self.cudactx.push()\n",
    "        self.context.debug_sync = True\n",
    "        \n",
    "        # Réservation de la mémoire pour l'entrée\n",
    "        print(\"Allocation mémoire...\")\n",
    "        size_input = trt.volume(self.engine.get_binding_shape(0))*self.engine.max_batch_size\n",
    "        self.input_host_mem = cuda.pagelocked_empty(size_input, np.int32)\n",
    "        self.input_device_mem = cuda.mem_alloc(self.input_host_mem.nbytes)\n",
    "       \n",
    "        # Réservation de la mémoire pour les sorties\n",
    "        self.output_device_mem = [];\n",
    "        format_sorties = [];\n",
    "        types_sorties = [];\n",
    "\n",
    "        for i in range(self.engine.num_bindings):\n",
    "            if not self.engine.binding_is_input(i):\n",
    "                size_output = trt.volume(self.engine.get_binding_shape(i))*self.engine.max_batch_size\n",
    "                output_hm = cuda.pagelocked_empty(size_output,trt.nptype(self.engine.get_binding_dtype(i)))\n",
    "                self.output_device_mem.append(cuda.mem_alloc(output_hm.nbytes))\n",
    "                format_sorties.append(self.engine.get_binding_shape(i))\n",
    "                types_sorties.append(trt.nptype(self.engine.get_binding_dtype(i)))\n",
    "\n",
    "        # Récupère les adresses en GPU des buffers entrées / sorties\n",
    "        binding_entree = int(self.input_device_mem)\n",
    "        binding_sorties = []\n",
    "\n",
    "        for output_ in self.output_device_mem:\n",
    "            binding_sorties.append(int(output_))\n",
    "        self.bindings = [binding_entree, binding_sorties[0]]\n",
    "\n",
    "        # Allocation de la mémoire hote pour les sorties\n",
    "        self.output_host_mem = []\n",
    "        for i in range(len(self.output_device_mem)):\n",
    "            self.output_host_mem.append(np.zeros(format_sorties[i],types_sorties[i]))\n",
    "        \n",
    "        # Input tensor\n",
    "        self.image = np.zeros((256, 256, 3), dtype=trt.nptype(self.engine.get_binding_dtype(0)))\n",
    "        self.image = self.image.astype(np.int32)       \n",
    "        self.cudactx.pop()\n",
    "\n",
    "    # Inférence\n",
    "    def Calcul(self):\n",
    "        # Copie de l'image dans le tenseur d'entrée\n",
    "        x = self.image.astype(np.int32)\n",
    "        x = np.expand_dims(x,axis=0)                    # (1,256,256,3)\n",
    "        np.copyto(self.input_host_mem,x.ravel())\n",
    "        \n",
    "        # Transfert de l'entrée vers le GPU\n",
    "        self.cudactx = cuda.Device(0).retain_primary_context()\n",
    "        self.cudactx.push()\n",
    "        cuda.memcpy_htod(self.input_device_mem, self.input_host_mem)\n",
    "        \n",
    "        # Appel du modèle\n",
    "        self.context.execute_v2(bindings=self.bindings)\n",
    "        \n",
    "        # Récupération des sorties\n",
    "        for i in range(len(self.output_host_mem)):\n",
    "            cuda.memcpy_dtoh(self.output_host_mem[i], self.output_device_mem[i])\n",
    "        self.cudactx.pop()\n",
    "\n",
    "    # Lecture d'une frame\n",
    "    def capture_image(self):\n",
    "        re, image = self.cap.read()\n",
    "        if re:\n",
    "            return image\n",
    "        else:\n",
    "            return self.widget_image.value\n",
    "        \n",
    "    def run(self):\n",
    "        while True:\n",
    "            if self.camera_on is True:\n",
    "                self.image_pour_widget = self.capture_image()\n",
    "                self.image = cv2.resize(self.image_pour_widget,(int(256),int(256)))              \n",
    "                self.Calcul()\n",
    "                \n",
    "                # Récupère les coordonnees XY\n",
    "                coordonneesXY = self.output_host_mem[0][0][0][:][:]\n",
    "                \n",
    "                # Place les points\n",
    "                width, height = (self.capture_width,self.capture_height)\n",
    "                for point in coordonneesXY:\n",
    "                    pt_Y = point[0]\n",
    "                    pt_X = point[1]\n",
    "                \n",
    "                    # Calcule la position du point sur l'image\n",
    "                    pt_image_X = pt_X * width\n",
    "                    pt_image_Y = pt_Y * height\n",
    "\n",
    "                    # Affiche le point sur l'image\n",
    "                    self.image_pour_widget = cv2.circle(self.image_pour_widget, (int(pt_image_X),int(pt_image_Y)), radius=5, color=(0, 0, 255), thickness=-1)\n",
    "                \n",
    "                self.widget_image.value = bgr8_to_jpeg(self.image_pour_widget)\n",
    "                time.sleep(0.001)\n",
    "\n",
    "    # Définition du pipeline pour la caméra CSI\n",
    "    def _gstreamer_pipeline_CSI(self):\n",
    "        return(\"nvarguscamerasrc sensor-id=%d ! \"\n",
    "                \"video/x-raw(memory:NVMM),\"\n",
    "                \"width=(int)%d,height=(int)%d,\"\n",
    "                \"format=(string)NV12, framerate=(fraction)%d/1 ! \"\n",
    "                \"nvvidconv flip-method=%d ! \"\n",
    "                \"video/x-raw,\"\n",
    "                \"width=(int)%d,height=(int)%d,\"\n",
    "                \"format=(string)BGRx ! videoconvert ! \"\n",
    "                \"video/x-raw, format=(string)BGR ! \"\n",
    "                \"appsink drop=true\"\n",
    "        %(self.capture_device,self.capture_width,self.capture_height,self.fps,self.flip, self.display_width,self.display_height))\n",
    "\n",
    "    # Définition du pipeline pour la USB\n",
    "    def _gstreamer_pipeline_USB(self):\n",
    "        return(\"v4l2src device=/dev/video%d ! \"\n",
    "               \"video/x-raw, width=(int)%d, height=(int)%d, framerate=(fraction)%d/1 ! \"\n",
    "               \"videoflip method=%d ! \"\n",
    "               \"videoconvert ! \"\n",
    "               \"video/x-raw, format=(string)BGR ! appsink drop=true\"\n",
    "        %(self.capture_device,self.capture_width,self.capture_height,self.fps,self.flip))            \n",
    "\n",
    "    # Routine pour arrêter le Thread\n",
    "    def raise_exception(self):\n",
    "        for id, thread in threading._active.items():\n",
    "            if thread is self:\n",
    "                thread_id = id\n",
    "        res = ctypes.pythonapi.PyThreadState_SetAsyncExc(thread_id,ctypes.py_object(SystemExit))\n",
    "        if res > 1:\n",
    "            ctypes.pythonapi.PyThreadState_SetAsyncExc(thread_id, 0)\n",
    "            print('Exception raise failure')\n",
    "\n",
    "    def destroy(self):\n",
    "        self.cudactx.detach()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def20f89-5cf1-4ab4-aa0a-747eda87b77f",
   "metadata": {},
   "source": [
    "### Interface de visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "770e6db1-a140-4507-832e-c666b5198af2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "612e27adc0c54b4aa75fc9b95de2b874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Image(value=b'', format='jpeg', height='768', width='1024'),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets.widgets as widgets\n",
    "import traitlets\n",
    "from IPython.display import display\n",
    "from jetbot import bgr8_to_jpeg\n",
    "\n",
    "# Création de l'interface\n",
    "image_widget = widgets.Image(format='jpeg', width=1024, height=768)\n",
    "\n",
    "# Affichage de l'interface\n",
    "display(widgets.VBox([image_widget]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10a0eee4-db1e-4537-987a-e1a0fdaaffeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caméra initialisée\n",
      "Chargement du moteur...\n",
      "Allocation mémoire...\n"
     ]
    }
   ],
   "source": [
    "trt_inference_wrapper = TRTInference(repertoire_engine=\"model_jetson.engine\",\n",
    "                        widget_image=image_widget,\n",
    "                        type_camera=\"USB\",capture_device=1,\n",
    "                        capture_width=1280,capture_height=960,\n",
    "                        display_width=1280,display_height=960,\n",
    "                        fps=30,flip=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ff8b348-25db-4fac-b7ec-ad4b0869b4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trt_inference_wrapper.start()\n",
    "trt_inference_wrapper.camera_on = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9548e1a-45ec-4990-8891-b49644b1ba64",
   "metadata": {},
   "source": [
    "### Arrêt de la caméra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e96724-f54c-475b-bd7a-e2653708aedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "trt_inference_wrapper.camera_on = False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
