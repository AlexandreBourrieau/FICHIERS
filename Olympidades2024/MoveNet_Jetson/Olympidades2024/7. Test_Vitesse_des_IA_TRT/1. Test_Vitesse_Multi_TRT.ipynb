{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QTPqwCC_wpuB"
   },
   "source": [
    "# Test de rapidité du modèle utilisé avec TensorRT\n",
    "\n",
    "Dans ce notebook, nous allons tester la rapidité du modèle TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "HS0yU5HBwCXU"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from tensorflow import keras\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QqDwwwm5wsCM"
   },
   "source": [
    "### Chargement du moteur de l'IA n°1 : Détection des coordonnées des articulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "7W2L6Xh1wE2V"
   },
   "outputs": [],
   "source": [
    "import tensorrt as trt\n",
    "\n",
    "# Construction de la class du logger\n",
    "class MyLogger(trt.ILogger):\n",
    "    def __init__(self):\n",
    "        trt.ILogger.__init__(self)\n",
    "\n",
    "    def log(self, severity, msg):\n",
    "        print(\"%s : %s\" %(severity,msg))\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uy3ibZCWwfOU",
    "outputId": "da1bd6a9-b99d-4d7d-b1d4-36d669ee4261"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Severity.INFO : [MemUsageChange] Init CUDA: CPU +225, GPU +0, now: CPU 320, GPU 2762 (MiB)\n",
      "Severity.VERBOSE : Registered plugin creator - ::BatchTilePlugin_TRT version 1\n",
      "Severity.VERBOSE : Registered plugin creator - ::BatchedNMS_TRT version 1\n",
      "Severity.VERBOSE : Registered plugin creator - ::BatchedNMSDynamic_TRT version 1\n",
      "Severity.VERBOSE : Registered plugin creator - ::CoordConvAC version 1\n",
      "Severity.VERBOSE : Registered plugin creator - ::CropAndResize version 1\n",
      "Severity.VERBOSE : Registered plugin creator - ::CropAndResizeDynamic version 1\n",
      "Severity.VERBOSE : Registered plugin creator - ::DecodeBbox3DPlugin version 1\n",
      "Severity.VERBOSE : Registered plugin creator - ::DetectionLayer_TRT version 1\n",
      "Severity.VERBOSE : Registered plugin creator - ::EfficientNMS_TRT version 1\n",
      "Severity.VERBOSE : Registered plugin creator - ::EfficientNMS_ONNX_TRT version 1\n",
      "Severity.VERBOSE : Registered plugin creator - ::EfficientNMS_Explicit_TF_TRT version 1\n",
      "Severity.VERBOSE : Registered plugin creator - ::EfficientNMS_Implicit_TF_TRT version 1\n",
      "Severity.VERBOSE : Registered plugin creator - ::FlattenConcat_TRT version 1\n",
      "Severity.VERBOSE : Registered plugin creator - ::GenerateDetection_TRT version 1\n",
      "Severity.VERBOSE : Registered plugin creator - ::GridAnchor_TRT version 1\n",
      "Severity.VERBOSE : Registered plugin creator - ::GridAnchorRect_TRT version 1\n",
      "Severity.VERBOSE : Registered plugin creator - ::InstanceNormalization_TRT version 1\n",
      "Severity.VERBOSE : Registered plugin creator - ::LReLU_TRT version 1\n",
      "Severity.VERBOSE : Registered plugin creator - ::MultilevelCropAndResize_TRT version 1\n",
      "Severity.VERBOSE : Registered plugin creator - ::MultilevelProposeROI_TRT version 1\n",
      "Severity.VERBOSE : Registered plugin creator - ::DMHA version 1\n",
      "Severity.VERBOSE : Registered plugin creator - ::NMS_TRT version 1\n",
      "Severity.VERBOSE : Registered plugin creator - ::NMSDynamic_TRT version 1\n",
      "Severity.VERBOSE : Registered plugin creator - ::Normalize_TRT version 1\n",
      "Severity.VERBOSE : Registered plugin creator - ::PillarScatterPlugin version 1\n",
      "Severity.VERBOSE : Registered plugin creator - ::PriorBox_TRT version 1\n",
      "Severity.VERBOSE : Registered plugin creator - ::ProposalLayer_TRT version 1\n",
      "Severity.VERBOSE : Registered plugin creator - ::Proposal version 1\n",
      "Severity.VERBOSE : Registered plugin creator - ::ProposalDynamic version 1\n",
      "Severity.VERBOSE : Registered plugin creator - ::PyramidROIAlign_TRT version 1\n",
      "Severity.VERBOSE : Registered plugin creator - ::Region_TRT version 1\n",
      "Severity.VERBOSE : Registered plugin creator - ::Reorg_TRT version 1\n",
      "Severity.VERBOSE : Registered plugin creator - ::ResizeNearest_TRT version 1\n",
      "Severity.VERBOSE : Registered plugin creator - ::RPROI_TRT version 1\n",
      "Severity.VERBOSE : Registered plugin creator - ::ScatterND version 1\n",
      "Severity.VERBOSE : Registered plugin creator - ::SpecialSlice_TRT version 1\n",
      "Severity.VERBOSE : Registered plugin creator - ::Split version 1\n",
      "Severity.VERBOSE : Registered plugin creator - ::VoxelGeneratorPlugin version 1\n",
      "Severity.INFO : Loaded engine size: 16 MiB\n",
      "Severity.VERBOSE : Using cublas as a tactic source\n",
      "Severity.INFO : [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +158, GPU +159, now: CPU 497, GPU 2940 (MiB)\n",
      "Severity.VERBOSE : Using cuDNN as a tactic source\n",
      "Severity.INFO : [MemUsageChange] Init cuDNN: CPU +240, GPU +245, now: CPU 737, GPU 3185 (MiB)\n",
      "Severity.VERBOSE : Deserialization required 3277557 microseconds.\n",
      "Severity.INFO : [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +14, now: CPU 0, GPU 14 (MiB)\n"
     ]
    }
   ],
   "source": [
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "\n",
    "logger = MyLogger()\n",
    "runtime = trt.Runtime(logger)\n",
    "trt.init_libnvinfer_plugins(logger, namespace=\"\")\n",
    "\n",
    "with open(\"model_jetson.engine\", \"rb\") as f:\n",
    "    engine_IA1 = runtime.deserialize_cuda_engine(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement du moteur de l'IA n°2 : Détection de la position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Severity.INFO : Loaded engine size: 1 MiB\n",
      "Severity.VERBOSE : Using cublas as a tactic source\n",
      "Severity.INFO : [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +0, now: CPU 723, GPU 3169 (MiB)\n",
      "Severity.VERBOSE : Using cuDNN as a tactic source\n",
      "Severity.INFO : [MemUsageChange] Init cuDNN: CPU +0, GPU +0, now: CPU 723, GPU 3169 (MiB)\n",
      "Severity.VERBOSE : Deserialization required 28354 microseconds.\n",
      "Severity.INFO : [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +0, now: CPU 0, GPU 14 (MiB)\n"
     ]
    }
   ],
   "source": [
    "with open(\"model_classification_multi.engine\", \"rb\") as f:\n",
    "    engine_IA2 = runtime.deserialize_cuda_engine(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bDAHF_ylyV6g"
   },
   "source": [
    " ### Création des contextes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bwJpEUifyZBn",
    "outputId": "c3fd00db-ed12-4049-a1b3-52d4607118c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Severity.VERBOSE : Using cublas as a tactic source\n",
      "Severity.INFO : [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +0, now: CPU 722, GPU 3169 (MiB)\n",
      "Severity.VERBOSE : Using cuDNN as a tactic source\n",
      "Severity.INFO : [MemUsageChange] Init cuDNN: CPU +0, GPU +0, now: CPU 722, GPU 3169 (MiB)\n",
      "Severity.VERBOSE : Total per-runner device persistent memory is 13678592\n",
      "Severity.VERBOSE : Total per-runner host persistent memory is 157056\n",
      "Severity.VERBOSE : Allocated activation device memory of size 18387456\n",
      "Severity.INFO : [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +30, now: CPU 0, GPU 44 (MiB)\n"
     ]
    }
   ],
   "source": [
    "context_IA1 = engine_IA1.create_execution_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Severity.VERBOSE : Using cublas as a tactic source\n",
      "Severity.INFO : [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +0, now: CPU 729, GPU 3177 (MiB)\n",
      "Severity.VERBOSE : Using cuDNN as a tactic source\n",
      "Severity.INFO : [MemUsageChange] Init cuDNN: CPU +0, GPU +0, now: CPU 729, GPU 3177 (MiB)\n",
      "Severity.VERBOSE : Total per-runner device persistent memory is 0\n",
      "Severity.VERBOSE : Total per-runner host persistent memory is 18592\n",
      "Severity.VERBOSE : Allocated activation device memory of size 7168\n",
      "Severity.INFO : [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +0, now: CPU 0, GPU 44 (MiB)\n"
     ]
    }
   ],
   "source": [
    "context_IA2 = engine_IA2.create_execution_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TCb-68EnybiR"
   },
   "source": [
    "### Allocation de l'espace mémoire hôte et GPU pour l'IA1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "4r5agnDZywUo"
   },
   "outputs": [],
   "source": [
    "# Réservation de la mémoire pour l'entrée\n",
    "size_input_IA1 = trt.volume(engine_IA1.get_binding_shape(0))* engine_IA1.max_batch_size\n",
    "input_host_mem_IA1 = cuda.pagelocked_empty(size_input_IA1, np.int32)\n",
    "input_device_mem_IA1 = cuda.mem_alloc(input_host_mem_IA1.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O98UDiHA0UwS"
   },
   "outputs": [],
   "source": [
    "# Réservation de la mémoire pour les sorties\n",
    "output_device_mem_IA1 = [];\n",
    "format_sorties_IA1 = [];\n",
    "types_sorties_IA1 = [];\n",
    "\n",
    "for i in range(engine_IA1.num_bindings):\n",
    "    if not engine_IA1.binding_is_input(i):\n",
    "        size_output = trt.volume(engine_IA1.get_binding_shape(i))* engine_IA1.max_batch_size\n",
    "        output_host_mem = cuda.pagelocked_empty(size_output, trt.nptype(engine_IA1.get_binding_dtype(i)))\n",
    "        output_device_mem_IA1.append(cuda.mem_alloc(output_host_mem.nbytes))\n",
    "        format_sorties_IA1.append(engine_IA1.get_binding_shape(i))\n",
    "        types_sorties_IA1.append(trt.nptype(engine_IA1.get_binding_dtype(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "aSwI5P5V0vOw"
   },
   "outputs": [],
   "source": [
    "# Récupère les adresses en GPU des buffers entrées / sorties\n",
    "binding_entree_IA1 = int(input_device_mem_IA1)\n",
    "\n",
    "binding_sorties_IA1 = []\n",
    "for output_ in output_device_mem_IA1:\n",
    "    binding_sorties_IA1.append(int(output_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Allocation de l'espace mémoire hôte et GPU pour l'IA2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Réservation de la mémoire pour l'entrée\n",
    "size_input_IA2 = trt.volume(engine_IA2.get_binding_shape(0))* engine_IA2.max_batch_size\n",
    "input_host_mem_IA2 = cuda.pagelocked_empty(size_input_IA2, np.float32)\n",
    "input_device_mem_IA2 = cuda.mem_alloc(input_host_mem_IA2.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Réservation de la mémoire pour les sorties\n",
    "output_device_mem_IA2 = [];\n",
    "format_sorties_IA2 = [];\n",
    "types_sorties_IA2 = [];\n",
    "\n",
    "for i in range(engine_IA2.num_bindings):\n",
    "    if not engine_IA2.binding_is_input(i):\n",
    "        size_output = trt.volume(engine_IA2.get_binding_shape(i))* engine_IA2.max_batch_size\n",
    "        output_host_mem = cuda.pagelocked_empty(size_output, trt.nptype(engine_IA2.get_binding_dtype(i)))\n",
    "        output_device_mem_IA2.append(cuda.mem_alloc(output_host_mem.nbytes))\n",
    "        format_sorties_IA2.append(engine_IA2.get_binding_shape(i))\n",
    "        types_sorties_IA2.append(trt.nptype(engine_IA2.get_binding_dtype(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupère les adresses en GPU des buffers entrées / sorties\n",
    "binding_entree_IA2 = int(input_device_mem_IA2)\n",
    "\n",
    "binding_sorties_IA2 = []\n",
    "for output_ in output_device_mem_IA2:\n",
    "    binding_sorties_IA2.append(int(output_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_U4b-3pI0yLW"
   },
   "source": [
    "### Exécution des IAs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ybfzUVfR00Qg"
   },
   "source": [
    "On commence par récupérer une image du dataset :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-df505c38ff1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput_host_mem_IA1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'tuple' object is not callable"
     ]
    }
   ],
   "source": [
    "output_host_mem_IA1[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialisation des calculs...\n",
      "Etape 0-5 moyenne : 52.3 ms\n",
      "Etape 0-5 moyenne : 55.6 ms\n",
      "Etape 0-5 moyenne : 56.5 ms\n",
      "Etape 0-5 moyenne : 55.3 ms\n",
      "Etape 0-5 moyenne : 54.0 ms\n",
      "Etape 0-5 moyenne : 54.1 ms\n",
      "Etape 0-5 moyenne : 53.5 ms\n",
      "Etape 0-5 moyenne : 53.1 ms\n",
      "Etape 0-5 moyenne : 52.7 ms\n",
      "Etape 0-5 moyenne : 52.1 ms\n",
      "Etape 0-5 moyenne : 51.6 ms\n",
      "Etape 0-5 moyenne : 50.4 ms\n",
      "Etape 0-5 moyenne : 48.9 ms\n",
      "Etape 0-5 moyenne : 47.5 ms\n",
      "Etape 0-5 moyenne : 46.7 ms\n",
      "Etape 0-5 moyenne : 45.3 ms\n",
      "Etape 0-5 moyenne : 44.5 ms\n",
      "Etape 0-5 moyenne : 43.6 ms\n",
      "Etape 0-5 moyenne : 42.6 ms\n",
      "Etape 0-5 moyenne : 42.0 ms\n",
      "Etape 0-5 moyenne : 41.3 ms\n",
      "Etape 0-5 moyenne : 40.6 ms\n",
      "Etape 0-5 moyenne : 40.0 ms\n",
      "Etape 0-5 moyenne : 40.0 ms\n",
      "Etape 0-5 moyenne : 39.9 ms\n",
      "Etape 0-5 moyenne : 39.9 ms\n",
      "Etape 0-5 moyenne : 39.6 ms\n",
      "Etape 0-5 moyenne : 39.3 ms\n",
      "Etape 0-5 moyenne : 39.2 ms\n",
      "Etape 0-5 moyenne : 39.2 ms\n",
      "Etape 0-5 moyenne : 39.1 ms\n",
      "Etape 0-5 moyenne : 39.1 ms\n",
      "Etape 0-5 moyenne : 39.3 ms\n",
      "Etape 0-5 moyenne : 39.3 ms\n",
      "Etape 0-5 moyenne : 39.3 ms\n",
      "Etape 0-5 moyenne : 39.3 ms\n",
      "Etape 0-5 moyenne : 39.4 ms\n",
      "Etape 0-5 moyenne : 39.6 ms\n",
      "Etape 0-5 moyenne : 39.5 ms\n",
      "Etape 0-5 moyenne : 39.4 ms\n",
      "Etape 0-5 moyenne : 39.4 ms\n",
      "Etape 0-5 moyenne : 39.4 ms\n",
      "Etape 0-5 moyenne : 39.3 ms\n",
      "Etape 0-5 moyenne : 39.3 ms\n",
      "Etape 0-5 moyenne : 39.3 ms\n",
      "Etape 0-5 moyenne : 39.1 ms\n",
      "Etape 0-5 moyenne : 38.9 ms\n",
      "Etape 0-5 moyenne : 38.9 ms\n",
      "Etape 0-5 moyenne : 38.9 ms\n",
      "Etape 0-5 moyenne : 39.0 ms\n",
      "Etape 0-5 moyenne : 38.9 ms\n",
      "Etape 0-5 moyenne : 38.9 ms\n",
      "Etape 0-5 moyenne : 39.0 ms\n",
      "Etape 0-5 moyenne : 39.0 ms\n",
      "Etape 0-5 moyenne : 39.3 ms\n",
      "Etape 0-5 moyenne : 39.4 ms\n",
      "Etape 0-5 moyenne : 39.4 ms\n",
      "Etape 0-5 moyenne : 39.3 ms\n",
      "Etape 0-5 moyenne : 39.5 ms\n",
      "Etape 0-5 moyenne : 39.4 ms\n",
      "Etape 0-5 moyenne : 39.6 ms\n",
      "Etape 0-5 moyenne : 39.7 ms\n",
      "Etape 0-5 moyenne : 39.7 ms\n",
      "Etape 0-5 moyenne : 39.7 ms\n",
      "Etape 0-5 moyenne : 39.5 ms\n",
      "Etape 0-5 moyenne : 39.3 ms\n",
      "Etape 0-5 moyenne : 39.3 ms\n",
      "Etape 0-5 moyenne : 39.5 ms\n",
      "Etape 0-5 moyenne : 39.4 ms\n",
      "Etape 0-5 moyenne : 39.5 ms\n",
      "Etape 0-5 moyenne : 39.4 ms\n",
      "Etape 0-5 moyenne : 39.3 ms\n",
      "Etape 0-5 moyenne : 39.4 ms\n",
      "Etape 0-5 moyenne : 39.4 ms\n",
      "Etape 0-5 moyenne : 39.4 ms\n",
      "Etape 0-5 moyenne : 39.6 ms\n",
      "Etape 0-5 moyenne : 39.5 ms\n",
      "Etape 0-5 moyenne : 39.5 ms\n",
      "Etape 0-5 moyenne : 39.5 ms\n",
      "Etape 0-5 moyenne : 39.5 ms\n",
      "Etape 0-5 moyenne : 39.4 ms\n",
      "Etape 0-5 moyenne : 39.3 ms\n",
      "Etape 0-5 moyenne : 39.1 ms\n",
      "Etape 0-5 moyenne : 39.1 ms\n",
      "Etape 0-5 moyenne : 39.1 ms\n",
      "Etape 0-5 moyenne : 39.2 ms\n",
      "Etape 0-5 moyenne : 39.3 ms\n",
      "Etape 0-5 moyenne : 39.4 ms\n",
      "Etape 0-5 moyenne : 39.4 ms\n",
      "Etape 0-5 moyenne : 39.1 ms\n",
      "Etape 0-5 moyenne : 39.2 ms\n",
      "Etape 0-5 moyenne : 39.2 ms\n",
      "Etape 0-5 moyenne : 39.3 ms\n",
      "Etape 0-5 moyenne : 39.3 ms\n",
      "Etape 0-5 moyenne : 39.2 ms\n",
      "Etape 0-5 moyenne : 38.9 ms\n",
      "Etape 0-5 moyenne : 38.7 ms\n",
      "Etape 0-5 moyenne : 38.6 ms\n",
      "Etape 0-5 moyenne : 38.7 ms\n",
      "Etape 0-5 moyenne : 38.9 ms\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "nbr_run = 100\n",
    "delais = []\n",
    "\n",
    "bindings_IA1 = [binding_entree_IA1, binding_sorties_IA1[0]]\n",
    "bindings_IA2 = [binding_entree_IA2, binding_sorties_IA2[0]]\n",
    "\n",
    "image = tf.keras.preprocessing.image.load_img(\"Corbeau_NonCorrect.jpg\",target_size=(256, 256))\n",
    "image = np.expand_dims(image,axis=0)\n",
    "\n",
    "# Initialisation des calculs\n",
    "print(\"Initialisation des calculs...\")\n",
    "for i in range(5):  \n",
    "    # IA1\n",
    "    np.copyto(input_host_mem_IA1,image.ravel())\n",
    "    cuda.memcpy_htod(input_device_mem_IA1, input_host_mem_IA1)\n",
    "    context_IA1.execute_v2(bindings=bindings_IA1)\n",
    "    output_host_mem_IA1 = []\n",
    "    for i in range(len(output_device_mem_IA1)):\n",
    "        output_host_mem_IA1.append(np.zeros(format_sorties_IA1[i],types_sorties_IA1[i]))\n",
    "    for i in range(len(output_host_mem_IA1)):\n",
    "        cuda.memcpy_dtoh(output_host_mem_IA1[i], output_device_mem_IA1[i])\n",
    "    \n",
    "    # IA2\n",
    "    x = output_host_mem_IA1[0][0]           # (1,17,3)\n",
    "    np.copyto(input_host_mem_IA2,x.ravel())\n",
    "    cuda.memcpy_htod(input_device_mem_IA2, input_host_mem_IA2)\n",
    "    context_IA2.execute_v2(bindings=bindings_IA2)\n",
    "    output_host_mem_IA2 = []\n",
    "    for i in range(len(output_device_mem_IA2)):\n",
    "        output_host_mem_IA2.append(np.zeros(format_sorties_IA2[i],types_sorties_IA2[i]))\n",
    "    for i in range(len(output_host_mem_IA2)):\n",
    "        cuda.memcpy_dtoh(output_host_mem_IA2[i], output_device_mem_IA2[i])\n",
    "\n",
    "# Lance les inférences\n",
    "for i in range(nbr_run):\n",
    "    time0 = time.time()\n",
    "\n",
    "    # IA1\n",
    "    np.copyto(input_host_mem_IA1,image.ravel())\n",
    "    cuda.memcpy_htod(input_device_mem_IA1, input_host_mem_IA1)\n",
    "    context_IA1.execute_v2(bindings=bindings_IA1)\n",
    "    output_host_mem_IA1 = []\n",
    "    for i in range(len(output_device_mem_IA1)):\n",
    "        output_host_mem_IA1.append(np.zeros(format_sorties_IA1[i],types_sorties_IA1[i]))\n",
    "    for i in range(len(output_host_mem_IA1)):\n",
    "        cuda.memcpy_dtoh(output_host_mem_IA1[i], output_device_mem_IA1[i])\n",
    "    \n",
    "    # IA2\n",
    "    x = output_host_mem_IA1[0][0]           # (1,17,3)\n",
    "    np.copyto(input_host_mem_IA2,x.ravel())\n",
    "    cuda.memcpy_htod(input_device_mem_IA2, input_host_mem_IA2)\n",
    "    context_IA2.execute_v2(bindings=bindings_IA2)\n",
    "    output_host_mem_IA2 = []\n",
    "    for i in range(len(output_device_mem_IA2)):\n",
    "        output_host_mem_IA2.append(np.zeros(format_sorties_IA2[i],types_sorties_IA2[i]))\n",
    "    for i in range(len(output_host_mem_IA2)):\n",
    "        cuda.memcpy_dtoh(output_host_mem_IA2[i], output_device_mem_IA2[i])\n",
    "    \n",
    "    time_end = time.time()\n",
    "        \n",
    "    delais = np.append(delais,time_end - time0)\n",
    "        \n",
    "    if i%10 == 0:\n",
    "        print(\"Etape %d-%d moyenne : %4.1f ms\" %(i,i+5,(delais[-10:].mean())*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
