{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5b205b5-161f-4901-8aa8-07ca54d3ff62",
   "metadata": {},
   "source": [
    "# Création des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd5bf42-52e2-43c7-88a3-4e5e9dfac209",
   "metadata": {},
   "source": [
    "La procédure que nous allons suivre est très simple :\n",
    "- Nous allons tout d'abord prendre des photos qui ne respectent pas les conditions d'une pose correcte. Ces conditions seront appelées \"NON_CORRECT\" (\"NON_CORRECT\" est le **label** correspondant à cette condition). Nous prendrons des photographies à l'aide de la caméra.\n",
    "\n",
    "- Ensuite, nous prendrons des photos qui respectent la condition d'une pose correcte. Le label correspondant sera nommé \"CORRECT\". Comme précédemment, des photographies seront prises et enregistrées sous ce label.\n",
    "\n",
    "L'ensemble de ces résultats nous permettra de créer un ensemble de données appelé **dataset**. Quand nous aurons beaucoup d'images représentatives de ces deux conditions avec les labels associés, nous enverrons le dataset obtenu dans le GPU du jetson pour **entrainer** le réseau de neurones. Ce réseau de neurones nous permettra ensuite de prédire, en fonction des images issues de la caméra, si la personne filmée se trouve dans une condition d'une pose correcte ou non. Nous utiliserons ensuite le réseau entrainé pour gérer le score attribué à la bonne réalisation de la pose par la personne.\n",
    "\n",
    "Tout cela sera fait pour différente position dans différents sports..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619dc36f-2bba-4948-8701-4bb374de86c3",
   "metadata": {},
   "source": [
    "### Affichage de la caméra\n",
    "\n",
    "Pour commencer, initialisons la caméra afin de créer un écran de visualisation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e2fd04-0fc5-4f9f-90c2-2b02f2859f21",
   "metadata": {},
   "source": [
    "**Pour réinitialiser la caméra :** sudo systemctl restart nvargus-daemon.service "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44089805-4e05-4a1c-9aee-7f10f2e3e309",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo /home/jetson/notebook/ResetCam.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad591a67-ec11-4380-8eef-5a6058915da7",
   "metadata": {},
   "source": [
    "**Affiche les caméras disponnibles :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78749596-7fbf-4013-aebd-6d2d8ca3dd3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vi-output, imx219 7-0010 (platform:54080000.vi:0):\n",
      "\t/dev/video0\n",
      "\n",
      "USB 2.0 Camera (usb-70090000.xusb-2.1):\n",
      "\t/dev/video1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!v4l2-ctl --list-devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f243c85f-f9fe-4617-b31d-abee1905dbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "610388e9-141f-4579-aef4-2bc4bfffeac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt\n",
    "import numpy as np\n",
    "import pycuda.driver as cuda\n",
    "import threading\n",
    "import ctypes\n",
    "import time\n",
    "import traitlets\n",
    "import atexit\n",
    "import cv2\n",
    "\n",
    "class TRTInference(threading.Thread):\n",
    "    def __init__(self,repertoire_engine, widget_image,type_camera,capture_device,capture_width,capture_height,display_width,display_height,fps,flip=0):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.widget_image = widget_image\n",
    "        self.type_camera = type_camera\n",
    "        self.capture_device = capture_device\n",
    "        self.capture_width = capture_width\n",
    "        self.capture_height = capture_height\n",
    "        self.display_width = display_width\n",
    "        self.display_height = display_height\n",
    "        self.fps = fps\n",
    "        self.flip = flip\n",
    "        self.camera_on = False\n",
    "\n",
    "        # Initialisation des variables de la caméra\n",
    "        self._running = False\n",
    "        self.image_pour_widget = np.zeros((capture_width, capture_height, 3), dtype=np.int32)\n",
    "        self.image_origine = np.zeros((capture_width, capture_height, 3), dtype=np.int32)\n",
    "        self.image = np.zeros((256, 256, 3), dtype=np.int32)\n",
    "        \n",
    "        if self.type_camera.find(\"CSI\")>=0:\n",
    "            self.cap = cv2.VideoCapture(self._gstreamer_pipeline_CSI(),cv2.CAP_GSTREAMER)\n",
    "        else:\n",
    "            self.cap = cv2.VideoCapture(self._gstreamer_pipeline_USB(),cv2.CAP_GSTREAMER)\n",
    "        if self.cap.isOpened():\n",
    "            print(\"Caméra initialisée\")\n",
    "        else:\n",
    "            print(\"Erreur d'ouverture du flux vidéo\")\n",
    "        atexit.register(self.cap.release)\n",
    "\n",
    "        # Initialisation du runtime TensorRT\n",
    "        #self.logger = MyLogger()\n",
    "        self.logger = trt.Logger(trt.Logger.INFO)\n",
    "        trt.init_libnvinfer_plugins(self.logger, namespace=\"\")\n",
    "        self.runtime = trt.Runtime(self.logger)\n",
    "        \n",
    "        # Chargement du moteur\n",
    "        print(\"Chargement du moteur...\")\n",
    "        with open(repertoire_engine, \"rb\") as f:\n",
    "            self.engine = self.runtime.deserialize_cuda_engine(f.read())\n",
    "        \n",
    "        self.context = self.engine.create_execution_context()\n",
    " \n",
    "        #Initialisation du context Cuda et du contexte TensorRT \n",
    "        cuda.init()\n",
    "        self.cudactx = cuda.Device(0).retain_primary_context()\n",
    "        self.cudactx.push()\n",
    "        self.context.debug_sync = True\n",
    "        \n",
    "        # Réservation de la mémoire pour l'entrée\n",
    "        print(\"Allocation mémoire...\")\n",
    "        size_input = trt.volume(self.engine.get_binding_shape(0))*self.engine.max_batch_size\n",
    "        self.input_host_mem = cuda.pagelocked_empty(size_input, np.int32)\n",
    "        self.input_device_mem = cuda.mem_alloc(self.input_host_mem.nbytes)\n",
    "       \n",
    "        # Réservation de la mémoire pour les sorties\n",
    "        self.output_device_mem = [];\n",
    "        format_sorties = [];\n",
    "        types_sorties = [];\n",
    "\n",
    "        for i in range(self.engine.num_bindings):\n",
    "            if not self.engine.binding_is_input(i):\n",
    "                size_output = trt.volume(self.engine.get_binding_shape(i))*self.engine.max_batch_size\n",
    "                output_hm = cuda.pagelocked_empty(size_output,trt.nptype(self.engine.get_binding_dtype(i)))\n",
    "                self.output_device_mem.append(cuda.mem_alloc(output_hm.nbytes))\n",
    "                format_sorties.append(self.engine.get_binding_shape(i))\n",
    "                types_sorties.append(trt.nptype(self.engine.get_binding_dtype(i)))\n",
    "\n",
    "        # Récupère les adresses en GPU des buffers entrées / sorties\n",
    "        binding_entree = int(self.input_device_mem)\n",
    "        binding_sorties = []\n",
    "\n",
    "        for output_ in self.output_device_mem:\n",
    "            binding_sorties.append(int(output_))\n",
    "        self.bindings = [binding_entree, binding_sorties[0]]\n",
    "\n",
    "        # Allocation de la mémoire hote pour les sorties\n",
    "        self.output_host_mem = []\n",
    "        for i in range(len(self.output_device_mem)):\n",
    "            self.output_host_mem.append(np.zeros(format_sorties[i],types_sorties[i]))\n",
    "        \n",
    "        # Input tensor\n",
    "        self.image = np.zeros((256, 256, 3), dtype=trt.nptype(self.engine.get_binding_dtype(0)))\n",
    "        self.image = self.image.astype(np.int32)       \n",
    "        self.cudactx.pop()\n",
    "\n",
    "    # Inférence\n",
    "    def Calcul(self):\n",
    "        # Copie de l'image dans le tenseur d'entrée\n",
    "        x = self.image.astype(np.int32)\n",
    "        x = np.expand_dims(x,axis=0)                    # (1,256,256,3)\n",
    "        np.copyto(self.input_host_mem,x.ravel())\n",
    "        \n",
    "        # Transfert de l'entrée vers le GPU\n",
    "        self.cudactx = cuda.Device(0).retain_primary_context()\n",
    "        self.cudactx.push()\n",
    "        cuda.memcpy_htod(self.input_device_mem, self.input_host_mem)\n",
    "        \n",
    "        # Appel du modèle\n",
    "        self.context.execute_v2(bindings=self.bindings)\n",
    "        \n",
    "        # Récupération des sorties\n",
    "        for i in range(len(self.output_host_mem)):\n",
    "            cuda.memcpy_dtoh(self.output_host_mem[i], self.output_device_mem[i])\n",
    "        self.cudactx.pop()\n",
    "\n",
    "    # Lecture d'une frame\n",
    "    def capture_image(self):\n",
    "        re, image = self.cap.read()\n",
    "        if re:\n",
    "            return image\n",
    "        else:\n",
    "            return self.image_pour_widget\n",
    "        \n",
    "    def run(self):\n",
    "        while True:\n",
    "            if self.camera_on is True:\n",
    "                self.image_pour_widget = self.capture_image()\n",
    "                self.image_origine = bgr8_to_jpeg(self.image_pour_widget)\n",
    "                self.image = cv2.resize(self.image_pour_widget,(int(256),int(256)))              \n",
    "                self.Calcul()\n",
    "                \n",
    "                # Récupère les coordonnees XY\n",
    "                coordonneesXY = self.output_host_mem[0][0][0][:][:]\n",
    "                \n",
    "                # Place les points\n",
    "                width, height = (self.display_width,self.display_height)\n",
    "\n",
    "                nez = [int(coordonneesXY[0][1]*width),int(coordonneesXY[0][0]*height)]\n",
    "                oeuil_gauche = [int(coordonneesXY[1][1]*width),int(coordonneesXY[1][0]*height)]\n",
    "                oeuil_droit = [int(coordonneesXY[2][1]*width),int(coordonneesXY[2][0]*height)]\n",
    "                oreille_gauche = [int(coordonneesXY[3][1]*width),int(coordonneesXY[3][0]*height)]\n",
    "                oreille_droite = [int(coordonneesXY[4][1]*width),int(coordonneesXY[4][0]*height)]\n",
    "                epaule_gauche = [int(coordonneesXY[5][1]*width),int(coordonneesXY[5][0]*height)]\n",
    "                epaule_droite = [int(coordonneesXY[6][1]*width),int(coordonneesXY[6][0]*height)]\n",
    "                coude_gauche = [int(coordonneesXY[7][1]*width),int(coordonneesXY[7][0]*height)]\n",
    "                coude_droite = [int(coordonneesXY[8][1]*width),int(coordonneesXY[8][0]*height)]\n",
    "                poignet_gauche = [int(coordonneesXY[9][1]*width),int(coordonneesXY[9][0]*height)]\n",
    "                poignet_droite = [int(coordonneesXY[10][1]*width),int(coordonneesXY[10][0]*height)]\n",
    "                hanche_gauche = [int(coordonneesXY[11][1]*width),int(coordonneesXY[11][0]*height)]\n",
    "                hanche_droite = [int(coordonneesXY[12][1]*width),int(coordonneesXY[12][0]*height)]\n",
    "                genou_gauche = [int(coordonneesXY[13][1]*width),int(coordonneesXY[13][0]*height)]\n",
    "                genou_droite = [int(coordonneesXY[14][1]*width),int(coordonneesXY[14][0]*height)]\n",
    "                cheville_gauche = [int(coordonneesXY[15][1]*width),int(coordonneesXY[15][0]*height)]\n",
    "                cheville_droite = [int(coordonneesXY[16][1]*width),int(coordonneesXY[16][0]*height)]\n",
    "\n",
    "\n",
    "                centre_yeux = [((int(0.5*(coordonneesXY[1][1]*width+int(coordonneesXY[2][1]*width))))),((int(0.5*(coordonneesXY[1][0]*height+int(coordonneesXY[2][0]*height)))))]\n",
    "                centre_epaules = [((int(0.5*(coordonneesXY[5][1]*width+int(coordonneesXY[6][1]*width))))),((int(0.5*(coordonneesXY[5][0]*height+int(coordonneesXY[6][0]*height)))))]\n",
    "                centre_hanches =  [((int(0.5*(coordonneesXY[11][1]*width+int(coordonneesXY[12][1]*width))))),((int(0.5*(coordonneesXY[11][0]*height+int(coordonneesXY[12][0]*height)))))]\n",
    "\n",
    "\n",
    "                # Lignes nez-centre des yeux\n",
    "                self.image_pour_widget = cv2.line(self.image_pour_widget, (nez[0],nez[1]),(centre_yeux[0],centre_yeux[1]),color=(0, 0, 255), thickness=2)\n",
    "\n",
    "                # Lignes centre des yeux - oueil gauche\n",
    "                self.image_pour_widget = cv2.line(self.image_pour_widget, (oeuil_gauche[0],oeuil_gauche[1]),(centre_yeux[0],centre_yeux[1]),color=(0, 0, 255), thickness=2)\n",
    "\n",
    "                # Lignes centre des yeux - oueil droit\n",
    "                self.image_pour_widget = cv2.line(self.image_pour_widget, (oeuil_droit[0],oeuil_droit[1]),(centre_yeux[0],centre_yeux[1]),color=(0, 0, 255), thickness=2)\n",
    "\n",
    "                # Lignes oeuil_gauche - oreille gauche\n",
    "                self.image_pour_widget = cv2.line(self.image_pour_widget, (oeuil_gauche[0],oeuil_gauche[1]),(oreille_gauche[0],oreille_gauche[1]),color=(0, 0, 255), thickness=2)\n",
    "\n",
    "                # Lignes oeuil_droit - oreille droite\n",
    "                self.image_pour_widget = cv2.line(self.image_pour_widget, (oeuil_droit[0],oeuil_droit[1]),(oreille_droite[0],oreille_droite[1]),color=(0, 0, 255), thickness=2)\n",
    "\n",
    "                # Lignes nez-centre_epaules\n",
    "                self.image_pour_widget = cv2.line(self.image_pour_widget, (nez[0],nez[1]),(centre_epaules[0],centre_epaules[1]),color=(0, 0, 255), thickness=2)\n",
    "\n",
    "                # Ligne centre_epaules - epaule_droit\n",
    "                self.image_pour_widget = cv2.line(self.image_pour_widget, (epaule_droite[0],epaule_droite[1]),(centre_epaules[0],centre_epaules[1]),color=(0, 0, 255), thickness=2)\n",
    "\n",
    "                # Ligne centre_epaules - epaule_gauche\n",
    "                self.image_pour_widget = cv2.line(self.image_pour_widget, (epaule_gauche[0],epaule_gauche[1]),(centre_epaules[0],centre_epaules[1]),color=(0, 0, 255), thickness=2)\n",
    "\n",
    "                # Ligne épaule_gauche - coude_gouche\n",
    "                self.image_pour_widget = cv2.line(self.image_pour_widget, (epaule_gauche[0],epaule_gauche[1]),(coude_gauche[0],coude_gauche[1]),color=(0, 0, 255), thickness=2)\n",
    "\n",
    "                # Ligne coude_gouche - poignet_gauche\n",
    "                self.image_pour_widget = cv2.line(self.image_pour_widget, (poignet_gauche[0],poignet_gauche[1]),(coude_gauche[0],coude_gauche[1]),color=(0, 0, 255), thickness=2)\n",
    "\n",
    "                # Ligne épaule_droite - coude_doit\n",
    "                self.image_pour_widget = cv2.line(self.image_pour_widget, (epaule_droite[0],epaule_droite[1]),(coude_droite[0],coude_droite[1]),color=(0, 0, 255), thickness=2)\n",
    "\n",
    "                # Ligne coude_droite - poignet_droite\n",
    "                self.image_pour_widget = cv2.line(self.image_pour_widget, (poignet_droite[0],poignet_droite[1]),(coude_droite[0],coude_droite[1]),color=(0, 0, 255), thickness=2)\n",
    "\n",
    "                # Ligne centre_epaules - centre_hanche\n",
    "                self.image_pour_widget = cv2.line(self.image_pour_widget, (centre_hanches[0],centre_hanches[1]),(centre_epaules[0],centre_epaules[1]),color=(0, 0, 255), thickness=2)\n",
    "\n",
    "                # Ligne centre_hanche - hanche_gauche\n",
    "                self.image_pour_widget = cv2.line(self.image_pour_widget, (centre_hanches[0],centre_hanches[1]),(hanche_gauche[0],hanche_gauche[1]),color=(0, 0, 255), thickness=2)\n",
    "\n",
    "                # Ligne centre_hanche - hanche_gauche\n",
    "                self.image_pour_widget = cv2.line(self.image_pour_widget, (centre_hanches[0],centre_hanches[1]),(hanche_droite[0],hanche_droite[1]),color=(0, 0, 255), thickness=2)\n",
    "\n",
    "                # Ligne hanche_gauche - genou_gauche\n",
    "                self.image_pour_widget = cv2.line(self.image_pour_widget, (genou_gauche[0],genou_gauche[1]),(hanche_gauche[0],hanche_gauche[1]),color=(0, 0, 255), thickness=2)\n",
    "\n",
    "                # Ligne hanche_droite - genou_droite\n",
    "                self.image_pour_widget = cv2.line(self.image_pour_widget, (genou_droite[0],genou_droite[1]),(hanche_droite[0],hanche_droite[1]),color=(0, 0, 255), thickness=2)\n",
    "\n",
    "                # Ligne genou_droite - cheville_droite\n",
    "                self.image_pour_widget = cv2.line(self.image_pour_widget, (genou_droite[0],genou_droite[1]),(cheville_droite[0],cheville_droite[1]),color=(0, 0, 255), thickness=2)\n",
    "\n",
    "                # Ligne genou_gauche - cheville_gauche\n",
    "                self.image_pour_widget = cv2.line(self.image_pour_widget, (genou_gauche[0],genou_gauche[1]),(cheville_gauche[0],cheville_gauche[1]),color=(0, 0, 255), thickness=2)                \n",
    "                \n",
    "                self.widget_image.value = bgr8_to_jpeg(self.image_pour_widget)\n",
    "                time.sleep(0.001)\n",
    "\n",
    "    # Définition du pipeline pour la caméra CSI\n",
    "    def _gstreamer_pipeline_CSI(self):\n",
    "        return(\"nvarguscamerasrc sensor-id=%d ! \"\n",
    "                \"video/x-raw(memory:NVMM),\"\n",
    "                \"width=(int)%d,height=(int)%d,\"\n",
    "                \"format=(string)NV12, framerate=(fraction)%d/1 ! \"\n",
    "                \"nvvidconv flip-method=%d ! \"\n",
    "                \"video/x-raw,\"\n",
    "                \"width=(int)%d,height=(int)%d,\"\n",
    "                \"format=(string)BGRx ! videoconvert ! \"\n",
    "                \"video/x-raw, format=(string)BGR ! \"\n",
    "                \"appsink drop=true\"\n",
    "        %(self.capture_device,self.capture_width,self.capture_height,self.fps,self.flip, self.display_width,self.display_height))\n",
    "\n",
    "    # Définition du pipeline pour la USB\n",
    "    def _gstreamer_pipeline_USB(self):\n",
    "        return(\"v4l2src device=/dev/video%d ! \"\n",
    "               \"video/x-raw, width=(int)%d, height=(int)%d, framerate=(fraction)%d/1 ! \"\n",
    "               \"videoflip method=%d ! \"\n",
    "               \"videoconvert ! \"\n",
    "               \"video/x-raw, format=(string)BGR ! appsink drop=true\"\n",
    "        %(self.capture_device,self.capture_width,self.capture_height,self.fps,self.flip))            \n",
    "\n",
    "    # Routine pour arrêter le Thread\n",
    "    def raise_exception(self):\n",
    "        for id, thread in threading._active.items():\n",
    "            if thread is self:\n",
    "                thread_id = id\n",
    "        res = ctypes.pythonapi.PyThreadState_SetAsyncExc(thread_id,ctypes.py_object(SystemExit))\n",
    "        if res > 1:\n",
    "            ctypes.pythonapi.PyThreadState_SetAsyncExc(thread_id, 0)\n",
    "            print('Exception raise failure')\n",
    "\n",
    "    def destroy(self):\n",
    "        self.cudactx.detach()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d22d29-89d2-4c0d-bf71-0d9a5015e28d",
   "metadata": {},
   "source": [
    "### Répertoires de sauvegarde"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98474013-8114-4cb8-906f-58c8c395b231",
   "metadata": {},
   "source": [
    "Maintenant, nous allons créer un répertoire qui nous permettra de sauvegarder nos données.\n",
    "\n",
    "Nous allons nommer ce répertoire ``dataset``. Il va contenir deux sous-répertoires : ``CORRECT`` et ``NON_CORRECT``. Les images correspondantes à chaque condition seront sauvegardées dans ces sous-répertoires.\n",
    "\n",
    "Ces deux répertoires sont contenus dans un répertoire principal nommé en fonction du nom de la position qui est entrainée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3b180ea-09b9-4291-86d1-858e4326a0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "nom_position = \"Corbeau\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03ec97f7-2011-4682-b60d-1b469ea9a0bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "repertoire_correct = 'dataset/' + nom_position + '/CORRECT'\n",
    "repertoire_non_correct = 'dataset/' + nom_position + '/NON_CORRECT'\n",
    "\n",
    "# On utilise lex exeptions car si les réperoires exsitent déjà cela provoquera une erreur\n",
    "try:\n",
    "    os.makedirs(repertoire_correct)\n",
    "    os.makedirs(repertoire_non_correct)\n",
    "except FileExistsError:\n",
    "    print('Réperoires non créés car ils existent déjà')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d706d83-bf46-41f8-8a30-0c1afd32aef8",
   "metadata": {},
   "source": [
    "Vous devriez maintenant voir le réperoire dataset ainsi que les répertoires associés."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e0139e-9dc0-4c8c-824b-875e77baf4be",
   "metadata": {},
   "source": [
    "### Interface d'acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9815fef6-9e11-4dfa-93ec-cbe3095a5280",
   "metadata": {},
   "source": [
    "Nous allons maintenant afficher quelques boutons afin d'avoir un interface pour prendre les photographies et décider à quelle **classe** (c'est à dire quel label) appartient chaque photo. Nous allons également indiquer combien d'images sont contenues dans chaque classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de1e8a5c-e6e2-4aad-a9e9-4fdb9a7cddf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd93934bebdb4f6ab802a5b954c01a13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntText(value=0, layout=Layout(height='64px', width='200px')), Button(button_style='success', d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08ba1e1e35f447909a46f029a2a48cca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntText(value=0, layout=Layout(height='64px', width='200px')), Button(button_style='danger', de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Librairies IPython pour les widgets\n",
    "import ipywidgets\n",
    "import traitlets\n",
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "layout_bouton = widgets.Layout(width='200px', height='64px')\n",
    "bouton_correct = widgets.Button(description='Ajouter correct', button_style='success', layout=layout_bouton)\n",
    "bouton_non_correct = widgets.Button(description='Ajouter non_correct', button_style='danger', layout=layout_bouton)\n",
    "nombre_correct = widgets.IntText(layout=layout_bouton, value=len(os.listdir(repertoire_correct)))\n",
    "nombre_non_correct = widgets.IntText(layout=layout_bouton, value=len(os.listdir(repertoire_non_correct)))\n",
    "\n",
    "display(widgets.HBox([nombre_correct, bouton_correct]))\n",
    "display(widgets.HBox([nombre_non_correct, bouton_non_correct]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d33025-18bd-4077-a327-45d11bcb125a",
   "metadata": {},
   "source": [
    "Pour le moment ces boutons n'ont aucune action associée. Il faut que nous attachions des fonctions permettant de sauvegarder une image à chaque fois qu'un clic de souris est détecté sur le bouton. Pour cela nous allons utiliser l'évènement ``on_click``. Nous sauvegarderons alors la valeur du widget ``Image`` (plutôt que celui du widget camera car l'image est déjà compressée au format JPEG !)\n",
    "\n",
    "Pour être sûr de ne pas répéter le nom des fichiers, nous allons utiliser le package ``uuid``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf5d2012-aaa8-44c8-8baf-6b5af859ec98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid1\n",
    "\n",
    "# Fonction permettant de sauvegarder une image avec un nom de fichier unique\n",
    "def sauvegarde_image(repertoire):\n",
    "    chemin_image = os.path.join(repertoire, str(uuid1()) + '.jpg')\n",
    "    with open(chemin_image, 'wb') as f:\n",
    "        f.write(trt_inference_wrapper.image_origine)\n",
    "\n",
    "# Fonction appellée lors de l'appui sur le bouton \"Ajouter correct\"\n",
    "def sauvegarde_correct():\n",
    "    global repertoire_correct, nombre_correct\n",
    "    sauvegarde_image(repertoire_correct)\n",
    "    nombre_correct.value = len(os.listdir(repertoire_correct))\n",
    "    \n",
    "# Fonction appellée lors de l'appui sur le bouton \"Ajouter bloquer\"\n",
    "def sauvegarde_non_correct():\n",
    "    global repertoire_non_correct, nombre_non_correct\n",
    "    sauvegarde_image(repertoire_non_correct)\n",
    "    nombre_non_correct.value = len(os.listdir(repertoire_non_correct))\n",
    "    \n",
    "# Création des liens entre les fonctions et les évènements \"on_click\" des boutons\n",
    "bouton_correct.on_click(lambda x: sauvegarde_correct())\n",
    "bouton_non_correct.on_click(lambda x: sauvegarde_non_correct())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94b9a00-e03b-40a8-98d7-2a936d559c5c",
   "metadata": {},
   "source": [
    "Les butons peuvent maintenant sauvegarder nos images dans les bons répertoires ! \n",
    "\n",
    "Il est temps de récupérer des données :\n",
    "\n",
    "1. Placer la personne dans les conditions \"non correct\" et cliquer sur le bouton ``Ajouter non correct``\n",
    "2. Placer la personne dans les conditions \"correct\" et cliquer sur le bouton ``Ajouter correct``\n",
    "3. Répéter les étapes 1 et 2\n",
    "\n",
    "Quelques astuces :\n",
    "\n",
    "1. Utiliser différentes orientations\n",
    "2. Utiliser différents éclairages\n",
    "\n",
    "Dans l'idéal, plus le dataset est important et plus l'IA sera capable de détecter les positions dans la vie réelle. Il est important d'avoir des données *variées* et non pas uniquement beaucoup de données. Vous aurez probablement besoin d'au moins 100 images par classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "185ead69-ea31-4bf5-9a18-4ae015d7d2ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caméra initialisée\n",
      "Chargement du moteur...\n",
      "Allocation mémoire...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aea75530ba124754ab056852674c2f3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'', format='jpeg', height='480', width='640'), VBox(children=(VBox(children=(IntTe…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from jetbot import bgr8_to_jpeg\n",
    "\n",
    "# Création de l'interface\n",
    "widget_but1 = ipywidgets.VBox([nombre_correct, bouton_correct])\n",
    "widget_but2 = ipywidgets.VBox([nombre_non_correct, bouton_non_correct])\n",
    "widget_but = ipywidgets.VBox([widget_but1,widget_but2])\n",
    "image_widget = widgets.Image(format='jpeg', width=640, height=480)\n",
    "\n",
    "widget_global = ipywidgets.HBox([image_widget, widget_but])\n",
    "\n",
    "\n",
    "trt_inference_wrapper = TRTInference(repertoire_engine=\"model_jetson.engine\",\n",
    "                        widget_image=image_widget,\n",
    "                        type_camera=\"USB\",capture_device=1,\n",
    "                        capture_width=1280,capture_height=960,\n",
    "                        display_width=1280,display_height=960,\n",
    "                        fps=30,flip=0)\n",
    "\n",
    "trt_inference_wrapper.start()\n",
    "trt_inference_wrapper.camera_on = True\n",
    "\n",
    "# Affichage de l'interface\n",
    "display(widget_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed59cf05-6179-4632-87f3-11ee75722a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: dataset/ (stored 0%)\n",
      "  adding: dataset/Corbeau/ (stored 0%)\n",
      "  adding: dataset/Corbeau/NON_CORRECT/ (stored 0%)\n",
      "  adding: dataset/Corbeau/NON_CORRECT/dfc62fa2-eb60-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n",
      "  adding: dataset/Corbeau/NON_CORRECT/b3b7f67a-eb60-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n",
      "  adding: dataset/Corbeau/NON_CORRECT/cbf90260-eb60-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n",
      "  adding: dataset/Corbeau/NON_CORRECT/d778ec68-eb60-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n",
      "  adding: dataset/Corbeau/NON_CORRECT/aaf7332a-eb60-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n",
      "  adding: dataset/Corbeau/NON_CORRECT/cf54075c-eb60-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n",
      "  adding: dataset/Corbeau/NON_CORRECT/e104de04-eb60-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n",
      "  adding: dataset/Corbeau/NON_CORRECT/b251f0b0-eb60-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n",
      "  adding: dataset/Corbeau/NON_CORRECT/df30036a-eb60-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n",
      "  adding: dataset/Corbeau/NON_CORRECT/921f05f8-eb60-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n",
      "  adding: dataset/Corbeau/NON_CORRECT/ac2a6172-eb60-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n",
      "  adding: dataset/Corbeau/NON_CORRECT/c0e6072e-eb60-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n",
      "  adding: dataset/Corbeau/NON_CORRECT/d3c33e5c-eb60-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n",
      "  adding: dataset/Corbeau/NON_CORRECT/ddd08332-eb60-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n",
      "  adding: dataset/Corbeau/NON_CORRECT/cd708a8c-eb60-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n",
      "  adding: dataset/Corbeau/NON_CORRECT/de4ce1de-eb60-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n",
      "  adding: dataset/Corbeau/NON_CORRECT/680908ea-eb60-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n",
      "  adding: dataset/Corbeau/NON_CORRECT/d49c791a-eb60-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n",
      "  adding: dataset/Corbeau/NON_CORRECT/d1cec1e8-eb60-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n",
      "  adding: dataset/Corbeau/NON_CORRECT/d0110f64-eb60-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n",
      "  adding: dataset/Corbeau/NON_CORRECT/db642842-eb60-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n",
      "  adding: dataset/Corbeau/NON_CORRECT/e05fe778-eb60-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n",
      "  adding: dataset/Corbeau/NON_CORRECT/6306187e-eb60-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n",
      "  adding: dataset/Corbeau/NON_CORRECT/ca5d143c-eb60-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n",
      "  adding: dataset/Corbeau/NON_CORRECT/dd47db54-eb60-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n",
      "  adding: dataset/Corbeau/NON_CORRECT/d8c88790-eb60-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n",
      "  adding: dataset/Corbeau/NON_CORRECT/d5c8a886-eb60-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n",
      "  adding: dataset/Corbeau/NON_CORRECT/b08269b8-eb60-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n",
      "  adding: dataset/Corbeau/NON_CORRECT/c5db8db2-eb60-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n",
      "  adding: dataset/Corbeau/NON_CORRECT/d991fca6-eb60-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n",
      "  adding: dataset/Corbeau/NON_CORRECT/ad56afd8-eb60-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n",
      "  adding: dataset/Corbeau/NON_CORRECT/b4fcfb52-eb60-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n",
      "  adding: dataset/Corbeau/NON_CORRECT/c8763ef0-eb60-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n",
      "  adding: dataset/Corbeau/NON_CORRECT/69ccba5a-eb60-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n",
      "  adding: dataset/Corbeau/NON_CORRECT/dc919b32-eb60-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n",
      "  adding: dataset/Corbeau/NON_CORRECT/e1e917ae-eb60-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n",
      "  adding: dataset/Corbeau/NON_CORRECT/86dbb7e0-eb60-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n",
      "  adding: dataset/Corbeau/NON_CORRECT/c765ac30-eb60-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n",
      "  adding: dataset/Corbeau/NON_CORRECT/da9c29dc-eb60-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n",
      "  adding: dataset/Corbeau/NON_CORRECT/d2d474f2-eb60-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n",
      "  adding: dataset/Corbeau/NON_CORRECT/c9665eee-eb60-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n",
      "  adding: dataset/Corbeau/NON_CORRECT/c2c486e2-eb60-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n",
      "  adding: dataset/Corbeau/CORRECT/ (stored 0%)\n",
      "  adding: dataset/Corbeau/CORRECT/e77859aa-eb60-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n",
      "  adding: dataset/Corbeau/CORRECT/e306b4f2-eb60-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n",
      "  adding: dataset/Corbeau/CORRECT/0f491d20-eb61-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n",
      "  adding: dataset/Corbeau/CORRECT/71e81554-eb60-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n",
      "  adding: dataset/Corbeau/CORRECT/a8d40ed8-eb60-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n",
      "  adding: dataset/Corbeau/CORRECT/5fe1d192-eb60-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n",
      "  adding: dataset/Corbeau/CORRECT/1d4b9ba0-eb61-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n",
      "  adding: dataset/Corbeau/CORRECT/e4c52bac-eb60-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n",
      "  adding: dataset/Corbeau/CORRECT/204c8486-eb61-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n",
      "  adding: dataset/Corbeau/CORRECT/21eb8bc0-eb61-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n",
      "  adding: dataset/Corbeau/CORRECT/b80f1bfe-eb60-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n",
      "  adding: dataset/Corbeau/CORRECT/93c7c25a-eb60-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n",
      "  adding: dataset/Corbeau/CORRECT/c46271f8-eb60-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n",
      "  adding: dataset/Corbeau/CORRECT/ae6bbdf0-eb60-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n",
      "  adding: dataset/Corbeau/CORRECT/1e372732-eb61-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n",
      "  adding: dataset/Corbeau/CORRECT/e9c117e2-eb60-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n",
      "  adding: dataset/Corbeau/CORRECT/78fb7ec6-eb60-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n",
      "  adding: dataset/Corbeau/CORRECT/8fbe31a8-eb60-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n",
      "  adding: dataset/Corbeau/CORRECT/117f6342-eb61-11ee-9231-48b02d51ecb9.jpg (deflated 0%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r dataset.zip dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0734ebe7-09c0-4c6e-afad-79543ac1538d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
