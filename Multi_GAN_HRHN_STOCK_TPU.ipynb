{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multi_GAN_HRHN_STOCK.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexandreBourrieau/FICHIERS/blob/main/Multi_GAN_HRHN_STOCK_TPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Luvr5mg72jn"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "from keras import backend as K"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SngD1T5rE09j"
      },
      "source": [
        "# Initialisation TPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azq2F27MXmeS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b08043b-2fdd-4f1a-be1d-b7a3ff73f00b"
      },
      "source": [
        "import os\n",
        "\n",
        "use_tpu = True\n",
        "\n",
        "if use_tpu:\n",
        "    assert 'COLAB_TPU_ADDR' in os.environ, 'Missing TPU; did you request a TPU in Notebook Settings?'\n",
        "\n",
        "if 'COLAB_TPU_ADDR' in os.environ:\n",
        "  TPU_ADDRESS = 'grpc://{}'.format(os.environ['COLAB_TPU_ADDR'])\n",
        "else:\n",
        "  TPU_ADDRESS = ''\n",
        "\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=TPU_ADDRESS)\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.31.153.234:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.31.153.234:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "All devices:  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArXLu7v7ZiZP"
      },
      "source": [
        "# Chargement et correction des données"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mg8UqC4JTMqD"
      },
      "source": [
        "Le dataset utilisé contient les prix des actions des 81 principales compagnies du NASDAQ100. La valeur de l'index du NASDAQ est utilisé comme cible.  \n",
        "La fréquence des information est d'une minute, depuis le 26 juillet 2016 jusqu'au 22 décembre 2016, soit 105 jours au total (les samedi et dimanche ne sont pas comptés, ainsi que le 25 novembre qui ne possède que 210 données et le 22 décembre qui n'en possède que 180)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNPjm5bA9_u8"
      },
      "source": [
        "**1. Chargement des données**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WwTu0bDquT2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f1218c9-846a-43c6-b92f-7ee14334cf34"
      },
      "source": [
        "!rm *.csv\n",
        "!curl --location --remote-header-name --remote-name \"https://github.com/AlexandreBourrieau/FICHIERS/raw/main/Series_Temporelles/Multi/Data/Stock_complet.csv\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove '*.csv': No such file or directory\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   180  100   180    0     0    303      0 --:--:-- --:--:-- --:--:--   303\n",
            "100 1920k  100 1920k    0     0  2671k      0 --:--:-- --:--:-- --:--:-- 2671k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z66721h8-CY1"
      },
      "source": [
        "**2. Analyse et correction des données**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffclRRHzqxYO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "108064bb-cd50-4191-c388-539d28dd5f8e"
      },
      "source": [
        "# Création de la série sous Pandas\n",
        "df_etude = pd.read_csv(\"Stock_complet.csv\")\n",
        "df_etude = df_etude.drop(columns='DateTime')\n",
        "df_etude = df_etude.astype('float32')\n",
        "df_etude"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>O_AAPL</th>\n",
              "      <th>H_AAPL</th>\n",
              "      <th>L_AAPL</th>\n",
              "      <th>AdjC_AAPL</th>\n",
              "      <th>V_AAPL</th>\n",
              "      <th>C_AMNZ</th>\n",
              "      <th>C_BRENT</th>\n",
              "      <th>C_BSESN</th>\n",
              "      <th>C_CAC40</th>\n",
              "      <th>C_DAX</th>\n",
              "      <th>C_DJI</th>\n",
              "      <th>C_FTSE</th>\n",
              "      <th>C_GOLD</th>\n",
              "      <th>C_GOOG</th>\n",
              "      <th>C_HSI</th>\n",
              "      <th>C_MSFT</th>\n",
              "      <th>C_N225</th>\n",
              "      <th>C_NASDAQ</th>\n",
              "      <th>C_NYSE</th>\n",
              "      <th>C_RUT2000</th>\n",
              "      <th>C_SP500</th>\n",
              "      <th>C_SPTSX</th>\n",
              "      <th>C_SSE</th>\n",
              "      <th>C_USD</th>\n",
              "      <th>C_W5000</th>\n",
              "      <th>C_WTICL</th>\n",
              "      <th>C_AAPL_sma5</th>\n",
              "      <th>C_AAPL_sma7</th>\n",
              "      <th>C_AAPL_sma10</th>\n",
              "      <th>C_AAPL_sma15</th>\n",
              "      <th>C_AAPL_sma21</th>\n",
              "      <th>C_AAPL_macd</th>\n",
              "      <th>C_AAPL_macdh</th>\n",
              "      <th>C_AAPL_macds</th>\n",
              "      <th>C_AAPL_BBl</th>\n",
              "      <th>C_AAPL_BBm</th>\n",
              "      <th>C_AAPL_BBu</th>\n",
              "      <th>C_AAPL_RSI</th>\n",
              "      <th>C_AAPL_FOUR3</th>\n",
              "      <th>C_AAPL_FOUR6</th>\n",
              "      <th>C_AAPL_FOUR9</th>\n",
              "      <th>C_AAPL_LR</th>\n",
              "      <th>C_AAPL_PERCENTLR</th>\n",
              "      <th>C_AAPL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9.387143</td>\n",
              "      <td>9.438571</td>\n",
              "      <td>9.296786</td>\n",
              "      <td>8.076332</td>\n",
              "      <td>420375200.0</td>\n",
              "      <td>127.580002</td>\n",
              "      <td>82.199997</td>\n",
              "      <td>18217.439453</td>\n",
              "      <td>3760.719971</td>\n",
              "      <td>6331.330078</td>\n",
              "      <td>10680.429688</td>\n",
              "      <td>5386.200195</td>\n",
              "      <td>1193.699951</td>\n",
              "      <td>252.214645</td>\n",
              "      <td>21549.880859</td>\n",
              "      <td>25.730000</td>\n",
              "      <td>9489.339844</td>\n",
              "      <td>2303.570068</td>\n",
              "      <td>7182.140137</td>\n",
              "      <td>662.960022</td>\n",
              "      <td>1127.239990</td>\n",
              "      <td>11845.099609</td>\n",
              "      <td>2638.521973</td>\n",
              "      <td>80.991997</td>\n",
              "      <td>11827.330078</td>\n",
              "      <td>82.470001</td>\n",
              "      <td>9.327572</td>\n",
              "      <td>9.291939</td>\n",
              "      <td>9.305500</td>\n",
              "      <td>9.280857</td>\n",
              "      <td>9.170510</td>\n",
              "      <td>0.101738</td>\n",
              "      <td>0.000268</td>\n",
              "      <td>0.101469</td>\n",
              "      <td>9.222883</td>\n",
              "      <td>9.327572</td>\n",
              "      <td>9.432260</td>\n",
              "      <td>64.230026</td>\n",
              "      <td>25.862972</td>\n",
              "      <td>22.961653</td>\n",
              "      <td>19.991785</td>\n",
              "      <td>0.062933</td>\n",
              "      <td>0.064955</td>\n",
              "      <td>9.392143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9.347500</td>\n",
              "      <td>9.399286</td>\n",
              "      <td>9.305357</td>\n",
              "      <td>8.037019</td>\n",
              "      <td>289097216.0</td>\n",
              "      <td>127.830002</td>\n",
              "      <td>81.610001</td>\n",
              "      <td>18172.830078</td>\n",
              "      <td>3764.189941</td>\n",
              "      <td>6333.580078</td>\n",
              "      <td>10674.980469</td>\n",
              "      <td>5365.799805</td>\n",
              "      <td>1197.199951</td>\n",
              "      <td>253.101318</td>\n",
              "      <td>21551.720703</td>\n",
              "      <td>25.370001</td>\n",
              "      <td>9653.919922</td>\n",
              "      <td>2293.060059</td>\n",
              "      <td>7174.270020</td>\n",
              "      <td>655.070007</td>\n",
              "      <td>1125.810059</td>\n",
              "      <td>11774.799805</td>\n",
              "      <td>2620.757080</td>\n",
              "      <td>80.930000</td>\n",
              "      <td>11797.599609</td>\n",
              "      <td>82.010002</td>\n",
              "      <td>9.348405</td>\n",
              "      <td>9.310255</td>\n",
              "      <td>9.314143</td>\n",
              "      <td>9.298619</td>\n",
              "      <td>9.187943</td>\n",
              "      <td>0.099481</td>\n",
              "      <td>-0.001591</td>\n",
              "      <td>0.101072</td>\n",
              "      <td>9.287694</td>\n",
              "      <td>9.348405</td>\n",
              "      <td>9.409116</td>\n",
              "      <td>60.517967</td>\n",
              "      <td>25.748791</td>\n",
              "      <td>22.791813</td>\n",
              "      <td>19.779182</td>\n",
              "      <td>0.058053</td>\n",
              "      <td>0.059772</td>\n",
              "      <td>9.346429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9.277857</td>\n",
              "      <td>9.338929</td>\n",
              "      <td>9.201071</td>\n",
              "      <td>7.987574</td>\n",
              "      <td>444897600.0</td>\n",
              "      <td>128.320007</td>\n",
              "      <td>80.160004</td>\n",
              "      <td>18143.990234</td>\n",
              "      <td>3716.050049</td>\n",
              "      <td>6259.629883</td>\n",
              "      <td>10653.559570</td>\n",
              "      <td>5332.399902</td>\n",
              "      <td>1203.400024</td>\n",
              "      <td>249.176025</td>\n",
              "      <td>21678.800781</td>\n",
              "      <td>25.549999</td>\n",
              "      <td>9642.120117</td>\n",
              "      <td>2288.469971</td>\n",
              "      <td>7153.720215</td>\n",
              "      <td>650.679993</td>\n",
              "      <td>1121.640015</td>\n",
              "      <td>11800.000000</td>\n",
              "      <td>2658.392090</td>\n",
              "      <td>80.496002</td>\n",
              "      <td>11754.440430</td>\n",
              "      <td>80.699997</td>\n",
              "      <td>9.346786</td>\n",
              "      <td>9.324745</td>\n",
              "      <td>9.299892</td>\n",
              "      <td>9.301167</td>\n",
              "      <td>9.205272</td>\n",
              "      <td>0.091992</td>\n",
              "      <td>-0.007264</td>\n",
              "      <td>0.099256</td>\n",
              "      <td>9.280504</td>\n",
              "      <td>9.346786</td>\n",
              "      <td>9.413068</td>\n",
              "      <td>56.124306</td>\n",
              "      <td>25.635012</td>\n",
              "      <td>22.623970</td>\n",
              "      <td>19.571798</td>\n",
              "      <td>0.051882</td>\n",
              "      <td>0.053252</td>\n",
              "      <td>9.288929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9.298095</td>\n",
              "      <td>9.346786</td>\n",
              "      <td>9.224166</td>\n",
              "      <td>8.004567</td>\n",
              "      <td>397641056.0</td>\n",
              "      <td>128.490005</td>\n",
              "      <td>80.436668</td>\n",
              "      <td>18191.826172</td>\n",
              "      <td>3736.489990</td>\n",
              "      <td>6290.286621</td>\n",
              "      <td>10668.623047</td>\n",
              "      <td>5358.433105</td>\n",
              "      <td>1202.500000</td>\n",
              "      <td>250.027832</td>\n",
              "      <td>21719.730469</td>\n",
              "      <td>25.570000</td>\n",
              "      <td>9618.910156</td>\n",
              "      <td>2294.209961</td>\n",
              "      <td>7165.246582</td>\n",
              "      <td>653.626648</td>\n",
              "      <td>1123.690063</td>\n",
              "      <td>11821.200195</td>\n",
              "      <td>2663.105469</td>\n",
              "      <td>80.593666</td>\n",
              "      <td>11778.633789</td>\n",
              "      <td>80.959999</td>\n",
              "      <td>9.338167</td>\n",
              "      <td>9.334235</td>\n",
              "      <td>9.298762</td>\n",
              "      <td>9.302841</td>\n",
              "      <td>9.225992</td>\n",
              "      <td>0.086653</td>\n",
              "      <td>-0.010082</td>\n",
              "      <td>0.096735</td>\n",
              "      <td>9.265800</td>\n",
              "      <td>9.338167</td>\n",
              "      <td>9.410535</td>\n",
              "      <td>57.272457</td>\n",
              "      <td>25.521643</td>\n",
              "      <td>22.458143</td>\n",
              "      <td>19.369669</td>\n",
              "      <td>0.054008</td>\n",
              "      <td>0.055493</td>\n",
              "      <td>9.308691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9.318333</td>\n",
              "      <td>9.354643</td>\n",
              "      <td>9.247262</td>\n",
              "      <td>8.021561</td>\n",
              "      <td>350384544.0</td>\n",
              "      <td>128.660004</td>\n",
              "      <td>80.713333</td>\n",
              "      <td>18239.664062</td>\n",
              "      <td>3756.930176</td>\n",
              "      <td>6320.943359</td>\n",
              "      <td>10683.686523</td>\n",
              "      <td>5384.466797</td>\n",
              "      <td>1201.599976</td>\n",
              "      <td>250.879639</td>\n",
              "      <td>21760.660156</td>\n",
              "      <td>25.590000</td>\n",
              "      <td>9595.700195</td>\n",
              "      <td>2299.949951</td>\n",
              "      <td>7176.773438</td>\n",
              "      <td>656.573364</td>\n",
              "      <td>1125.739990</td>\n",
              "      <td>11842.399414</td>\n",
              "      <td>2667.818604</td>\n",
              "      <td>80.691338</td>\n",
              "      <td>11802.826172</td>\n",
              "      <td>81.220001</td>\n",
              "      <td>9.332929</td>\n",
              "      <td>9.338725</td>\n",
              "      <td>9.309786</td>\n",
              "      <td>9.306357</td>\n",
              "      <td>9.250102</td>\n",
              "      <td>0.083059</td>\n",
              "      <td>-0.010941</td>\n",
              "      <td>0.094000</td>\n",
              "      <td>9.262320</td>\n",
              "      <td>9.332929</td>\n",
              "      <td>9.403538</td>\n",
              "      <td>58.443516</td>\n",
              "      <td>25.408688</td>\n",
              "      <td>22.294350</td>\n",
              "      <td>19.172829</td>\n",
              "      <td>0.056128</td>\n",
              "      <td>0.057733</td>\n",
              "      <td>9.328452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3630</th>\n",
              "      <td>96.621666</td>\n",
              "      <td>98.630005</td>\n",
              "      <td>95.073334</td>\n",
              "      <td>94.984985</td>\n",
              "      <td>157851872.0</td>\n",
              "      <td>3136.000000</td>\n",
              "      <td>42.893333</td>\n",
              "      <td>36660.570312</td>\n",
              "      <td>5027.646484</td>\n",
              "      <td>12744.549805</td>\n",
              "      <td>26082.300781</td>\n",
              "      <td>6149.266602</td>\n",
              "      <td>1806.733276</td>\n",
              "      <td>1521.473267</td>\n",
              "      <td>25757.216797</td>\n",
              "      <td>209.270004</td>\n",
              "      <td>22620.097656</td>\n",
              "      <td>10466.373047</td>\n",
              "      <td>12034.973633</td>\n",
              "      <td>1409.939941</td>\n",
              "      <td>3165.159912</td>\n",
              "      <td>15664.200195</td>\n",
              "      <td>3423.297852</td>\n",
              "      <td>96.475998</td>\n",
              "      <td>32263.197266</td>\n",
              "      <td>40.250000</td>\n",
              "      <td>95.682503</td>\n",
              "      <td>95.006783</td>\n",
              "      <td>94.178253</td>\n",
              "      <td>93.016556</td>\n",
              "      <td>92.157974</td>\n",
              "      <td>2.494917</td>\n",
              "      <td>0.133170</td>\n",
              "      <td>2.361747</td>\n",
              "      <td>95.294365</td>\n",
              "      <td>95.682503</td>\n",
              "      <td>96.070633</td>\n",
              "      <td>74.219666</td>\n",
              "      <td>44.328197</td>\n",
              "      <td>45.216000</td>\n",
              "      <td>48.296745</td>\n",
              "      <td>2.383493</td>\n",
              "      <td>9.842714</td>\n",
              "      <td>95.625000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3631</th>\n",
              "      <td>97.264999</td>\n",
              "      <td>99.955002</td>\n",
              "      <td>95.257500</td>\n",
              "      <td>94.838470</td>\n",
              "      <td>191649200.0</td>\n",
              "      <td>3104.000000</td>\n",
              "      <td>42.720001</td>\n",
              "      <td>36693.691406</td>\n",
              "      <td>5056.229980</td>\n",
              "      <td>12799.969727</td>\n",
              "      <td>26085.800781</td>\n",
              "      <td>6176.200195</td>\n",
              "      <td>1811.000000</td>\n",
              "      <td>1511.339966</td>\n",
              "      <td>25772.119141</td>\n",
              "      <td>207.070007</td>\n",
              "      <td>22784.740234</td>\n",
              "      <td>10390.839844</td>\n",
              "      <td>12014.669922</td>\n",
              "      <td>1403.569946</td>\n",
              "      <td>3155.219971</td>\n",
              "      <td>15639.400391</td>\n",
              "      <td>3443.285889</td>\n",
              "      <td>96.406998</td>\n",
              "      <td>32131.820312</td>\n",
              "      <td>40.099998</td>\n",
              "      <td>95.709503</td>\n",
              "      <td>95.294640</td>\n",
              "      <td>94.562378</td>\n",
              "      <td>93.397331</td>\n",
              "      <td>92.432259</td>\n",
              "      <td>2.436403</td>\n",
              "      <td>0.059725</td>\n",
              "      <td>2.376678</td>\n",
              "      <td>95.411385</td>\n",
              "      <td>95.709503</td>\n",
              "      <td>96.007614</td>\n",
              "      <td>73.031967</td>\n",
              "      <td>44.226395</td>\n",
              "      <td>45.003918</td>\n",
              "      <td>48.016922</td>\n",
              "      <td>2.381950</td>\n",
              "      <td>9.825990</td>\n",
              "      <td>95.477501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3632</th>\n",
              "      <td>94.839996</td>\n",
              "      <td>97.254997</td>\n",
              "      <td>93.877502</td>\n",
              "      <td>96.407898</td>\n",
              "      <td>170989200.0</td>\n",
              "      <td>3084.000000</td>\n",
              "      <td>42.900002</td>\n",
              "      <td>36033.058594</td>\n",
              "      <td>5007.459961</td>\n",
              "      <td>12697.360352</td>\n",
              "      <td>26642.589844</td>\n",
              "      <td>6179.799805</td>\n",
              "      <td>1810.599976</td>\n",
              "      <td>1520.579956</td>\n",
              "      <td>25477.890625</td>\n",
              "      <td>208.350006</td>\n",
              "      <td>22587.009766</td>\n",
              "      <td>10488.580078</td>\n",
              "      <td>12014.669922</td>\n",
              "      <td>1428.260010</td>\n",
              "      <td>3197.520020</td>\n",
              "      <td>15908.500000</td>\n",
              "      <td>3414.618896</td>\n",
              "      <td>96.207001</td>\n",
              "      <td>32556.599609</td>\n",
              "      <td>40.290001</td>\n",
              "      <td>95.970497</td>\n",
              "      <td>95.849640</td>\n",
              "      <td>95.043625</td>\n",
              "      <td>93.838165</td>\n",
              "      <td>92.690598</td>\n",
              "      <td>2.488833</td>\n",
              "      <td>0.089724</td>\n",
              "      <td>2.399109</td>\n",
              "      <td>94.844177</td>\n",
              "      <td>95.970497</td>\n",
              "      <td>97.096825</td>\n",
              "      <td>77.234558</td>\n",
              "      <td>44.124035</td>\n",
              "      <td>44.790424</td>\n",
              "      <td>47.732841</td>\n",
              "      <td>2.398363</td>\n",
              "      <td>10.005142</td>\n",
              "      <td>97.057503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3633</th>\n",
              "      <td>94.839996</td>\n",
              "      <td>97.254997</td>\n",
              "      <td>93.877502</td>\n",
              "      <td>96.407898</td>\n",
              "      <td>170989200.0</td>\n",
              "      <td>3008.870117</td>\n",
              "      <td>43.790001</td>\n",
              "      <td>36051.808594</td>\n",
              "      <td>5108.979980</td>\n",
              "      <td>12930.980469</td>\n",
              "      <td>26870.099609</td>\n",
              "      <td>6292.700195</td>\n",
              "      <td>1811.400024</td>\n",
              "      <td>1513.640015</td>\n",
              "      <td>25481.580078</td>\n",
              "      <td>208.039993</td>\n",
              "      <td>22945.500000</td>\n",
              "      <td>10550.490234</td>\n",
              "      <td>12391.320312</td>\n",
              "      <td>1478.270020</td>\n",
              "      <td>3226.560059</td>\n",
              "      <td>16063.299805</td>\n",
              "      <td>3361.303955</td>\n",
              "      <td>96.039001</td>\n",
              "      <td>32935.410156</td>\n",
              "      <td>41.200001</td>\n",
              "      <td>96.197998</td>\n",
              "      <td>96.094643</td>\n",
              "      <td>95.464005</td>\n",
              "      <td>94.228668</td>\n",
              "      <td>93.025955</td>\n",
              "      <td>2.501548</td>\n",
              "      <td>0.081951</td>\n",
              "      <td>2.419597</td>\n",
              "      <td>94.782097</td>\n",
              "      <td>96.197998</td>\n",
              "      <td>97.613907</td>\n",
              "      <td>77.234558</td>\n",
              "      <td>44.021114</td>\n",
              "      <td>44.575554</td>\n",
              "      <td>47.444576</td>\n",
              "      <td>2.398363</td>\n",
              "      <td>10.005142</td>\n",
              "      <td>97.057503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3634</th>\n",
              "      <td>94.839996</td>\n",
              "      <td>97.254997</td>\n",
              "      <td>93.877502</td>\n",
              "      <td>96.407898</td>\n",
              "      <td>170989200.0</td>\n",
              "      <td>2999.899902</td>\n",
              "      <td>43.369999</td>\n",
              "      <td>36471.679688</td>\n",
              "      <td>5085.279785</td>\n",
              "      <td>12874.969727</td>\n",
              "      <td>26734.710938</td>\n",
              "      <td>6250.700195</td>\n",
              "      <td>1798.699951</td>\n",
              "      <td>1518.000000</td>\n",
              "      <td>24970.689453</td>\n",
              "      <td>203.919998</td>\n",
              "      <td>22770.359375</td>\n",
              "      <td>10473.830078</td>\n",
              "      <td>12350.110352</td>\n",
              "      <td>1467.560059</td>\n",
              "      <td>3215.570068</td>\n",
              "      <td>16024.500000</td>\n",
              "      <td>3210.099121</td>\n",
              "      <td>96.319000</td>\n",
              "      <td>32805.871094</td>\n",
              "      <td>40.750000</td>\n",
              "      <td>96.455002</td>\n",
              "      <td>96.281075</td>\n",
              "      <td>95.823502</td>\n",
              "      <td>94.630669</td>\n",
              "      <td>93.304405</td>\n",
              "      <td>2.483001</td>\n",
              "      <td>0.050724</td>\n",
              "      <td>2.432278</td>\n",
              "      <td>94.976234</td>\n",
              "      <td>96.455002</td>\n",
              "      <td>97.933769</td>\n",
              "      <td>77.234558</td>\n",
              "      <td>43.917648</td>\n",
              "      <td>44.359348</td>\n",
              "      <td>47.152218</td>\n",
              "      <td>2.398363</td>\n",
              "      <td>10.005142</td>\n",
              "      <td>97.057503</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3635 rows × 44 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         O_AAPL     H_AAPL     L_AAPL  ...  C_AAPL_LR  C_AAPL_PERCENTLR     C_AAPL\n",
              "0      9.387143   9.438571   9.296786  ...   0.062933          0.064955   9.392143\n",
              "1      9.347500   9.399286   9.305357  ...   0.058053          0.059772   9.346429\n",
              "2      9.277857   9.338929   9.201071  ...   0.051882          0.053252   9.288929\n",
              "3      9.298095   9.346786   9.224166  ...   0.054008          0.055493   9.308691\n",
              "4      9.318333   9.354643   9.247262  ...   0.056128          0.057733   9.328452\n",
              "...         ...        ...        ...  ...        ...               ...        ...\n",
              "3630  96.621666  98.630005  95.073334  ...   2.383493          9.842714  95.625000\n",
              "3631  97.264999  99.955002  95.257500  ...   2.381950          9.825990  95.477501\n",
              "3632  94.839996  97.254997  93.877502  ...   2.398363         10.005142  97.057503\n",
              "3633  94.839996  97.254997  93.877502  ...   2.398363         10.005142  97.057503\n",
              "3634  94.839996  97.254997  93.877502  ...   2.398363         10.005142  97.057503\n",
              "\n",
              "[3635 rows x 44 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7J2st85d9AKo"
      },
      "source": [
        "Affiche les types :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INH5D4lncQRY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a5f71c8-34ca-4abb-ea3c-5460a83d9264"
      },
      "source": [
        "df_etude.dtypes"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "O_AAPL              float32\n",
              "H_AAPL              float32\n",
              "L_AAPL              float32\n",
              "AdjC_AAPL           float32\n",
              "V_AAPL              float32\n",
              "C_AMNZ              float32\n",
              "C_BRENT             float32\n",
              "C_BSESN             float32\n",
              "C_CAC40             float32\n",
              "C_DAX               float32\n",
              "C_DJI               float32\n",
              "C_FTSE              float32\n",
              "C_GOLD              float32\n",
              "C_GOOG              float32\n",
              "C_HSI               float32\n",
              "C_MSFT              float32\n",
              "C_N225              float32\n",
              "C_NASDAQ            float32\n",
              "C_NYSE              float32\n",
              "C_RUT2000           float32\n",
              "C_SP500             float32\n",
              "C_SPTSX             float32\n",
              "C_SSE               float32\n",
              "C_USD               float32\n",
              "C_W5000             float32\n",
              "C_WTICL             float32\n",
              "C_AAPL_sma5         float32\n",
              "C_AAPL_sma7         float32\n",
              "C_AAPL_sma10        float32\n",
              "C_AAPL_sma15        float32\n",
              "C_AAPL_sma21        float32\n",
              "C_AAPL_macd         float32\n",
              "C_AAPL_macdh        float32\n",
              "C_AAPL_macds        float32\n",
              "C_AAPL_BBl          float32\n",
              "C_AAPL_BBm          float32\n",
              "C_AAPL_BBu          float32\n",
              "C_AAPL_RSI          float32\n",
              "C_AAPL_FOUR3        float32\n",
              "C_AAPL_FOUR6        float32\n",
              "C_AAPL_FOUR9        float32\n",
              "C_AAPL_LR           float32\n",
              "C_AAPL_PERCENTLR    float32\n",
              "C_AAPL              float32\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXCWWy_kBmpZ"
      },
      "source": [
        "**5. Affiche les données**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0rshQNtq2P-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "9878714a-9176-4b80-adc1-f819dcee23c8"
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(go.Scatter(x=np.linspace(0,len(df_etude),len(df_etude)+1),y=df_etude['C_AAPL'], line=dict(color='blue', width=1),name=\"Index\"))\n",
        "fig.update_xaxes(rangeslider_visible=True)\n",
        "yaxis=dict(autorange = True,fixedrange= False)\n",
        "fig.update_yaxes(yaxis)\n",
        "fig.show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"eea200ec-e6a9-4264-9bdd-b80e12d3a95e\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"eea200ec-e6a9-4264-9bdd-b80e12d3a95e\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'eea200ec-e6a9-4264-9bdd-b80e12d3a95e',\n",
              "                        [{\"line\": {\"color\": \"blue\", \"width\": 1}, \"name\": \"Index\", \"type\": \"scatter\", \"x\": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 229.0, 230.0, 231.0, 232.0, 233.0, 234.0, 235.0, 236.0, 237.0, 238.0, 239.0, 240.0, 241.0, 242.0, 243.0, 244.0, 245.0, 246.0, 247.0, 248.0, 249.0, 250.0, 251.0, 252.0, 253.0, 254.0, 255.0, 256.0, 257.0, 258.0, 259.0, 260.0, 261.0, 262.0, 263.0, 264.0, 265.0, 266.0, 267.0, 268.0, 269.0, 270.0, 271.0, 272.0, 273.0, 274.0, 275.0, 276.0, 277.0, 278.0, 279.0, 280.0, 281.0, 282.0, 283.0, 284.0, 285.0, 286.0, 287.0, 288.0, 289.0, 290.0, 291.0, 292.0, 293.0, 294.0, 295.0, 296.0, 297.0, 298.0, 299.0, 300.0, 301.0, 302.0, 303.0, 304.0, 305.0, 306.0, 307.0, 308.0, 309.0, 310.0, 311.0, 312.0, 313.0, 314.0, 315.0, 316.0, 317.0, 318.0, 319.0, 320.0, 321.0, 322.0, 323.0, 324.0, 325.0, 326.0, 327.0, 328.0, 329.0, 330.0, 331.0, 332.0, 333.0, 334.0, 335.0, 336.0, 337.0, 338.0, 339.0, 340.0, 341.0, 342.0, 343.0, 344.0, 345.0, 346.0, 347.0, 348.0, 349.0, 350.0, 351.0, 352.0, 353.0, 354.0, 355.0, 356.0, 357.0, 358.0, 359.0, 360.0, 361.0, 362.0, 363.0, 364.0, 365.0, 366.0, 367.0, 368.0, 369.0, 370.0, 371.0, 372.0, 373.0, 374.0, 375.0, 376.0, 377.0, 378.0, 379.0, 380.0, 381.0, 382.0, 383.0, 384.0, 385.0, 386.0, 387.0, 388.0, 389.0, 390.0, 391.0, 392.0, 393.0, 394.0, 395.0, 396.0, 397.0, 398.0, 399.0, 400.0, 401.0, 402.0, 403.0, 404.0, 405.0, 406.0, 407.0, 408.0, 409.0, 410.0, 411.0, 412.0, 413.0, 414.0, 415.0, 416.0, 417.0, 418.0, 419.0, 420.0, 421.0, 422.0, 423.0, 424.0, 425.0, 426.0, 427.0, 428.0, 429.0, 430.0, 431.0, 432.0, 433.0, 434.0, 435.0, 436.0, 437.0, 438.0, 439.0, 440.0, 441.0, 442.0, 443.0, 444.0, 445.0, 446.0, 447.0, 448.0, 449.0, 450.0, 451.0, 452.0, 453.0, 454.0, 455.0, 456.0, 457.0, 458.0, 459.0, 460.0, 461.0, 462.0, 463.0, 464.0, 465.0, 466.0, 467.0, 468.0, 469.0, 470.0, 471.0, 472.0, 473.0, 474.0, 475.0, 476.0, 477.0, 478.0, 479.0, 480.0, 481.0, 482.0, 483.0, 484.0, 485.0, 486.0, 487.0, 488.0, 489.0, 490.0, 491.0, 492.0, 493.0, 494.0, 495.0, 496.0, 497.0, 498.0, 499.0, 500.0, 501.0, 502.0, 503.0, 504.0, 505.0, 506.0, 507.0, 508.0, 509.0, 510.0, 511.0, 512.0, 513.0, 514.0, 515.0, 516.0, 517.0, 518.0, 519.0, 520.0, 521.0, 522.0, 523.0, 524.0, 525.0, 526.0, 527.0, 528.0, 529.0, 530.0, 531.0, 532.0, 533.0, 534.0, 535.0, 536.0, 537.0, 538.0, 539.0, 540.0, 541.0, 542.0, 543.0, 544.0, 545.0, 546.0, 547.0, 548.0, 549.0, 550.0, 551.0, 552.0, 553.0, 554.0, 555.0, 556.0, 557.0, 558.0, 559.0, 560.0, 561.0, 562.0, 563.0, 564.0, 565.0, 566.0, 567.0, 568.0, 569.0, 570.0, 571.0, 572.0, 573.0, 574.0, 575.0, 576.0, 577.0, 578.0, 579.0, 580.0, 581.0, 582.0, 583.0, 584.0, 585.0, 586.0, 587.0, 588.0, 589.0, 590.0, 591.0, 592.0, 593.0, 594.0, 595.0, 596.0, 597.0, 598.0, 599.0, 600.0, 601.0, 602.0, 603.0, 604.0, 605.0, 606.0, 607.0, 608.0, 609.0, 610.0, 611.0, 612.0, 613.0, 614.0, 615.0, 616.0, 617.0, 618.0, 619.0, 620.0, 621.0, 622.0, 623.0, 624.0, 625.0, 626.0, 627.0, 628.0, 629.0, 630.0, 631.0, 632.0, 633.0, 634.0, 635.0, 636.0, 637.0, 638.0, 639.0, 640.0, 641.0, 642.0, 643.0, 644.0, 645.0, 646.0, 647.0, 648.0, 649.0, 650.0, 651.0, 652.0, 653.0, 654.0, 655.0, 656.0, 657.0, 658.0, 659.0, 660.0, 661.0, 662.0, 663.0, 664.0, 665.0, 666.0, 667.0, 668.0, 669.0, 670.0, 671.0, 672.0, 673.0, 674.0, 675.0, 676.0, 677.0, 678.0, 679.0, 680.0, 681.0, 682.0, 683.0, 684.0, 685.0, 686.0, 687.0, 688.0, 689.0, 690.0, 691.0, 692.0, 693.0, 694.0, 695.0, 696.0, 697.0, 698.0, 699.0, 700.0, 701.0, 702.0, 703.0, 704.0, 705.0, 706.0, 707.0, 708.0, 709.0, 710.0, 711.0, 712.0, 713.0, 714.0, 715.0, 716.0, 717.0, 718.0, 719.0, 720.0, 721.0, 722.0, 723.0, 724.0, 725.0, 726.0, 727.0, 728.0, 729.0, 730.0, 731.0, 732.0, 733.0, 734.0, 735.0, 736.0, 737.0, 738.0, 739.0, 740.0, 741.0, 742.0, 743.0, 744.0, 745.0, 746.0, 747.0, 748.0, 749.0, 750.0, 751.0, 752.0, 753.0, 754.0, 755.0, 756.0, 757.0, 758.0, 759.0, 760.0, 761.0, 762.0, 763.0, 764.0, 765.0, 766.0, 767.0, 768.0, 769.0, 770.0, 771.0, 772.0, 773.0, 774.0, 775.0, 776.0, 777.0, 778.0, 779.0, 780.0, 781.0, 782.0, 783.0, 784.0, 785.0, 786.0, 787.0, 788.0, 789.0, 790.0, 791.0, 792.0, 793.0, 794.0, 795.0, 796.0, 797.0, 798.0, 799.0, 800.0, 801.0, 802.0, 803.0, 804.0, 805.0, 806.0, 807.0, 808.0, 809.0, 810.0, 811.0, 812.0, 813.0, 814.0, 815.0, 816.0, 817.0, 818.0, 819.0, 820.0, 821.0, 822.0, 823.0, 824.0, 825.0, 826.0, 827.0, 828.0, 829.0, 830.0, 831.0, 832.0, 833.0, 834.0, 835.0, 836.0, 837.0, 838.0, 839.0, 840.0, 841.0, 842.0, 843.0, 844.0, 845.0, 846.0, 847.0, 848.0, 849.0, 850.0, 851.0, 852.0, 853.0, 854.0, 855.0, 856.0, 857.0, 858.0, 859.0, 860.0, 861.0, 862.0, 863.0, 864.0, 865.0, 866.0, 867.0, 868.0, 869.0, 870.0, 871.0, 872.0, 873.0, 874.0, 875.0, 876.0, 877.0, 878.0, 879.0, 880.0, 881.0, 882.0, 883.0, 884.0, 885.0, 886.0, 887.0, 888.0, 889.0, 890.0, 891.0, 892.0, 893.0, 894.0, 895.0, 896.0, 897.0, 898.0, 899.0, 900.0, 901.0, 902.0, 903.0, 904.0, 905.0, 906.0, 907.0, 908.0, 909.0, 910.0, 911.0, 912.0, 913.0, 914.0, 915.0, 916.0, 917.0, 918.0, 919.0, 920.0, 921.0, 922.0, 923.0, 924.0, 925.0, 926.0, 927.0, 928.0, 929.0, 930.0, 931.0, 932.0, 933.0, 934.0, 935.0, 936.0, 937.0, 938.0, 939.0, 940.0, 941.0, 942.0, 943.0, 944.0, 945.0, 946.0, 947.0, 948.0, 949.0, 950.0, 951.0, 952.0, 953.0, 954.0, 955.0, 956.0, 957.0, 958.0, 959.0, 960.0, 961.0, 962.0, 963.0, 964.0, 965.0, 966.0, 967.0, 968.0, 969.0, 970.0, 971.0, 972.0, 973.0, 974.0, 975.0, 976.0, 977.0, 978.0, 979.0, 980.0, 981.0, 982.0, 983.0, 984.0, 985.0, 986.0, 987.0, 988.0, 989.0, 990.0, 991.0, 992.0, 993.0, 994.0, 995.0, 996.0, 997.0, 998.0, 999.0, 1000.0, 1001.0, 1002.0, 1003.0, 1004.0, 1005.0, 1006.0, 1007.0, 1008.0, 1009.0, 1010.0, 1011.0, 1012.0, 1013.0, 1014.0, 1015.0, 1016.0, 1017.0, 1018.0, 1019.0, 1020.0, 1021.0, 1022.0, 1023.0, 1024.0, 1025.0, 1026.0, 1027.0, 1028.0, 1029.0, 1030.0, 1031.0, 1032.0, 1033.0, 1034.0, 1035.0, 1036.0, 1037.0, 1038.0, 1039.0, 1040.0, 1041.0, 1042.0, 1043.0, 1044.0, 1045.0, 1046.0, 1047.0, 1048.0, 1049.0, 1050.0, 1051.0, 1052.0, 1053.0, 1054.0, 1055.0, 1056.0, 1057.0, 1058.0, 1059.0, 1060.0, 1061.0, 1062.0, 1063.0, 1064.0, 1065.0, 1066.0, 1067.0, 1068.0, 1069.0, 1070.0, 1071.0, 1072.0, 1073.0, 1074.0, 1075.0, 1076.0, 1077.0, 1078.0, 1079.0, 1080.0, 1081.0, 1082.0, 1083.0, 1084.0, 1085.0, 1086.0, 1087.0, 1088.0, 1089.0, 1090.0, 1091.0, 1092.0, 1093.0, 1094.0, 1095.0, 1096.0, 1097.0, 1098.0, 1099.0, 1100.0, 1101.0, 1102.0, 1103.0, 1104.0, 1105.0, 1106.0, 1107.0, 1108.0, 1109.0, 1110.0, 1111.0, 1112.0, 1113.0, 1114.0, 1115.0, 1116.0, 1117.0, 1118.0, 1119.0, 1120.0, 1121.0, 1122.0, 1123.0, 1124.0, 1125.0, 1126.0, 1127.0, 1128.0, 1129.0, 1130.0, 1131.0, 1132.0, 1133.0, 1134.0, 1135.0, 1136.0, 1137.0, 1138.0, 1139.0, 1140.0, 1141.0, 1142.0, 1143.0, 1144.0, 1145.0, 1146.0, 1147.0, 1148.0, 1149.0, 1150.0, 1151.0, 1152.0, 1153.0, 1154.0, 1155.0, 1156.0, 1157.0, 1158.0, 1159.0, 1160.0, 1161.0, 1162.0, 1163.0, 1164.0, 1165.0, 1166.0, 1167.0, 1168.0, 1169.0, 1170.0, 1171.0, 1172.0, 1173.0, 1174.0, 1175.0, 1176.0, 1177.0, 1178.0, 1179.0, 1180.0, 1181.0, 1182.0, 1183.0, 1184.0, 1185.0, 1186.0, 1187.0, 1188.0, 1189.0, 1190.0, 1191.0, 1192.0, 1193.0, 1194.0, 1195.0, 1196.0, 1197.0, 1198.0, 1199.0, 1200.0, 1201.0, 1202.0, 1203.0, 1204.0, 1205.0, 1206.0, 1207.0, 1208.0, 1209.0, 1210.0, 1211.0, 1212.0, 1213.0, 1214.0, 1215.0, 1216.0, 1217.0, 1218.0, 1219.0, 1220.0, 1221.0, 1222.0, 1223.0, 1224.0, 1225.0, 1226.0, 1227.0, 1228.0, 1229.0, 1230.0, 1231.0, 1232.0, 1233.0, 1234.0, 1235.0, 1236.0, 1237.0, 1238.0, 1239.0, 1240.0, 1241.0, 1242.0, 1243.0, 1244.0, 1245.0, 1246.0, 1247.0, 1248.0, 1249.0, 1250.0, 1251.0, 1252.0, 1253.0, 1254.0, 1255.0, 1256.0, 1257.0, 1258.0, 1259.0, 1260.0, 1261.0, 1262.0, 1263.0, 1264.0, 1265.0, 1266.0, 1267.0, 1268.0, 1269.0, 1270.0, 1271.0, 1272.0, 1273.0, 1274.0, 1275.0, 1276.0, 1277.0, 1278.0, 1279.0, 1280.0, 1281.0, 1282.0, 1283.0, 1284.0, 1285.0, 1286.0, 1287.0, 1288.0, 1289.0, 1290.0, 1291.0, 1292.0, 1293.0, 1294.0, 1295.0, 1296.0, 1297.0, 1298.0, 1299.0, 1300.0, 1301.0, 1302.0, 1303.0, 1304.0, 1305.0, 1306.0, 1307.0, 1308.0, 1309.0, 1310.0, 1311.0, 1312.0, 1313.0, 1314.0, 1315.0, 1316.0, 1317.0, 1318.0, 1319.0, 1320.0, 1321.0, 1322.0, 1323.0, 1324.0, 1325.0, 1326.0, 1327.0, 1328.0, 1329.0, 1330.0, 1331.0, 1332.0, 1333.0, 1334.0, 1335.0, 1336.0, 1337.0, 1338.0, 1339.0, 1340.0, 1341.0, 1342.0, 1343.0, 1344.0, 1345.0, 1346.0, 1347.0, 1348.0, 1349.0, 1350.0, 1351.0, 1352.0, 1353.0, 1354.0, 1355.0, 1356.0, 1357.0, 1358.0, 1359.0, 1360.0, 1361.0, 1362.0, 1363.0, 1364.0, 1365.0, 1366.0, 1367.0, 1368.0, 1369.0, 1370.0, 1371.0, 1372.0, 1373.0, 1374.0, 1375.0, 1376.0, 1377.0, 1378.0, 1379.0, 1380.0, 1381.0, 1382.0, 1383.0, 1384.0, 1385.0, 1386.0, 1387.0, 1388.0, 1389.0, 1390.0, 1391.0, 1392.0, 1393.0, 1394.0, 1395.0, 1396.0, 1397.0, 1398.0, 1399.0, 1400.0, 1401.0, 1402.0, 1403.0, 1404.0, 1405.0, 1406.0, 1407.0, 1408.0, 1409.0, 1410.0, 1411.0, 1412.0, 1413.0, 1414.0, 1415.0, 1416.0, 1417.0, 1418.0, 1419.0, 1420.0, 1421.0, 1422.0, 1423.0, 1424.0, 1425.0, 1426.0, 1427.0, 1428.0, 1429.0, 1430.0, 1431.0, 1432.0, 1433.0, 1434.0, 1435.0, 1436.0, 1437.0, 1438.0, 1439.0, 1440.0, 1441.0, 1442.0, 1443.0, 1444.0, 1445.0, 1446.0, 1447.0, 1448.0, 1449.0, 1450.0, 1451.0, 1452.0, 1453.0, 1454.0, 1455.0, 1456.0, 1457.0, 1458.0, 1459.0, 1460.0, 1461.0, 1462.0, 1463.0, 1464.0, 1465.0, 1466.0, 1467.0, 1468.0, 1469.0, 1470.0, 1471.0, 1472.0, 1473.0, 1474.0, 1475.0, 1476.0, 1477.0, 1478.0, 1479.0, 1480.0, 1481.0, 1482.0, 1483.0, 1484.0, 1485.0, 1486.0, 1487.0, 1488.0, 1489.0, 1490.0, 1491.0, 1492.0, 1493.0, 1494.0, 1495.0, 1496.0, 1497.0, 1498.0, 1499.0, 1500.0, 1501.0, 1502.0, 1503.0, 1504.0, 1505.0, 1506.0, 1507.0, 1508.0, 1509.0, 1510.0, 1511.0, 1512.0, 1513.0, 1514.0, 1515.0, 1516.0, 1517.0, 1518.0, 1519.0, 1520.0, 1521.0, 1522.0, 1523.0, 1524.0, 1525.0, 1526.0, 1527.0, 1528.0, 1529.0, 1530.0, 1531.0, 1532.0, 1533.0, 1534.0, 1535.0, 1536.0, 1537.0, 1538.0, 1539.0, 1540.0, 1541.0, 1542.0, 1543.0, 1544.0, 1545.0, 1546.0, 1547.0, 1548.0, 1549.0, 1550.0, 1551.0, 1552.0, 1553.0, 1554.0, 1555.0, 1556.0, 1557.0, 1558.0, 1559.0, 1560.0, 1561.0, 1562.0, 1563.0, 1564.0, 1565.0, 1566.0, 1567.0, 1568.0, 1569.0, 1570.0, 1571.0, 1572.0, 1573.0, 1574.0, 1575.0, 1576.0, 1577.0, 1578.0, 1579.0, 1580.0, 1581.0, 1582.0, 1583.0, 1584.0, 1585.0, 1586.0, 1587.0, 1588.0, 1589.0, 1590.0, 1591.0, 1592.0, 1593.0, 1594.0, 1595.0, 1596.0, 1597.0, 1598.0, 1599.0, 1600.0, 1601.0, 1602.0, 1603.0, 1604.0, 1605.0, 1606.0, 1607.0, 1608.0, 1609.0, 1610.0, 1611.0, 1612.0, 1613.0, 1614.0, 1615.0, 1616.0, 1617.0, 1618.0, 1619.0, 1620.0, 1621.0, 1622.0, 1623.0, 1624.0, 1625.0, 1626.0, 1627.0, 1628.0, 1629.0, 1630.0, 1631.0, 1632.0, 1633.0, 1634.0, 1635.0, 1636.0, 1637.0, 1638.0, 1639.0, 1640.0, 1641.0, 1642.0, 1643.0, 1644.0, 1645.0, 1646.0, 1647.0, 1648.0, 1649.0, 1650.0, 1651.0, 1652.0, 1653.0, 1654.0, 1655.0, 1656.0, 1657.0, 1658.0, 1659.0, 1660.0, 1661.0, 1662.0, 1663.0, 1664.0, 1665.0, 1666.0, 1667.0, 1668.0, 1669.0, 1670.0, 1671.0, 1672.0, 1673.0, 1674.0, 1675.0, 1676.0, 1677.0, 1678.0, 1679.0, 1680.0, 1681.0, 1682.0, 1683.0, 1684.0, 1685.0, 1686.0, 1687.0, 1688.0, 1689.0, 1690.0, 1691.0, 1692.0, 1693.0, 1694.0, 1695.0, 1696.0, 1697.0, 1698.0, 1699.0, 1700.0, 1701.0, 1702.0, 1703.0, 1704.0, 1705.0, 1706.0, 1707.0, 1708.0, 1709.0, 1710.0, 1711.0, 1712.0, 1713.0, 1714.0, 1715.0, 1716.0, 1717.0, 1718.0, 1719.0, 1720.0, 1721.0, 1722.0, 1723.0, 1724.0, 1725.0, 1726.0, 1727.0, 1728.0, 1729.0, 1730.0, 1731.0, 1732.0, 1733.0, 1734.0, 1735.0, 1736.0, 1737.0, 1738.0, 1739.0, 1740.0, 1741.0, 1742.0, 1743.0, 1744.0, 1745.0, 1746.0, 1747.0, 1748.0, 1749.0, 1750.0, 1751.0, 1752.0, 1753.0, 1754.0, 1755.0, 1756.0, 1757.0, 1758.0, 1759.0, 1760.0, 1761.0, 1762.0, 1763.0, 1764.0, 1765.0, 1766.0, 1767.0, 1768.0, 1769.0, 1770.0, 1771.0, 1772.0, 1773.0, 1774.0, 1775.0, 1776.0, 1777.0, 1778.0, 1779.0, 1780.0, 1781.0, 1782.0, 1783.0, 1784.0, 1785.0, 1786.0, 1787.0, 1788.0, 1789.0, 1790.0, 1791.0, 1792.0, 1793.0, 1794.0, 1795.0, 1796.0, 1797.0, 1798.0, 1799.0, 1800.0, 1801.0, 1802.0, 1803.0, 1804.0, 1805.0, 1806.0, 1807.0, 1808.0, 1809.0, 1810.0, 1811.0, 1812.0, 1813.0, 1814.0, 1815.0, 1816.0, 1817.0, 1818.0, 1819.0, 1820.0, 1821.0, 1822.0, 1823.0, 1824.0, 1825.0, 1826.0, 1827.0, 1828.0, 1829.0, 1830.0, 1831.0, 1832.0, 1833.0, 1834.0, 1835.0, 1836.0, 1837.0, 1838.0, 1839.0, 1840.0, 1841.0, 1842.0, 1843.0, 1844.0, 1845.0, 1846.0, 1847.0, 1848.0, 1849.0, 1850.0, 1851.0, 1852.0, 1853.0, 1854.0, 1855.0, 1856.0, 1857.0, 1858.0, 1859.0, 1860.0, 1861.0, 1862.0, 1863.0, 1864.0, 1865.0, 1866.0, 1867.0, 1868.0, 1869.0, 1870.0, 1871.0, 1872.0, 1873.0, 1874.0, 1875.0, 1876.0, 1877.0, 1878.0, 1879.0, 1880.0, 1881.0, 1882.0, 1883.0, 1884.0, 1885.0, 1886.0, 1887.0, 1888.0, 1889.0, 1890.0, 1891.0, 1892.0, 1893.0, 1894.0, 1895.0, 1896.0, 1897.0, 1898.0, 1899.0, 1900.0, 1901.0, 1902.0, 1903.0, 1904.0, 1905.0, 1906.0, 1907.0, 1908.0, 1909.0, 1910.0, 1911.0, 1912.0, 1913.0, 1914.0, 1915.0, 1916.0, 1917.0, 1918.0, 1919.0, 1920.0, 1921.0, 1922.0, 1923.0, 1924.0, 1925.0, 1926.0, 1927.0, 1928.0, 1929.0, 1930.0, 1931.0, 1932.0, 1933.0, 1934.0, 1935.0, 1936.0, 1937.0, 1938.0, 1939.0, 1940.0, 1941.0, 1942.0, 1943.0, 1944.0, 1945.0, 1946.0, 1947.0, 1948.0, 1949.0, 1950.0, 1951.0, 1952.0, 1953.0, 1954.0, 1955.0, 1956.0, 1957.0, 1958.0, 1959.0, 1960.0, 1961.0, 1962.0, 1963.0, 1964.0, 1965.0, 1966.0, 1967.0, 1968.0, 1969.0, 1970.0, 1971.0, 1972.0, 1973.0, 1974.0, 1975.0, 1976.0, 1977.0, 1978.0, 1979.0, 1980.0, 1981.0, 1982.0, 1983.0, 1984.0, 1985.0, 1986.0, 1987.0, 1988.0, 1989.0, 1990.0, 1991.0, 1992.0, 1993.0, 1994.0, 1995.0, 1996.0, 1997.0, 1998.0, 1999.0, 2000.0, 2001.0, 2002.0, 2003.0, 2004.0, 2005.0, 2006.0, 2007.0, 2008.0, 2009.0, 2010.0, 2011.0, 2012.0, 2013.0, 2014.0, 2015.0, 2016.0, 2017.0, 2018.0, 2019.0, 2020.0, 2021.0, 2022.0, 2023.0, 2024.0, 2025.0, 2026.0, 2027.0, 2028.0, 2029.0, 2030.0, 2031.0, 2032.0, 2033.0, 2034.0, 2035.0, 2036.0, 2037.0, 2038.0, 2039.0, 2040.0, 2041.0, 2042.0, 2043.0, 2044.0, 2045.0, 2046.0, 2047.0, 2048.0, 2049.0, 2050.0, 2051.0, 2052.0, 2053.0, 2054.0, 2055.0, 2056.0, 2057.0, 2058.0, 2059.0, 2060.0, 2061.0, 2062.0, 2063.0, 2064.0, 2065.0, 2066.0, 2067.0, 2068.0, 2069.0, 2070.0, 2071.0, 2072.0, 2073.0, 2074.0, 2075.0, 2076.0, 2077.0, 2078.0, 2079.0, 2080.0, 2081.0, 2082.0, 2083.0, 2084.0, 2085.0, 2086.0, 2087.0, 2088.0, 2089.0, 2090.0, 2091.0, 2092.0, 2093.0, 2094.0, 2095.0, 2096.0, 2097.0, 2098.0, 2099.0, 2100.0, 2101.0, 2102.0, 2103.0, 2104.0, 2105.0, 2106.0, 2107.0, 2108.0, 2109.0, 2110.0, 2111.0, 2112.0, 2113.0, 2114.0, 2115.0, 2116.0, 2117.0, 2118.0, 2119.0, 2120.0, 2121.0, 2122.0, 2123.0, 2124.0, 2125.0, 2126.0, 2127.0, 2128.0, 2129.0, 2130.0, 2131.0, 2132.0, 2133.0, 2134.0, 2135.0, 2136.0, 2137.0, 2138.0, 2139.0, 2140.0, 2141.0, 2142.0, 2143.0, 2144.0, 2145.0, 2146.0, 2147.0, 2148.0, 2149.0, 2150.0, 2151.0, 2152.0, 2153.0, 2154.0, 2155.0, 2156.0, 2157.0, 2158.0, 2159.0, 2160.0, 2161.0, 2162.0, 2163.0, 2164.0, 2165.0, 2166.0, 2167.0, 2168.0, 2169.0, 2170.0, 2171.0, 2172.0, 2173.0, 2174.0, 2175.0, 2176.0, 2177.0, 2178.0, 2179.0, 2180.0, 2181.0, 2182.0, 2183.0, 2184.0, 2185.0, 2186.0, 2187.0, 2188.0, 2189.0, 2190.0, 2191.0, 2192.0, 2193.0, 2194.0, 2195.0, 2196.0, 2197.0, 2198.0, 2199.0, 2200.0, 2201.0, 2202.0, 2203.0, 2204.0, 2205.0, 2206.0, 2207.0, 2208.0, 2209.0, 2210.0, 2211.0, 2212.0, 2213.0, 2214.0, 2215.0, 2216.0, 2217.0, 2218.0, 2219.0, 2220.0, 2221.0, 2222.0, 2223.0, 2224.0, 2225.0, 2226.0, 2227.0, 2228.0, 2229.0, 2230.0, 2231.0, 2232.0, 2233.0, 2234.0, 2235.0, 2236.0, 2237.0, 2238.0, 2239.0, 2240.0, 2241.0, 2242.0, 2243.0, 2244.0, 2245.0, 2246.0, 2247.0, 2248.0, 2249.0, 2250.0, 2251.0, 2252.0, 2253.0, 2254.0, 2255.0, 2256.0, 2257.0, 2258.0, 2259.0, 2260.0, 2261.0, 2262.0, 2263.0, 2264.0, 2265.0, 2266.0, 2267.0, 2268.0, 2269.0, 2270.0, 2271.0, 2272.0, 2273.0, 2274.0, 2275.0, 2276.0, 2277.0, 2278.0, 2279.0, 2280.0, 2281.0, 2282.0, 2283.0, 2284.0, 2285.0, 2286.0, 2287.0, 2288.0, 2289.0, 2290.0, 2291.0, 2292.0, 2293.0, 2294.0, 2295.0, 2296.0, 2297.0, 2298.0, 2299.0, 2300.0, 2301.0, 2302.0, 2303.0, 2304.0, 2305.0, 2306.0, 2307.0, 2308.0, 2309.0, 2310.0, 2311.0, 2312.0, 2313.0, 2314.0, 2315.0, 2316.0, 2317.0, 2318.0, 2319.0, 2320.0, 2321.0, 2322.0, 2323.0, 2324.0, 2325.0, 2326.0, 2327.0, 2328.0, 2329.0, 2330.0, 2331.0, 2332.0, 2333.0, 2334.0, 2335.0, 2336.0, 2337.0, 2338.0, 2339.0, 2340.0, 2341.0, 2342.0, 2343.0, 2344.0, 2345.0, 2346.0, 2347.0, 2348.0, 2349.0, 2350.0, 2351.0, 2352.0, 2353.0, 2354.0, 2355.0, 2356.0, 2357.0, 2358.0, 2359.0, 2360.0, 2361.0, 2362.0, 2363.0, 2364.0, 2365.0, 2366.0, 2367.0, 2368.0, 2369.0, 2370.0, 2371.0, 2372.0, 2373.0, 2374.0, 2375.0, 2376.0, 2377.0, 2378.0, 2379.0, 2380.0, 2381.0, 2382.0, 2383.0, 2384.0, 2385.0, 2386.0, 2387.0, 2388.0, 2389.0, 2390.0, 2391.0, 2392.0, 2393.0, 2394.0, 2395.0, 2396.0, 2397.0, 2398.0, 2399.0, 2400.0, 2401.0, 2402.0, 2403.0, 2404.0, 2405.0, 2406.0, 2407.0, 2408.0, 2409.0, 2410.0, 2411.0, 2412.0, 2413.0, 2414.0, 2415.0, 2416.0, 2417.0, 2418.0, 2419.0, 2420.0, 2421.0, 2422.0, 2423.0, 2424.0, 2425.0, 2426.0, 2427.0, 2428.0, 2429.0, 2430.0, 2431.0, 2432.0, 2433.0, 2434.0, 2435.0, 2436.0, 2437.0, 2438.0, 2439.0, 2440.0, 2441.0, 2442.0, 2443.0, 2444.0, 2445.0, 2446.0, 2447.0, 2448.0, 2449.0, 2450.0, 2451.0, 2452.0, 2453.0, 2454.0, 2455.0, 2456.0, 2457.0, 2458.0, 2459.0, 2460.0, 2461.0, 2462.0, 2463.0, 2464.0, 2465.0, 2466.0, 2467.0, 2468.0, 2469.0, 2470.0, 2471.0, 2472.0, 2473.0, 2474.0, 2475.0, 2476.0, 2477.0, 2478.0, 2479.0, 2480.0, 2481.0, 2482.0, 2483.0, 2484.0, 2485.0, 2486.0, 2487.0, 2488.0, 2489.0, 2490.0, 2491.0, 2492.0, 2493.0, 2494.0, 2495.0, 2496.0, 2497.0, 2498.0, 2499.0, 2500.0, 2501.0, 2502.0, 2503.0, 2504.0, 2505.0, 2506.0, 2507.0, 2508.0, 2509.0, 2510.0, 2511.0, 2512.0, 2513.0, 2514.0, 2515.0, 2516.0, 2517.0, 2518.0, 2519.0, 2520.0, 2521.0, 2522.0, 2523.0, 2524.0, 2525.0, 2526.0, 2527.0, 2528.0, 2529.0, 2530.0, 2531.0, 2532.0, 2533.0, 2534.0, 2535.0, 2536.0, 2537.0, 2538.0, 2539.0, 2540.0, 2541.0, 2542.0, 2543.0, 2544.0, 2545.0, 2546.0, 2547.0, 2548.0, 2549.0, 2550.0, 2551.0, 2552.0, 2553.0, 2554.0, 2555.0, 2556.0, 2557.0, 2558.0, 2559.0, 2560.0, 2561.0, 2562.0, 2563.0, 2564.0, 2565.0, 2566.0, 2567.0, 2568.0, 2569.0, 2570.0, 2571.0, 2572.0, 2573.0, 2574.0, 2575.0, 2576.0, 2577.0, 2578.0, 2579.0, 2580.0, 2581.0, 2582.0, 2583.0, 2584.0, 2585.0, 2586.0, 2587.0, 2588.0, 2589.0, 2590.0, 2591.0, 2592.0, 2593.0, 2594.0, 2595.0, 2596.0, 2597.0, 2598.0, 2599.0, 2600.0, 2601.0, 2602.0, 2603.0, 2604.0, 2605.0, 2606.0, 2607.0, 2608.0, 2609.0, 2610.0, 2611.0, 2612.0, 2613.0, 2614.0, 2615.0, 2616.0, 2617.0, 2618.0, 2619.0, 2620.0, 2621.0, 2622.0, 2623.0, 2624.0, 2625.0, 2626.0, 2627.0, 2628.0, 2629.0, 2630.0, 2631.0, 2632.0, 2633.0, 2634.0, 2635.0, 2636.0, 2637.0, 2638.0, 2639.0, 2640.0, 2641.0, 2642.0, 2643.0, 2644.0, 2645.0, 2646.0, 2647.0, 2648.0, 2649.0, 2650.0, 2651.0, 2652.0, 2653.0, 2654.0, 2655.0, 2656.0, 2657.0, 2658.0, 2659.0, 2660.0, 2661.0, 2662.0, 2663.0, 2664.0, 2665.0, 2666.0, 2667.0, 2668.0, 2669.0, 2670.0, 2671.0, 2672.0, 2673.0, 2674.0, 2675.0, 2676.0, 2677.0, 2678.0, 2679.0, 2680.0, 2681.0, 2682.0, 2683.0, 2684.0, 2685.0, 2686.0, 2687.0, 2688.0, 2689.0, 2690.0, 2691.0, 2692.0, 2693.0, 2694.0, 2695.0, 2696.0, 2697.0, 2698.0, 2699.0, 2700.0, 2701.0, 2702.0, 2703.0, 2704.0, 2705.0, 2706.0, 2707.0, 2708.0, 2709.0, 2710.0, 2711.0, 2712.0, 2713.0, 2714.0, 2715.0, 2716.0, 2717.0, 2718.0, 2719.0, 2720.0, 2721.0, 2722.0, 2723.0, 2724.0, 2725.0, 2726.0, 2727.0, 2728.0, 2729.0, 2730.0, 2731.0, 2732.0, 2733.0, 2734.0, 2735.0, 2736.0, 2737.0, 2738.0, 2739.0, 2740.0, 2741.0, 2742.0, 2743.0, 2744.0, 2745.0, 2746.0, 2747.0, 2748.0, 2749.0, 2750.0, 2751.0, 2752.0, 2753.0, 2754.0, 2755.0, 2756.0, 2757.0, 2758.0, 2759.0, 2760.0, 2761.0, 2762.0, 2763.0, 2764.0, 2765.0, 2766.0, 2767.0, 2768.0, 2769.0, 2770.0, 2771.0, 2772.0, 2773.0, 2774.0, 2775.0, 2776.0, 2777.0, 2778.0, 2779.0, 2780.0, 2781.0, 2782.0, 2783.0, 2784.0, 2785.0, 2786.0, 2787.0, 2788.0, 2789.0, 2790.0, 2791.0, 2792.0, 2793.0, 2794.0, 2795.0, 2796.0, 2797.0, 2798.0, 2799.0, 2800.0, 2801.0, 2802.0, 2803.0, 2804.0, 2805.0, 2806.0, 2807.0, 2808.0, 2809.0, 2810.0, 2811.0, 2812.0, 2813.0, 2814.0, 2815.0, 2816.0, 2817.0, 2818.0, 2819.0, 2820.0, 2821.0, 2822.0, 2823.0, 2824.0, 2825.0, 2826.0, 2827.0, 2828.0, 2829.0, 2830.0, 2831.0, 2832.0, 2833.0, 2834.0, 2835.0, 2836.0, 2837.0, 2838.0, 2839.0, 2840.0, 2841.0, 2842.0, 2843.0, 2844.0, 2845.0, 2846.0, 2847.0, 2848.0, 2849.0, 2850.0, 2851.0, 2852.0, 2853.0, 2854.0, 2855.0, 2856.0, 2857.0, 2858.0, 2859.0, 2860.0, 2861.0, 2862.0, 2863.0, 2864.0, 2865.0, 2866.0, 2867.0, 2868.0, 2869.0, 2870.0, 2871.0, 2872.0, 2873.0, 2874.0, 2875.0, 2876.0, 2877.0, 2878.0, 2879.0, 2880.0, 2881.0, 2882.0, 2883.0, 2884.0, 2885.0, 2886.0, 2887.0, 2888.0, 2889.0, 2890.0, 2891.0, 2892.0, 2893.0, 2894.0, 2895.0, 2896.0, 2897.0, 2898.0, 2899.0, 2900.0, 2901.0, 2902.0, 2903.0, 2904.0, 2905.0, 2906.0, 2907.0, 2908.0, 2909.0, 2910.0, 2911.0, 2912.0, 2913.0, 2914.0, 2915.0, 2916.0, 2917.0, 2918.0, 2919.0, 2920.0, 2921.0, 2922.0, 2923.0, 2924.0, 2925.0, 2926.0, 2927.0, 2928.0, 2929.0, 2930.0, 2931.0, 2932.0, 2933.0, 2934.0, 2935.0, 2936.0, 2937.0, 2938.0, 2939.0, 2940.0, 2941.0, 2942.0, 2943.0, 2944.0, 2945.0, 2946.0, 2947.0, 2948.0, 2949.0, 2950.0, 2951.0, 2952.0, 2953.0, 2954.0, 2955.0, 2956.0, 2957.0, 2958.0, 2959.0, 2960.0, 2961.0, 2962.0, 2963.0, 2964.0, 2965.0, 2966.0, 2967.0, 2968.0, 2969.0, 2970.0, 2971.0, 2972.0, 2973.0, 2974.0, 2975.0, 2976.0, 2977.0, 2978.0, 2979.0, 2980.0, 2981.0, 2982.0, 2983.0, 2984.0, 2985.0, 2986.0, 2987.0, 2988.0, 2989.0, 2990.0, 2991.0, 2992.0, 2993.0, 2994.0, 2995.0, 2996.0, 2997.0, 2998.0, 2999.0, 3000.0, 3001.0, 3002.0, 3003.0, 3004.0, 3005.0, 3006.0, 3007.0, 3008.0, 3009.0, 3010.0, 3011.0, 3012.0, 3013.0, 3014.0, 3015.0, 3016.0, 3017.0, 3018.0, 3019.0, 3020.0, 3021.0, 3022.0, 3023.0, 3024.0, 3025.0, 3026.0, 3027.0, 3028.0, 3029.0, 3030.0, 3031.0, 3032.0, 3033.0, 3034.0, 3035.0, 3036.0, 3037.0, 3038.0, 3039.0, 3040.0, 3041.0, 3042.0, 3043.0, 3044.0, 3045.0, 3046.0, 3047.0, 3048.0, 3049.0, 3050.0, 3051.0, 3052.0, 3053.0, 3054.0, 3055.0, 3056.0, 3057.0, 3058.0, 3059.0, 3060.0, 3061.0, 3062.0, 3063.0, 3064.0, 3065.0, 3066.0, 3067.0, 3068.0, 3069.0, 3070.0, 3071.0, 3072.0, 3073.0, 3074.0, 3075.0, 3076.0, 3077.0, 3078.0, 3079.0, 3080.0, 3081.0, 3082.0, 3083.0, 3084.0, 3085.0, 3086.0, 3087.0, 3088.0, 3089.0, 3090.0, 3091.0, 3092.0, 3093.0, 3094.0, 3095.0, 3096.0, 3097.0, 3098.0, 3099.0, 3100.0, 3101.0, 3102.0, 3103.0, 3104.0, 3105.0, 3106.0, 3107.0, 3108.0, 3109.0, 3110.0, 3111.0, 3112.0, 3113.0, 3114.0, 3115.0, 3116.0, 3117.0, 3118.0, 3119.0, 3120.0, 3121.0, 3122.0, 3123.0, 3124.0, 3125.0, 3126.0, 3127.0, 3128.0, 3129.0, 3130.0, 3131.0, 3132.0, 3133.0, 3134.0, 3135.0, 3136.0, 3137.0, 3138.0, 3139.0, 3140.0, 3141.0, 3142.0, 3143.0, 3144.0, 3145.0, 3146.0, 3147.0, 3148.0, 3149.0, 3150.0, 3151.0, 3152.0, 3153.0, 3154.0, 3155.0, 3156.0, 3157.0, 3158.0, 3159.0, 3160.0, 3161.0, 3162.0, 3163.0, 3164.0, 3165.0, 3166.0, 3167.0, 3168.0, 3169.0, 3170.0, 3171.0, 3172.0, 3173.0, 3174.0, 3175.0, 3176.0, 3177.0, 3178.0, 3179.0, 3180.0, 3181.0, 3182.0, 3183.0, 3184.0, 3185.0, 3186.0, 3187.0, 3188.0, 3189.0, 3190.0, 3191.0, 3192.0, 3193.0, 3194.0, 3195.0, 3196.0, 3197.0, 3198.0, 3199.0, 3200.0, 3201.0, 3202.0, 3203.0, 3204.0, 3205.0, 3206.0, 3207.0, 3208.0, 3209.0, 3210.0, 3211.0, 3212.0, 3213.0, 3214.0, 3215.0, 3216.0, 3217.0, 3218.0, 3219.0, 3220.0, 3221.0, 3222.0, 3223.0, 3224.0, 3225.0, 3226.0, 3227.0, 3228.0, 3229.0, 3230.0, 3231.0, 3232.0, 3233.0, 3234.0, 3235.0, 3236.0, 3237.0, 3238.0, 3239.0, 3240.0, 3241.0, 3242.0, 3243.0, 3244.0, 3245.0, 3246.0, 3247.0, 3248.0, 3249.0, 3250.0, 3251.0, 3252.0, 3253.0, 3254.0, 3255.0, 3256.0, 3257.0, 3258.0, 3259.0, 3260.0, 3261.0, 3262.0, 3263.0, 3264.0, 3265.0, 3266.0, 3267.0, 3268.0, 3269.0, 3270.0, 3271.0, 3272.0, 3273.0, 3274.0, 3275.0, 3276.0, 3277.0, 3278.0, 3279.0, 3280.0, 3281.0, 3282.0, 3283.0, 3284.0, 3285.0, 3286.0, 3287.0, 3288.0, 3289.0, 3290.0, 3291.0, 3292.0, 3293.0, 3294.0, 3295.0, 3296.0, 3297.0, 3298.0, 3299.0, 3300.0, 3301.0, 3302.0, 3303.0, 3304.0, 3305.0, 3306.0, 3307.0, 3308.0, 3309.0, 3310.0, 3311.0, 3312.0, 3313.0, 3314.0, 3315.0, 3316.0, 3317.0, 3318.0, 3319.0, 3320.0, 3321.0, 3322.0, 3323.0, 3324.0, 3325.0, 3326.0, 3327.0, 3328.0, 3329.0, 3330.0, 3331.0, 3332.0, 3333.0, 3334.0, 3335.0, 3336.0, 3337.0, 3338.0, 3339.0, 3340.0, 3341.0, 3342.0, 3343.0, 3344.0, 3345.0, 3346.0, 3347.0, 3348.0, 3349.0, 3350.0, 3351.0, 3352.0, 3353.0, 3354.0, 3355.0, 3356.0, 3357.0, 3358.0, 3359.0, 3360.0, 3361.0, 3362.0, 3363.0, 3364.0, 3365.0, 3366.0, 3367.0, 3368.0, 3369.0, 3370.0, 3371.0, 3372.0, 3373.0, 3374.0, 3375.0, 3376.0, 3377.0, 3378.0, 3379.0, 3380.0, 3381.0, 3382.0, 3383.0, 3384.0, 3385.0, 3386.0, 3387.0, 3388.0, 3389.0, 3390.0, 3391.0, 3392.0, 3393.0, 3394.0, 3395.0, 3396.0, 3397.0, 3398.0, 3399.0, 3400.0, 3401.0, 3402.0, 3403.0, 3404.0, 3405.0, 3406.0, 3407.0, 3408.0, 3409.0, 3410.0, 3411.0, 3412.0, 3413.0, 3414.0, 3415.0, 3416.0, 3417.0, 3418.0, 3419.0, 3420.0, 3421.0, 3422.0, 3423.0, 3424.0, 3425.0, 3426.0, 3427.0, 3428.0, 3429.0, 3430.0, 3431.0, 3432.0, 3433.0, 3434.0, 3435.0, 3436.0, 3437.0, 3438.0, 3439.0, 3440.0, 3441.0, 3442.0, 3443.0, 3444.0, 3445.0, 3446.0, 3447.0, 3448.0, 3449.0, 3450.0, 3451.0, 3452.0, 3453.0, 3454.0, 3455.0, 3456.0, 3457.0, 3458.0, 3459.0, 3460.0, 3461.0, 3462.0, 3463.0, 3464.0, 3465.0, 3466.0, 3467.0, 3468.0, 3469.0, 3470.0, 3471.0, 3472.0, 3473.0, 3474.0, 3475.0, 3476.0, 3477.0, 3478.0, 3479.0, 3480.0, 3481.0, 3482.0, 3483.0, 3484.0, 3485.0, 3486.0, 3487.0, 3488.0, 3489.0, 3490.0, 3491.0, 3492.0, 3493.0, 3494.0, 3495.0, 3496.0, 3497.0, 3498.0, 3499.0, 3500.0, 3501.0, 3502.0, 3503.0, 3504.0, 3505.0, 3506.0, 3507.0, 3508.0, 3509.0, 3510.0, 3511.0, 3512.0, 3513.0, 3514.0, 3515.0, 3516.0, 3517.0, 3518.0, 3519.0, 3520.0, 3521.0, 3522.0, 3523.0, 3524.0, 3525.0, 3526.0, 3527.0, 3528.0, 3529.0, 3530.0, 3531.0, 3532.0, 3533.0, 3534.0, 3535.0, 3536.0, 3537.0, 3538.0, 3539.0, 3540.0, 3541.0, 3542.0, 3543.0, 3544.0, 3545.0, 3546.0, 3547.0, 3548.0, 3549.0, 3550.0, 3551.0, 3552.0, 3553.0, 3554.0, 3555.0, 3556.0, 3557.0, 3558.0, 3559.0, 3560.0, 3561.0, 3562.0, 3563.0, 3564.0, 3565.0, 3566.0, 3567.0, 3568.0, 3569.0, 3570.0, 3571.0, 3572.0, 3573.0, 3574.0, 3575.0, 3576.0, 3577.0, 3578.0, 3579.0, 3580.0, 3581.0, 3582.0, 3583.0, 3584.0, 3585.0, 3586.0, 3587.0, 3588.0, 3589.0, 3590.0, 3591.0, 3592.0, 3593.0, 3594.0, 3595.0, 3596.0, 3597.0, 3598.0, 3599.0, 3600.0, 3601.0, 3602.0, 3603.0, 3604.0, 3605.0, 3606.0, 3607.0, 3608.0, 3609.0, 3610.0, 3611.0, 3612.0, 3613.0, 3614.0, 3615.0, 3616.0, 3617.0, 3618.0, 3619.0, 3620.0, 3621.0, 3622.0, 3623.0, 3624.0, 3625.0, 3626.0, 3627.0, 3628.0, 3629.0, 3630.0, 3631.0, 3632.0, 3633.0, 3634.0, 3635.0], \"y\": [9.392143249511719, 9.346428871154785, 9.288928985595703, 9.308691024780273, 9.328452110290527, 9.348214149475098, 9.264642715454102, 8.935357093811035, 8.992500305175781, 8.896429061889648, 8.879048347473145, 8.861666679382324, 8.84428596496582, 8.998929023742676, 9.038213729858398, 8.924285888671875, 8.915714263916016, 8.869999885559082, 8.824285507202148, 8.778571128845215, 8.568928718566895, 8.674642562866211, 8.581428527832031, 8.62928581237793, 8.639761924743652, 8.650238037109375, 8.660714149475098, 8.682143211364746, 8.940357208251953, 9.006071090698242, 9.241786003112793, 9.233214378356934, 9.22464370727539, 9.216072082519531, 9.207500457763672, 9.390000343322754, 9.395357131958008, 9.407500267028809, 9.450714111328125, 9.493928909301758, 9.537142753601074, 9.57357120513916, 9.650713920593262, 9.8774995803833, 9.834643363952637, 9.928215026855469, 10.021785736083984, 10.115357398986816, 10.134642601013184, 10.276785850524902, 10.318571090698242, 10.4399995803833, 10.426190376281738, 10.41238021850586, 10.398571014404297, 10.244999885559082, 10.263214111328125, 10.133929252624512, 10.09000015258789, 10.04380989074707, 9.99761962890625, 9.95142936706543, 10.319286346435547, 10.328213691711426, 10.329285621643066, 10.5024995803833, 10.51785659790039, 10.53321361541748, 10.54857063293457, 10.662142753601074, 10.71928596496582, 10.796786308288574, 11.240714073181152, 11.279523849487305, 11.318333625793457, 11.35714340209961, 11.053214073181152, 11.090356826782227, 11.054286003112793, 10.981071472167969, 10.997381210327148, 11.013689994812012, 11.029999732971191, 11.001786231994629, 10.993928909301758, 10.901429176330566, 10.749285697937012, 10.787381172180176, 10.825475692749023, 10.863571166992188, 11.04857063293457, 11.171428680419922, 11.366786003112793, 11.326070785522461, 11.343809127807617, 11.361547470092773, 11.37928581237793, 11.28857135772705, 11.358214378356934, 11.308929443359375, 11.001070976257324, 10.989285469055176, 10.977499961853027, 10.965714454650879, 10.771071434020996, 10.73214340209961, 11.01535701751709, 10.954643249511719, 11.03357219696045, 11.112500190734863, 11.191429138183594, 11.026070594787598, 11.242856979370117, 11.246428489685059, 11.25, 11.272261619567871, 11.294524192810059, 11.31678581237793, 11.112500190734863, 11.300000190734863, 11.362500190734863, 11.337142944335938, 11.369404792785645, 11.401667594909668, 11.433929443359375, 11.364643096923828, 11.464642524719238, 11.420000076293945, 11.44857120513916, 11.461785316467285, 11.47499942779541, 11.488213539123535, 11.438928604125977, 11.441429138183594, 11.473214149475098, 11.450357437133789, 11.469405174255371, 11.488451957702637, 11.507499694824219, 11.578571319580078, 11.6128568649292, 11.557143211364746, 11.56678581237793, 11.576428413391113, 11.586071014404297, 11.59571361541748, 11.623929023742676, 11.617500305175781, 11.559286117553711, 11.520000457763672, 11.603452682495117, 11.686904907226562, 11.770357131958008, 11.831786155700684, 11.928570747375488, 11.918929100036621, 12.00428581237793, 12.079643249511719, 12.154999732971191, 12.23035717010498, 12.20142936706543, 12.300713539123535, 12.34571361541748, 12.445713996887207, 12.375802993774414, 12.305892944335938, 12.235981941223145, 12.166070938110352, 12.101428985595703, 11.881428718566895, 11.668571472167969, 11.796309471130371, 11.92404842376709, 12.051786422729492, 12.192856788635254, 12.280357360839844, 12.257499694824219, 12.003570556640625, 12.04190444946289, 12.08023738861084, 12.118571281433105, 12.322500228881836, 12.29714298248291, 12.265713691711426, 12.375, 12.439047813415527, 12.503095626831055, 12.567143440246582, 12.685713768005371, 12.791428565979004, 12.662142753601074, 12.744643211364746, 12.772380828857422, 12.800119400024414, 12.82785701751709, 12.853570938110352, 12.968929290771484, 12.796428680419922, 12.520000457763672, 12.41330337524414, 12.306607246398926, 12.199911117553711, 12.09321403503418, 12.236429214477539, 12.24571418762207, 12.434286117553711, 12.494404792785645, 12.554524421691895, 12.614643096923828, 12.475357055664062, 12.575714111328125, 12.841428756713867, 12.85714340209961, 12.801905632019043, 12.74666690826416, 12.691429138183594, 12.705714225769043, 12.588213920593262, 12.381071090698242, 12.571070671081543, 12.589761734008789, 12.608451843261719, 12.627142906188965, 12.336786270141602, 11.786070823669434, 11.95142936706543, 11.809642791748047, 11.912381172180176, 12.015118598937988, 12.117856979370117, 12.185713768005371, 12.11392879486084, 12.320357322692871, 12.555000305175781, 12.54190444946289, 12.528809547424316, 12.515713691711426, 12.534285545349121, 12.451070785522461, 12.446785926818848, 12.305713653564453, 12.265594482421875, 12.225476264953613, 12.185357093811035, 12.103214263916016, 12.072856903076172, 12.074286460876465, 11.966428756713867, 11.915714263916016, 11.86500072479248, 11.814286231994629, 11.871429443359375, 12.004643440246582, 11.872142791748047, 11.694999694824219, 11.747262001037598, 11.79952335357666, 11.851785659790039, 12.066429138183594, 12.228928565979004, 12.524999618530273, 12.545624732971191, 12.56624984741211, 12.586874961853027, 12.607500076293945, 12.515000343322754, 12.505356788635254, 12.383929252624512, 12.504643440246582, 12.458809852600098, 12.412976264953613, 12.367142677307129, 12.435713768005371, 12.48464298248291, 12.383929252624512, 12.380714416503906, 12.391904830932617, 12.403095245361328, 12.414285659790039, 12.48035717010498, 12.401070594787598, 12.3774995803833, 12.160714149475098, 12.074999809265137, 11.989285469055176, 11.903571128845215, 12.005000114440918, 12.138214111328125, 12.161786079406738, 11.972143173217773, 11.962381362915039, 11.952618598937988, 11.942856788635254, 11.86392879486084, 12.027856826782227, 11.964285850524902, 12.0503568649292, 12.143392562866211, 12.236428260803223, 12.329463958740234, 12.422499656677246, 12.339642524719238, 12.360713958740234, 12.265713691711426, 12.201428413391113, 12.137142181396484, 12.072856903076172, 11.85857105255127, 11.865714073181152, 11.838929176330566, 11.639286041259766, 11.647619247436523, 11.655952453613281, 11.664285659790039, 11.872857093811035, 11.66964340209961, 11.6128568649292, 11.437856674194336, 11.379047393798828, 11.32023811340332, 11.261428833007812, 11.617856979370117, 11.521785736083984, 11.829643249511719, 11.655357360839844, 11.723094940185547, 11.790833473205566, 11.85857105255127, 11.973570823669434, 11.930000305175781, 11.988213539123535, 12.259285926818848, 12.314374923706055, 12.369464874267578, 12.424553871154785, 12.479642868041992, 12.562856674194336, 12.757143020629883, 12.846785545349121, 12.778809547424316, 12.710832595825195, 12.64285659790039, 12.633929252624512, 12.786429405212402, 12.77750015258789, 13.032856941223145, 13.138571739196777, 13.244285583496094, 13.350000381469727, 13.458929061889648, 13.817856788635254, 13.831786155700684, 14.046428680419922, 14.108333587646484, 14.170238494873047, 14.23214340209961, 14.407500267028809, 14.021071434020996, 13.993571281433105, 13.945713996887207, 14.020357131958008, 14.095000267028809, 14.16964340209961, 13.889642715454102, 14.020357131958008, 13.477499961853027, 13.343570709228516, 13.100594520568848, 12.857619285583496, 12.614643096923828, 13.357500076293945, 12.98892879486084, 13.346428871154785, 13.463929176330566, 13.54035758972168, 13.616786003112793, 13.693214416503906, 13.588570594787598, 13.587142944335938, 13.073213577270508, 12.715356826782227, 12.720237731933594, 12.725118637084961, 12.729999542236328, 13.342857360839844, 13.4350004196167, 13.347143173217773, 13.699286460876465, 13.775357246398926, 13.851428985595703, 13.927499771118164, 13.928214073181152, 13.743928909301758, 13.608214378356934, 13.358928680419922, 13.409732818603516, 13.460536003112793, 13.51133918762207, 13.562143325805664, 13.711786270141602, 13.71928596496582, 13.481429100036621, 13.510714530944824, 13.540000915527344, 13.569286346435547, 13.736429214477539, 13.903571128845215, 14.034285545349121, 14.303570747375488, 14.436070442199707, 14.568571090698242, 14.701070785522461, 14.766071319580078, 14.71928596496582, 14.350713729858398, 14.439286231994629, 14.425833702087402, 14.412381172180176, 14.39892864227295, 14.259285926818848, 14.178929328918457, 13.948928833007812, 13.618571281433105, 13.53857135772705, 13.45857048034668, 13.378570556640625, 13.303570747375488, 13.508929252624512, 13.477499961853027, 13.20714282989502, 13.433452606201172, 13.659761428833008, 13.88607120513916, 14.29607105255127, 14.36392879486084, 14.586786270141602, 15.071429252624512, 15.047500610351562, 15.023571968078613, 14.999643325805664, 15.079999923706055, 14.236429214477539, 14.118213653564453, 14.031070709228516, 14.184642791748047, 14.338213920593262, 14.491786003112793, 14.206070899963379, 14.307143211364746, 14.453213691711426, 14.462499618530273, 14.46047592163086, 14.458452224731445, 14.456428527832031, 14.161070823669434, 14.193214416503906, 14.395357131958008, 14.294285774230957, 14.288213729858398, 14.282142639160156, 14.276070594787598, 14.508213996887207, 14.117142677307129, 13.757857322692871, 13.736429214477539, 13.672619819641113, 13.608809471130371, 13.545000076293945, 13.886786460876465, 13.741786003112793, 13.478928565979004, 13.390713691711426, 13.32011890411377, 13.249524116516113, 13.178929328918457, 13.446785926818848, 13.106785774230957, 13.045714378356934, 12.98464298248291, 13.134047508239746, 13.283452033996582, 13.432856559753418, 13.328571319580078, 13.649999618530273, 13.854642868041992, 13.91785717010498, 13.95726203918457, 13.996665954589844, 14.036070823669434, 13.962499618530273, 13.896071434020996, 13.952142715454102, 14.057856559753418, 14.036665916442871, 14.01547622680664, 13.994285583496094, 13.88607120513916, 13.578213691711426, 13.533571243286133, 13.607856750488281, 13.622023582458496, 13.636190414428711, 13.650357246398926, 14.141071319580078, 14.158928871154785, 14.233928680419922, 14.404643058776855, 14.43321418762207, 14.461786270141602, 14.490357398986816, 14.518928527832031, 14.380000114440918, 14.468570709228516, 14.464285850524902, 14.51991081237793, 14.575535774230957, 14.631160736083984, 14.686785697937012, 14.765713691711426, 14.929642677307129, 15.085714340209961, 15.077737808227539, 15.069762229919434, 15.061785697937012, 15.115714073181152, 15.091071128845215, 15.049642562866211, 14.993213653564453, 15.036874771118164, 15.080535888671875, 15.12419605255127, 15.16785717010498, 15.325357437133789, 15.276785850524902, 15.010713577270508, 15.095356941223145, 15.179999351501465, 15.264642715454102, 15.014642715454102, 15.952142715454102, 15.879643440246582, 15.974286079406738, 16.042499542236328, 16.110713958740234, 16.17892837524414, 16.3028564453125, 16.292499542236328, 16.25428581237793, 16.417142868041992, 16.46821403503418, 16.519285202026367, 16.570356369018555, 16.743928909301758, 17.0242862701416, 17.61321449279785, 17.622142791748047, 17.731428146362305, 17.840715408325195, 17.950000762939453, 18.19499969482422, 17.773929595947266, 17.936071395874023, 17.932857513427734, 18.046518325805664, 18.160179138183594, 18.273839950561523, 18.387500762939453, 18.322856903076172, 18.4424991607666, 18.657499313354492, 18.69738006591797, 18.737262725830078, 18.777143478393555, 19.12178611755371, 19.37285614013672, 19.445356369018555, 19.470714569091797, 19.327619552612305, 19.184524536132812, 19.04142951965332, 18.937856674194336, 18.953214645385742, 19.356786727905273, 19.47035789489746, 19.551668167114258, 19.632976531982422, 19.71428680419922, 20.28928565979004, 21.056428909301758, 20.912857055664062, 20.9132137298584, 21.098094940185547, 21.282976150512695, 21.467857360839844, 21.641429901123047, 21.51785659790039, 21.405000686645508, 21.287500381469727, 21.417619705200195, 21.54773712158203, 21.6778564453125, 21.945714950561523, 22.057857513427734, 21.78071403503418, 21.412500381469727, 21.6396427154541, 21.86678695678711, 22.093929290771484, 22.4757137298584, 22.296785354614258, 22.63142967224121, 22.654197692871094, 22.676963806152344, 22.699731826782227, 22.72249984741211, 22.444286346435547, 22.364286422729492, 22.241785049438477, 21.6153564453125, 21.316547393798828, 21.017738342285156, 20.718929290771484, 21.774999618530273, 21.726428985595703, 20.979999542236328, 20.463571548461914, 20.448333740234375, 20.433094024658203, 20.417856216430664, 20.010000228881836, 21.78571319580078, 21.703571319580078, 21.53571319580078, 21.309284210205078, 21.082857131958008, 20.856428146362305, 20.79035758972168, 20.9278564453125, 20.779285430908203, 20.1875, 20.237857818603516, 20.2882137298584, 20.338571548461914, 20.292142868041992, 20.327856063842773, 20.375713348388672, 20.239643096923828, 20.13857078552246, 20.037500381469727, 19.93642807006836, 19.756071090698242, 19.502857208251953, 18.932857513427734, 18.942142486572266, 19.309999465942383, 19.6778564453125, 20.045713424682617, 19.891786575317383, 20.37714385986328, 20.190000534057617, 20.081785202026367, 20.1708927154541, 20.259998321533203, 20.349105834960938, 20.438213348388672, 20.684642791748047, 20.633214950561523, 20.035356521606445, 20.074642181396484, 20.113927841186523, 20.153213500976562, 20.101070404052734, 20.409286499023438, 20.41857147216797, 20.7257137298584, 20.616785049438477, 20.507858276367188, 20.398929595947266, 20.5771427154541, 20.43428611755371, 20.411785125732422, 20.504642486572266, 20.643333435058594, 20.78202247619629, 20.920713424682617, 20.97892951965332, 20.919286727905273, 20.631071090698242, 20.78928565979004, 20.65440559387207, 20.51952362060547, 20.3846435546875, 20.429643630981445, 20.51785659790039, 20.323213577270508, 20.85714340209961, 20.958572387695312, 21.059999465942383, 21.161428451538086, 21.407499313354492, 21.595535278320312, 21.783571243286133, 21.63857078552246, 21.733928680419922, 21.82928466796875, 21.92464256286621, 21.721786499023438, 21.5867862701416, 21.389286041259766, 21.60607147216797, 21.629167556762695, 21.65226173400879, 21.675357818603516, 21.676429748535156, 21.652143478393555, 21.940000534057617, 21.582143783569336, 21.576547622680664, 21.570953369140625, 21.565357208251953, 21.461429595947266, 20.534643173217773, 20.531429290771484, 20.898571014404297, 21.016071319580078, 21.13357162475586, 21.25107192993164, 21.812856674194336, 21.671785354614258, 21.706785202026367, 21.989286422729492, 22.070833206176758, 22.152381896972656, 22.233928680419922, 22.175357818603516, 22.13785743713379, 22.168928146362305, 22.203571319580078, 22.30238151550293, 22.40118980407715, 22.5, 22.56035614013672, 22.52964210510254, 22.726428985595703, 23.146785736083984, 23.34964370727539, 23.552499771118164, 23.75535774230957, 23.430713653564453, 23.888214111328125, 23.66535758972168, 23.68642807006836, 23.834762573242188, 23.983095169067383, 24.13142967224121, 24.100000381469727, 24.052499771118164, 23.70964241027832, 23.75857162475586, 23.845447540283203, 23.932321548461914, 24.019195556640625, 24.10607147216797, 23.936786651611328, 24.15250015258789, 24.301429748535156, 24.090715408325195, 23.880001068115234, 23.669286727905273, 23.592500686645508, 23.921070098876953, 24.39214324951172, 24.68857192993164, 24.789762496948242, 24.890953063964844, 24.992143630981445, 25.068214416503906, 25.075000762939453, 24.953571319580078, 25.00321388244629, 24.892499923706055, 24.781784057617188, 24.671070098876953, 24.05500030517578, 23.75642967224121, 24.332857131958008, 23.825000762939453, 23.73321533203125, 23.641427993774414, 23.54964256286621, 23.618213653564453, 23.980356216430664, 23.814285278320312, 23.306785583496094, 23.13511848449707, 22.96345329284668, 22.791786193847656, 22.70892906188965, 22.8896427154541, 22.43214225769043, 22.489643096923828, 22.549762725830078, 22.609880447387695, 22.670000076293945, 23.206785202026367, 23.021785736083984, 22.59428596496582, 21.780000686645508, 22.067975997924805, 22.355953216552734, 22.64392852783203, 21.90571403503418, 22.02964210510254, 21.769285202026367, 21.571428298950195, 21.509428024291992, 21.44742774963379, 21.38542938232422, 21.323429107666016, 21.261428833007812, 21.30500030517578, 20.600000381469727, 20.693096160888672, 20.786190032958984, 20.87928581237793, 20.816070556640625, 19.928571701049805, 19.20535659790039, 19.537857055664062, 19.487499237060547, 19.437143325805664, 19.38678550720215, 19.389286041259766, 19.174285888671875, 18.77214241027832, 18.845714569091797, 19.298690795898438, 19.751667022705078, 20.20464324951172, 20.032499313354492, 20.060714721679688, 20.235713958740234, 20.41071319580078, 20.625356674194336, 20.84000015258789, 21.054643630981445, 20.885000228881836, 20.819286346435547, 21.04857063293457, 20.902856826782227, 20.9136905670166, 20.924522399902344, 20.93535614013672, 20.566070556640625, 19.24250030517578, 19.544286727905273, 19.04464340209961, 19.00381088256836, 18.962976455688477, 18.922143936157227, 19.335357666015625, 19.25, 18.917499542236328, 18.206785202026367, 18.314403533935547, 18.42202377319336, 18.52964210510254, 19.06785774230957, 18.796785354614258, 18.633214950561523, 18.547500610351562, 18.5575008392334, 18.5674991607666, 18.577499389648438, 18.449462890625, 18.321428298950195, 18.395000457763672, 18.199642181396484, 18.46845245361328, 18.737260818481445, 19.006071090698242, 19.30714225769043, 19.608213424682617, 19.360713958740234, 18.821428298950195, 18.784523010253906, 18.74761962890625, 18.71071434020996, 18.761070251464844, 18.467857360839844, 18.696786880493164, 18.582143783569336, 18.361310958862305, 18.14047622680664, 17.91964340209961, 17.354286193847656, 18.074642181396484, 17.952856063842773, 17.85714340209961, 17.89973258972168, 17.94232177734375, 17.98491096496582, 18.02750015258789, 18.357500076293945, 16.08928680419922, 15.710000038146973, 15.828452110290527, 15.946905136108398, 16.065357208251953, 16.366785049438477, 16.315357208251953, 16.267499923706055, 16.200714111328125, 16.066190719604492, 15.931666374206543, 15.79714298248291, 16.351428985595703, 16.33392906188965, 16.722143173217773, 16.963571548461914, 17.022499084472656, 17.08142852783203, 17.140356063842773, 16.71071434020996, 16.67892837524414, 16.663928985595703, 16.43428611755371, 16.432767868041992, 16.431249618530273, 16.429731369018555, 16.428213119506836, 16.030357360839844, 15.930713653564453, 16.100357055664062, 16.005001068115234, 15.909643173217773, 15.814286231994629, 16.034643173217773, 15.8774995803833, 15.764286041259766, 15.373929023742676, 15.249881744384766, 15.125833511352539, 15.001786231994629, 15.397856712341309, 15.202142715454102, 15.377857208251953, 15.418571472167969, 15.491786003112793, 15.5649995803833, 15.638214111328125, 15.301071166992188, 15.298213958740234, 15.446429252624512, 15.845000267028809, 15.988572120666504, 16.132143020629883, 16.275714874267578, 16.231786727905273, 16.145713806152344, 16.168928146362305, 16.49678611755371, 16.516666412353516, 16.536548614501953, 16.556428909301758, 16.46928596496582, 16.145713806152344, 15.809286117553711, 15.686517715454102, 15.563750267028809, 15.440982818603516, 15.318214416503906, 15.349642753601074, 15.428214073181152, 15.275713920593262, 15.114286422729492, 15.15011978149414, 15.185952186584473, 15.221785545349121, 15.249285697937012, 15.560357093811035, 15.511786460876465, 15.350000381469727, 15.231548309326172, 15.1130952835083, 14.994643211364746, 15.222857475280762, 14.385713577270508, 14.001786231994629, 13.947500228881836, 14.044404983520508, 14.141308784484863, 14.238213539123535, 14.504643440246582, 14.480713844299316, 14.585000038146973, 14.899999618530273, 15.05380916595459, 15.207619667053223, 15.361429214477539, 15.813570976257324, 15.688928604125977, 15.911429405212402, 16.070714950561523, 16.198453903198242, 16.326190948486328, 16.453929901123047, 16.380714416503906, 16.56571388244629, 16.313213348388672, 16.177499771118164, 16.198570251464844, 16.219642639160156, 16.240713119506836, 15.852143287658691, 15.316070556640625, 15.520713806152344, 15.473570823669434, 15.588689804077148, 15.70380973815918, 15.818928718566895, 15.702142715454102, 15.762499809265137, 15.790714263916016, 15.898214340209961, 15.865089416503906, 15.831964492797852, 15.79883861541748, 15.765713691711426, 15.891071319580078, 16.127857208251953, 16.061786651611328, 16.073572158813477, 16.085357666015625, 16.097143173217773, 16.046785354614258, 15.896785736083984, 15.659285545349121, 15.778928756713867, 15.744166374206543, 15.709404945373535, 15.674642562866211, 15.628570556640625, 15.435357093811035, 15.569999694824219, 15.358928680419922, 15.382143020629883, 15.405356407165527, 15.428570747375488, 15.420356750488281, 15.10714340209961, 14.8871431350708, 14.76785659790039, 14.637380599975586, 14.506904602050781, 14.376428604125977, 14.379643440246582, 14.21678638458252, 14.063570976257324, 14.161786079406738, 14.312857627868652, 14.46392822265625, 14.614999771118164, 14.946070671081543, 15.028571128845215, 14.96821403503418, 14.907856941223145, 14.879642486572266, 14.851428031921387, 14.823213577270508, 15.083929061889648, 15.026070594787598, 15.260356903076172, 15.232500076293945, 15.243571281433105, 15.254642486572266, 15.265713691711426, 15.364286422729492, 15.368213653564453, 15.420000076293945, 15.176786422729492, 15.192976951599121, 15.209166526794434, 15.225357055664062, 14.963929176330566, 15.732500076293945, 15.660714149475098, 15.749643325805664, 15.830595970153809, 15.911547660827637, 15.992500305175781, 16.190000534057617, 16.161785125732422, 16.309999465942383, 16.519285202026367, 16.601547241210938, 16.683809280395508, 16.766071319580078, 16.616071701049805, 16.606428146362305, 16.464643478393555, 16.230356216430664, 16.38404655456543, 16.537738800048828, 16.691429138183594, 17.484643936157227, 17.803571701049805, 17.782499313354492, 17.940357208251953, 18.004762649536133, 18.06916618347168, 18.13357162475586, 17.895357131958008, 17.941429138183594, 17.96285629272461, 17.893571853637695, 17.916786193847656, 17.940000534057617, 17.963214874267578, 17.449642181396484, 17.532142639160156, 17.560714721679688, 17.400714874267578, 17.412857055664062, 17.424999237060547, 17.437143325805664, 17.44928550720215, 17.81035614013672, 17.688213348388672, 17.79357147216797, 17.888214111328125, 17.98285675048828, 18.077499389648438, 17.665714263916016, 16.703929901123047, 16.881786346435547, 16.60357093811035, 16.4276180267334, 16.251667022705078, 16.075714111328125, 16.261428833007812, 16.595714569091797, 16.867856979370117, 16.693214416503906, 16.969762802124023, 17.246309280395508, 17.522857666015625, 17.467857360839844, 17.197500228881836, 17.364999771118164, 17.241071701049805, 17.16964340209961, 17.098215103149414, 17.02678680419922, 17.427143096923828, 17.484285354614258, 17.2646427154541, 17.25107192993164, 17.307262420654297, 17.363452911376953, 17.41964340209961, 17.176429748535156, 17.37821388244629, 17.48714256286621, 17.600357055664062, 17.638809204101562, 17.677261352539062, 17.715713500976562, 17.809999465942383, 17.896785736083984, 18.01785659790039, 18.17464256286621, 18.323095321655273, 18.471548080444336, 18.6200008392334, 18.56678581237793, 18.748571395874023, 18.99678611755371, 18.784286499023438, 18.83095359802246, 18.87761878967285, 18.924285888671875, 18.452856063842773, 18.746429443359375, 18.667856216430664, 18.572500228881836, 18.65250015258789, 18.732500076293945, 18.8125, 18.766071319580078, 18.604286193847656, 18.303213119506836, 18.591428756713867, 18.57345199584961, 18.555477142333984, 18.537500381469727, 18.571786880493164, 18.593929290771484, 18.862857818603516, 18.749643325805664, 18.67392921447754, 18.59821319580078, 18.522499084472656, 18.555356979370117, 18.39285659790039, 18.61214256286621, 18.564285278320312, 18.611190795898438, 18.65809440612793, 18.704999923706055, 19.049999237060547, 19.498571395874023, 19.679107666015625, 19.859643936157227, 19.802024841308594, 19.74440574645996, 19.686786651611328, 20.2257137298584, 20.178571701049805, 20.282142639160156, 20.000713348388672, 20.077022552490234, 20.15333366394043, 20.229642868041992, 20.198213577270508, 20.04857063293457, 20.019285202026367, 19.801071166992188, 19.837617874145508, 19.87416648864746, 19.91071319580078, 19.82107162475586, 19.67035675048828, 19.44499969482422, 19.60785675048828, 19.85869026184082, 20.10952377319336, 20.3603572845459, 20.273929595947266, 20.206607818603516, 20.139286041259766, 20.00321388244629, 19.936904907226562, 19.870594024658203, 19.804285049438477, 20.036428451538086, 19.89553451538086, 19.754642486572266, 19.320714950561523, 19.355833053588867, 19.390953063964844, 19.426071166992188, 19.28714370727539, 19.409286499023438, 19.161428451538086, 19.033571243286133, 19.06678581237793, 19.100000381469727, 19.133214950561523, 19.51392936706543, 19.90571403503418, 19.79464340209961, 19.309642791748047, 19.3846435546875, 19.459644317626953, 19.534643173217773, 19.609643936157227, 19.696786880493164, 19.863571166992188, 19.502500534057617, 19.555238723754883, 19.607975006103516, 19.66071319580078, 18.08928680419922, 17.883928298950195, 17.849285125732422, 17.878570556640625, 17.8896427154541, 17.900712966918945, 17.911785125732422, 18.171070098876953, 18.306785583496094, 18.30392837524414, 18.559999465942383, 18.670833587646484, 18.781665802001953, 18.892499923706055, 19.141429901123047, 19.139999389648438, 19.44392967224121, 19.428213119506836, 19.44607162475586, 19.46392822265625, 19.48178482055664, 19.499643325805664, 19.19178581237793, 18.969642639160156, 18.758928298950195, 18.78630828857422, 18.813690185546875, 18.8410701751709, 18.645000457763672, 18.47678565979004, 18.84535789489746, 18.794286727905273, 18.812381744384766, 18.830476760864258, 18.84857177734375, 18.972856521606445, 19.01285743713379, 18.95535659790039, 18.944286346435547, 18.950000762939453, 18.95571517944336, 18.961429595947266, 19.14607048034668, 19.164642333984375, 18.951786041259766, 18.738929748535156, 18.763334274291992, 18.787738800048828, 18.812143325805664, 18.97857093811035, 18.97357177734375, 18.882143020629883, 19.031070709228516, 19.10630989074707, 19.181547164916992, 19.256786346435547, 19.46392822265625, 19.277856826782227, 19.19499969482422, 19.17357063293457, 19.172142028808594, 19.17071533203125, 19.169286727905273, 19.344642639160156, 19.376785278320312, 19.24250030517578, 18.99357032775879, 18.8941650390625, 18.794761657714844, 18.695356369018555, 18.694286346435547, 18.940000534057617, 18.695714950561523, 18.5575008392334, 18.582143783569336, 18.606786727905273, 18.63142967224121, 18.498571395874023, 18.53607177734375, 18.74785614013672, 18.803482055664062, 18.859107971191406, 18.914731979370117, 18.97035789489746, 18.989286422729492, 18.741071701049805, 20.27750015258789, 20.426429748535156, 20.690120697021484, 20.95380973815918, 21.217500686645508, 21.15464210510254, 21.074642181396484, 21.124286651611328, 21.163570404052734, 21.26333236694336, 21.363094329833984, 21.46285629272461, 21.22892951965332, 21.15464210510254, 20.999643325805664, 20.91214370727539, 20.998929977416992, 21.08571434020996, 21.172500610351562, 21.205713272094727, 21.20964241027832, 21.029285430908203, 21.339643478393555, 21.42392921447754, 21.508214950561523, 21.592500686645508, 21.596786499023438, 21.653928756713867, 21.688213348388672, 21.93321418762207, 22.035892486572266, 22.138572692871094, 22.24125099182129, 22.343929290771484, 22.28607177734375, 22.692142486572266, 22.60714340209961, 22.555356979370117, 22.503572463989258, 22.451786041259766, 22.769285202026367, 23.029285430908203, 23.11964225769043, 23.05607032775879, 23.179046630859375, 23.30202293395996, 23.424999237060547, 23.5625, 23.46500015258789, 23.072500228881836, 22.81999969482422, 22.896665573120117, 22.97333335876465, 23.049999237060547, 23.020000457763672, 23.045000076293945, 22.96500015258789, 22.727500915527344, 22.720834732055664, 22.71416664123535, 22.707500457763672, 22.56999969482422, 22.59000015258789, 22.725000381469727, 22.9950008392334, 23.074167251586914, 23.15333366394043, 23.232500076293945, 23.3799991607666, 23.3700008392334, 23.50749969482422, 23.62874984741211, 23.75, 23.87125015258789, 23.99250030517578, 23.837499618530273, 23.84749984741211, 23.760000228881836, 23.80500030517578, 23.907499313354492, 24.010000228881836, 24.112499237060547, 23.829999923706055, 23.69499969482422, 23.272499084472656, 23.607500076293945, 23.566667556762695, 23.525833129882812, 23.485000610351562, 23.68000030517578, 24.297500610351562, 24.25749969482422, 24.417499542236328, 24.529998779296875, 24.642499923706055, 24.7549991607666, 24.594999313354492, 24.537500381469727, 23.899999618530273, 24.032499313354492, 23.987499237060547, 23.9424991607666, 23.897499084472656, 23.780000686645508, 23.739999771118164, 23.6200008392334, 23.684999465942383, 23.789165496826172, 23.893333435058594, 23.997499465942383, 23.99250030517578, 24.309999465942383, 24.375, 24.4950008392334, 24.593334197998047, 24.691667556762695, 24.790000915527344, 25.13249969482422, 25.142499923706055, 25.145000457763672, 25.329999923706055, 25.34833335876465, 25.366666793823242, 25.385000228881836, 25.22249984741211, 25.532499313354492, 25.5625, 25.625, 25.674999237060547, 25.725000381469727, 25.775001525878906, 25.825000762939453, 24.735000610351562, 24.530000686645508, 24.74250030517578, 24.691667556762695, 24.640832901000977, 24.59000015258789, 24.497499465942383, 25.25, 25.357500076293945, 25.415000915527344, 25.412500381469727, 25.40999984741211, 25.407499313354492, 25.21500015258789, 25.395000457763672, 25.447500228881836, 25.239999771118164, 25.248332977294922, 25.25666618347168, 25.264999389648438, 25.65999984741211, 25.4375, 24.467500686645508, 25.1875, 25.134166717529297, 25.080833435058594, 25.02750015258789, 25.1875, 24.795000076293945, 24.975000381469727, 24.905000686645508, 24.905000686645508, 24.905000686645508, 24.905000686645508, 24.6875, 25.200000762939453, 25.2549991607666, 25.1825008392334, 25.105833053588867, 25.02916717529297, 24.952499389648438, 24.6875, 24.385000228881836, 24.065000534057617, 24.417499542236328, 24.59166717529297, 24.765832901000977, 24.940000534057617, 25.61750030517578, 25.747499465942383, 26.207500457763672, 26.30500030517578, 26.295833587646484, 26.286666870117188, 26.27750015258789, 26.684999465942383, 26.834999084472656, 26.7450008392334, 27.0, 27.116666793823242, 27.233333587646484, 27.350000381469727, 27.149999618530273, 27.21500015258789, 27.174999237060547, 27.252500534057617, 27.23750114440918, 27.22249984741211, 27.207500457763672, 27.424999237060547, 27.8125, 28.204999923706055, 28.545000076293945, 28.52916717529297, 28.51333236694336, 28.497499465942383, 28.86750030517578, 28.667499542236328, 29.077499389648438, 29.11750030517578, 29.297500610351562, 29.47749900817871, 29.657499313354492, 29.399999618530273, 29.75, 29.741249084472656, 29.732500076293945, 29.41083335876465, 29.08916664123535, 28.767499923706055, 28.657499313354492, 28.982500076293945, 28.872499465942383, 28.75, 28.53333282470703, 28.316667556762695, 28.100000381469727, 28.530000686645508, 27.987499237060547, 27.905000686645508, 27.4325008392334, 27.3075008392334, 27.1825008392334, 27.0575008392334, 26.6875, 27.352500915527344, 28.162500381469727, 27.94499969482422, 28.04166603088379, 28.138334274291992, 28.235000610351562, 28.135000228881836, 28.002500534057617, 28.25, 28.497499465942383, 28.490833282470703, 28.484167098999023, 28.477500915527344, 28.1299991607666, 27.594999313354492, 27.463748931884766, 27.332500457763672, 27.075834274291992, 26.81916618347168, 26.5625, 26.565000534057617, 26.9375, 27.97249984741211, 28.002500534057617, 27.77250099182129, 27.542499542236328, 27.3125, 27.55500030517578, 27.450000762939453, 26.704999923706055, 26.497499465942383, 26.66812515258789, 26.838748931884766, 27.009374618530273, 27.18000030517578, 27.387500762939453, 28.100000381469727, 28.2450008392334, 28.255001068115234, 28.264999389648438, 28.274999618530273, 27.28499984741211, 28.827499389648438, 29.725000381469727, 29.290000915527344, 29.412500381469727, 29.53499984741211, 29.657499313354492, 29.662500381469727, 29.889999389648438, 29.985000610351562, 29.732500076293945, 29.7983341217041, 29.864166259765625, 29.93000030517578, 30.5049991607666, 31.219999313354492, 31.614999771118164, 31.770000457763672, 31.816875457763672, 31.863750457763672, 31.910625457763672, 31.957500457763672, 32.18000030517578, 32.11249923706055, 32.375, 32.66666793823242, 32.95833206176758, 33.25, 33.04249954223633, 32.1974983215332, 32.60499954223633, 32.1150016784668, 32.16749954223633, 32.220001220703125, 32.272499084472656, 32.34000015258789, 32.1349983215332, 31.602500915527344, 31.649999618530273, 31.69499969482422, 31.739999771118164, 31.78499984741211, 31.127500534057617, 30.559999465942383, 31.112499237060547, 30.897499084472656, 31.010831832885742, 31.12416648864746, 31.237499237060547, 31.760000228881836, 32.11750030517578, 31.875, 31.475000381469727, 31.58416748046875, 31.69333267211914, 31.802499771118164, 31.672500610351562, 30.844999313354492, 31.059999465942383, 30.8125, 31.072500228881836, 31.332500457763672, 31.592500686645508, 31.107500076293945, 31.0625, 31.329999923706055, 31.45687484741211, 31.583749771118164, 31.71062469482422, 31.837499618530273, 31.502500534057617, 31.399999618530273, 31.639999389648438, 31.774999618530273, 31.754165649414062, 31.733333587646484, 31.712499618530273, 31.575000762939453, 31.69499969482422, 31.542499542236328, 31.1875, 31.424999237060547, 31.662500381469727, 31.899999618530273, 31.727500915527344, 32.154998779296875, 32.41749954223633, 32.56999969482422, 32.76749801635742, 32.96500015258789, 33.162498474121094, 32.63999938964844, 32.15999984741211, 31.287500381469727, 32.23749923706055, 32.21666717529297, 32.195831298828125, 32.17499923706055, 31.450000762939453, 31.252500534057617, 31.315000534057617, 31.905000686645508, 31.796667098999023, 31.68833351135254, 31.579999923706055, 31.467500686645508, 31.502500534057617, 32.23749923706055, 32.192501068115234, 32.31083297729492, 32.429168701171875, 32.54750061035156, 32.51750183105469, 32.51499938964844, 32.84749984741211, 33.1349983215332, 32.95249938964844, 32.769996643066406, 32.58749771118164, 32.404998779296875, 33.0099983215332, 32.94499969482422, 32.56999969482422, 32.59166717529297, 32.61333084106445, 32.6349983215332, 32.4900016784668, 32.529998779296875, 32.34000015258789, 32.162498474121094, 32.09166717529297, 32.02083206176758, 31.950000762939453, 31.854999542236328, 32.220001220703125, 32.147499084472656, 31.792499542236328, 31.771665573120117, 31.75083351135254, 31.729999542236328, 31.899999618530273, 31.825000762939453, 31.969999313354492, 31.649999618530273, 31.734167098999023, 31.81833267211914, 31.90250015258789, 31.75749969482422, 32.02750015258789, 31.875, 31.6875, 31.502500534057617, 31.3174991607666, 31.13249969482422, 31.357500076293945, 31.649999618530273, 31.610000610351562, 31.582500457763672, 31.55500030517578, 31.52750015258789, 31.5, 31.422500610351562, 30.642499923706055, 30.017499923706055, 30.81999969482422, 31.018333435058594, 31.21666717529297, 31.415000915527344, 31.40250015258789, 31.704999923706055, 32.127498626708984, 32.404998779296875, 32.60916519165039, 32.81333541870117, 33.01750183105469, 32.6875, 31.30500030517578, 31.290000915527344, 31.125, 30.980833053588867, 30.836666107177734, 30.6924991607666, 30.844999313354492, 30.747499465942383, 30.592500686645508, 30.325000762939453, 30.086668014526367, 29.84833335876465, 29.610000610351562, 28.65999984741211, 28.850000381469727, 28.782499313354492, 28.8799991607666, 29.229999542236328, 29.579999923706055, 29.93000030517578, 28.372499465942383, 28.809999465942383, 28.787500381469727, 28.989999771118164, 29.09000015258789, 29.190000534057617, 29.290000915527344, 29.125, 28.752500534057617, 28.162500381469727, 26.440000534057617, 26.220001220703125, 26.0, 25.780000686645508, 25.934999465942383, 27.422500610351562, 28.229999542236328, 28.322500228881836, 28.27833366394043, 28.234167098999023, 28.190000534057617, 26.93000030517578, 28.084999084472656, 27.592500686645508, 27.3174991607666, 27.50749969482422, 27.697498321533203, 27.88749885559082, 28.077499389648438, 27.537500381469727, 28.142499923706055, 28.552499771118164, 28.644166946411133, 28.73583221435547, 28.827499389648438, 29.06999969482422, 29.102500915527344, 28.479999542236328, 28.362499237060547, 28.509166717529297, 28.655832290649414, 28.802499771118164, 28.350000381469727, 28.579999923706055, 28.75, 28.677499771118164, 28.488332748413086, 28.29916763305664, 28.110000610351562, 27.264999389648438, 27.575000762939453, 27.395000457763672, 27.594999313354492, 27.628332138061523, 27.661666870117188, 27.69499969482422, 27.827499389648438, 27.69499969482422, 27.375, 28.030000686645508, 27.98666763305664, 27.94333267211914, 27.899999618530273, 27.947500228881836, 27.552499771118164, 27.96500015258789, 27.760000228881836, 27.817501068115234, 27.875, 27.9325008392334, 28.4424991607666, 28.440000534057617, 28.875, 29.770000457763672, 29.453332901000977, 29.136667251586914, 28.81999969482422, 28.637500762939453, 29.8174991607666, 30.13249969482422, 29.875, 30.014999389648438, 30.155000686645508, 30.295000076293945, 30.642499923706055, 30.5, 30.229999542236328, 30.264999389648438, 30.224166870117188, 30.183332443237305, 30.142499923706055, 29.1924991607666, 29.02750015258789, 28.93000030517578, 28.084999084472656, 28.238332748413086, 28.391666412353516, 28.545000076293945, 28.422500610351562, 29.322500228881836, 29.69499969482422, 29.825000762939453, 29.695833206176758, 29.566667556762695, 29.4375, 29.719999313354492, 29.50749969482422, 29.479999542236328, 29.452499389648438, 29.49333381652832, 29.53416633605957, 29.575000762939453, 29.334999084472656, 29.06999969482422, 28.799999237060547, 29.75749969482422, 29.69499969482422, 29.63249969482422, 29.56999969482422, 29.5575008392334, 28.905000686645508, 29.042499542236328, 28.295000076293945, 28.23666763305664, 28.178333282470703, 28.1200008392334, 27.622499465942383, 27.834999084472656, 27.2450008392334, 26.50749969482422, 26.615833282470703, 26.724166870117188, 26.832500457763672, 26.8075008392334, 27.15250015258789, 27.00749969482422, 26.931875228881836, 26.856250762939453, 26.780624389648438, 26.704999923706055, 27.184999465942383, 26.829999923706055, 26.315000534057617, 26.32062530517578, 26.326250076293945, 26.33187484741211, 26.337499618530273, 25.677499771118164, 25.174999237060547, 24.112499237060547, 24.239999771118164, 24.370832443237305, 24.501667022705078, 24.63249969482422, 24.989999771118164, 24.34749984741211, 24.8799991607666, 24.282499313354492, 24.253124237060547, 24.223751068115234, 24.19437599182129, 24.165000915527344, 24.197500228881836, 24.075000762939453, 25.354999542236328, 25.190000534057617, 25.024999618530273, 24.860000610351562, 24.997499465942383, 23.354999542236328, 23.522499084472656, 24.334999084472656, 24.259166717529297, 24.183332443237305, 24.107500076293945, 23.6200008392334, 24.087499618530273, 24.149999618530273, 23.5049991607666, 23.587499618530273, 23.670000076293945, 23.752500534057617, 23.747499465942383, 23.5674991607666, 23.424999237060547, 23.497499465942383, 23.663124084472656, 23.828750610351562, 23.994375228881836, 24.15999984741211, 24.530000686645508, 24.065000534057617, 24.010000228881836, 24.079999923706055, 24.149999618530273, 24.219999313354492, 23.672500610351562, 24.024999618530273, 24.190000534057617, 24.227500915527344, 24.20916748046875, 24.190834045410156, 24.172500610351562, 25.13249969482422, 25.1875, 25.375, 25.752500534057617, 25.657501220703125, 25.5625, 25.467500686645508, 25.25749969482422, 25.280000686645508, 25.292499542236328, 25.565000534057617, 25.586666107177734, 25.608333587646484, 25.6299991607666, 26.145000457763672, 26.49250030517578, 26.450000762939453, 26.479999542236328, 26.47916603088379, 26.478334426879883, 26.477500915527344, 26.68000030517578, 26.532499313354492, 26.417499542236328, 26.387500762939453, 26.357500076293945, 26.327499389648438, 26.297500610351562, 26.920000076293945, 27.389999389648438, 27.247499465942383, 27.497499465942383, 27.59166717529297, 27.685832977294922, 27.780000686645508, 27.452499389648438, 27.739999771118164, 27.135000228881836, 27.165000915527344, 27.19499969482422, 27.225000381469727, 27.2549991607666, 27.610000610351562, 28.010000228881836, 28.024999618530273, 27.462499618530273, 27.264999389648438, 27.067501068115234, 26.8700008392334, 26.727500915527344, 26.782499313354492, 26.49250030517578, 26.420000076293945, 26.3700008392334, 26.31999969482422, 26.270000457763672, 26.087499618530273, 24.454999923706055, 23.707500457763672, 23.434999465942383, 23.426666259765625, 23.418333053588867, 23.40999984741211, 23.795000076293945, 23.547500610351562, 23.309999465942383, 23.18000030517578, 23.185832977294922, 23.191667556762695, 23.197500228881836, 23.354999542236328, 23.127500534057617, 22.584999084472656, 22.6299991607666, 22.90999984741211, 23.189998626708984, 23.469999313354492, 23.372499465942383, 23.639999389648438, 23.549999237060547, 23.80500030517578, 23.905834197998047, 24.00666618347168, 24.107500076293945, 24.475000381469727, 24.905000686645508, 25.102500915527344, 25.087499618530273, 25.056875228881836, 25.026248931884766, 24.995624542236328, 24.96500015258789, 24.614999771118164, 24.43000030517578, 24.479999542236328, 24.539165496826172, 24.59833335876465, 24.657499313354492, 24.75749969482422, 24.735000610351562, 24.912500381469727, 24.707500457763672, 24.58333396911621, 24.459165573120117, 24.334999084472656, 24.364999771118164, 24.28499984741211, 24.387500762939453, 23.832500457763672, 23.81333351135254, 23.794166564941406, 23.774999618530273, 23.977500915527344, 23.887500762939453, 24.024999618530273, 23.350000381469727, 23.23666763305664, 23.123332977294922, 23.010000228881836, 23.397499084472656, 23.600000381469727, 23.899999618530273, 23.97249984741211, 23.916250228881836, 23.860000610351562, 23.803749084472656, 23.747499465942383, 23.88249969482422, 23.985000610351562, 24.170000076293945, 24.19499969482422, 24.220001220703125, 24.2450008392334, 24.354999542236328, 24.217500686645508, 24.697500228881836, 24.69499969482422, 24.782499313354492, 24.8700008392334, 24.957500457763672, 24.967500686645508, 24.989999771118164, 24.857500076293945, 24.665000915527344, 24.55500030517578, 24.44499969482422, 24.334999084472656, 24.167499542236328, 25.737499237060547, 26.084999084472656, 26.052499771118164, 26.205833435058594, 26.359167098999023, 26.512500762939453, 26.1200008392334, 26.447500228881836, 26.467500686645508, 26.8700008392334, 26.944168090820312, 27.018333435058594, 27.092500686645508, 27.202499389648438, 27.0, 26.982500076293945, 27.045000076293945, 27.15333366394043, 27.261667251586914, 27.3700008392334, 27.344999313354492, 27.30500030517578, 27.270000457763672, 27.34000015258789, 27.269166946411133, 27.198333740234375, 27.127500534057617, 27.212499618530273, 27.00749969482422, 26.892499923706055, 26.735000610351562, 26.725000381469727, 26.71500015258789, 26.704999923706055, 26.5, 26.524999618530273, 26.6825008392334, 26.9325008392334, 26.930625915527344, 26.928749084472656, 26.9268741607666, 26.924999237060547, 27.09000015258789, 26.3799991607666, 25.782499313354492, 25.975000381469727, 26.167499542236328, 26.360000610351562, 26.987499237060547, 27.9424991607666, 28.892499923706055, 28.729999542236328, 28.61833381652832, 28.50666618347168, 28.395000457763672, 28.392499923706055, 28.387500762939453, 28.655000686645508, 28.177499771118164, 28.191665649414062, 28.205833435058594, 28.219999313354492, 28.272499084472656, 28.487499237060547, 28.045000076293945, 28.262500762939453, 28.218334197998047, 28.174165725708008, 28.1299991607666, 28.25, 28.262500762939453, 28.47249984741211, 28.514999389648438, 28.68083381652832, 28.84666633605957, 29.012500762939453, 29.075000762939453, 29.334999084472656, 29.2450008392334, 29.407499313354492, 29.400833129882812, 29.394166946411133, 29.387500762939453, 29.36750030517578, 29.280000686645508, 29.264999389648438, 29.149999618530273, 29.237499237060547, 29.325000762939453, 29.412500381469727, 29.5625, 28.897499084472656, 28.6200008392334, 28.43000030517578, 28.415000915527344, 28.399999618530273, 28.385000228881836, 27.872499465942383, 27.897499084472656, 27.457500457763672, 27.209999084472656, 27.34083366394043, 27.47166633605957, 27.602500915527344, 27.764999389648438, 27.719999313354492, 26.947500228881836, 27.107500076293945, 26.88083267211914, 26.65416717529297, 26.427499771118164, 26.77750015258789, 27.497499465942383, 27.487499237060547, 27.514999389648438, 27.65416717529297, 27.793333053588867, 27.9325008392334, 27.950000762939453, 27.8075008392334, 27.877500534057617, 27.947500228881836, 27.929166793823242, 27.91083335876465, 27.892499923706055, 27.864999771118164, 27.6299991607666, 27.372499465942383, 27.475000381469727, 27.40916633605957, 27.343334197998047, 27.27750015258789, 27.487499237060547, 27.75749969482422, 28.030000686645508, 28.487499237060547, 28.433332443237305, 28.379167556762695, 28.325000762939453, 28.797500610351562, 28.797500610351562, 28.954999923706055, 28.99250030517578, 29.0483341217041, 29.10416603088379, 29.15999984741211, 29.237499237060547, 29.264999389648438, 29.072500228881836, 29.1299991607666, 29.176250457763672, 29.22249984741211, 29.268749237060547, 29.315000534057617, 29.190000534057617, 29.1825008392334, 28.954999923706055, 28.975624084472656, 28.99625015258789, 29.016876220703125, 29.037500381469727, 29.0049991607666, 29.15250015258789, 29.477500915527344, 29.567501068115234, 29.657499313354492, 29.747499465942383, 29.77750015258789, 29.9375, 29.8125, 29.760000228881836, 29.81999969482422, 29.880001068115234, 29.940000534057617, 30.0, 29.997499465942383, 29.94499969482422, 30.0, 30.00666618347168, 30.013334274291992, 30.020000457763672, 29.99250030517578, 30.469999313354492, 30.485000610351562, 30.487499237060547, 30.460832595825195, 30.434165954589844, 30.407499313354492, 30.337499618530273, 32.1875, 32.13249969482422, 32.27000045776367, 32.37083435058594, 32.47166442871094, 32.5724983215332, 32.88249969482422, 33.0099983215332, 33.10499954223633, 33.029998779296875, 33.127498626708984, 33.224998474121094, 33.3224983215332, 33.755001068115234, 33.877498626708984, 33.837501525878906, 33.93000030517578, 33.991249084472656, 34.05249786376953, 34.11375045776367, 34.17499923706055, 34.27750015258789, 34.13249969482422, 34.165000915527344, 34.1875, 34.209999084472656, 34.23249816894531, 34.247501373291016, 34.9474983215332, 34.7400016784668, 34.94499969482422, 34.90833282470703, 34.871665954589844, 34.834999084472656, 34.880001068115234, 34.75, 34.66999816894531, 34.78499984741211, 34.790000915527344, 34.79499816894531, 34.79999923706055, 34.747501373291016, 35.1150016784668, 35.17250061035156, 34.997501373291016, 35.12000274658203, 35.24250030517578, 35.3650016784668, 34.959999084472656, 35.35499954223633, 35.22999954223633, 35.15999984741211, 35.18000030517578, 35.20000076293945, 35.220001220703125, 35.95000076293945, 36.029998779296875, 35.98249816894531, 35.915000915527344, 35.9183349609375, 35.92166519165039, 35.92499923706055, 36.192501068115234, 36.005001068115234, 35.915000915527344, 35.834999084472656, 35.820831298828125, 35.80666732788086, 35.79249954223633, 35.407501220703125, 35.45000076293945, 35.26250076293945, 35.311248779296875, 35.36000061035156, 35.40875244140625, 35.45750045776367, 35.29999923706055, 35.16999816894531, 35.61000061035156, 35.567501068115234, 35.68166732788086, 35.795833587646484, 35.90999984741211, 36.13249969482422, 35.91999816894531, 35.9474983215332, 35.912498474121094, 36.15666580200195, 36.40083312988281, 36.64500045776367, 36.877498626708984, 36.76499938964844, 36.63249969482422, 37.2400016784668, 37.57749938964844, 37.915000915527344, 38.252498626708984, 38.497501373291016, 38.314998626708984, 38.48749923706055, 39.025001525878906, 38.991668701171875, 38.95833206176758, 38.92499923706055, 38.86750030517578, 37.5625, 38.1349983215332, 38.26499938964844, 38.342498779296875, 38.42000198364258, 38.497501373291016, 38.45000076293945, 38.334999084472656, 38.467498779296875, 38.40250015258789, 38.40625, 38.40999984741211, 38.41374969482422, 38.41749954223633, 38.189998626708984, 38.29499816894531, 38.86249923706055, 38.73583221435547, 38.60916519165039, 38.48249816894531, 38.61249923706055, 38.842498779296875, 38.747501373291016, 37.244998931884766, 36.948333740234375, 36.65166473388672, 36.35499954223633, 36.647499084472656, 36.290000915527344, 36.0724983215332, 35.567501068115234, 35.90666580200195, 36.24583435058594, 36.584999084472656, 36.252498626708984, 36.467498779296875, 36.407501220703125, 36.56999969482422, 36.53166580200195, 36.49333572387695, 36.45500183105469, 35.932498931884766, 36.45750045776367, 35.91999816894531, 36.005001068115234, 35.961666107177734, 35.9183349609375, 35.875, 35.94874954223633, 36.022499084472656, 35.682498931884766, 36.04499816894531, 36.11833190917969, 36.19166564941406, 36.26499938964844, 36.38249969482422, 36.435001373291016, 36.942501068115234, 37.2599983215332, 37.3033332824707, 37.34666442871094, 37.38999938964844, 37.52000045776367, 37.755001068115234, 37.584999084472656, 37.567501068115234, 37.71916580200195, 37.87083435058594, 38.022499084472656, 38.185001373291016, 38.3650016784668, 37.63999938964844, 37.375, 37.31083297729492, 37.246665954589844, 37.182498931884766, 37.51250076293945, 39.28499984741211, 38.89250183105469, 39.09749984741211, 39.29916763305664, 39.500831604003906, 39.70249938964844, 40.02000045776367, 40.26499938964844, 38.83000183105469, 39.369998931884766, 39.567501068115234, 39.76499938964844, 39.962501525878906, 40.400001525878906, 40.23749923706055, 39.46500015258789, 39.375, 39.350833892822266, 39.32666778564453, 39.3025016784668, 39.94499969482422, 39.994998931884766, 39.817501068115234, 39.96500015258789, 40.09916687011719, 40.233333587646484, 40.36750030517578, 40.727500915527344, 40.837501525878906, 41.0, 41.01250076293945, 40.889373779296875, 40.76625061035156, 40.64312744140625, 40.52000045776367, 40.477500915527344, 40.314998626708984, 39.657501220703125, 39.89666748046875, 40.135833740234375, 40.375, 40.21500015258789, 39.912498474121094, 39.56999969482422, 39.970001220703125, 39.86916732788086, 39.768333435058594, 39.66749954223633, 39.682498931884766, 39.01750183105469, 38.34749984741211, 37.97249984741211, 37.86083221435547, 37.749168395996094, 37.63750076293945, 38.28499984741211, 38.557498931884766, 38.31999969482422, 38.529998779296875, 38.50416564941406, 38.47833251953125, 38.45249938964844, 38.619998931884766, 38.369998931884766, 38.84749984741211, 38.82500076293945, 38.869998931884766, 38.915000915527344, 38.959999084472656, 38.974998474121094, 39.13750076293945, 39.0, 39.247501373291016, 39.48833465576172, 39.72916793823242, 39.970001220703125, 40.11750030517578, 39.939998626708984, 38.994998931884766, 39.0625, 39.05583190917969, 39.04916763305664, 39.04249954223633, 39.275001525878906, 39.102500915527344, 39.352500915527344, 40.76250076293945, 41.06833267211914, 41.374168395996094, 41.68000030517578, 42.2599983215332, 41.72249984741211, 42.02750015258789, 43.125, 43.27083206176758, 43.41666793823242, 43.5625, 43.70249938964844, 44.060001373291016, 43.970001220703125, 43.66749954223633, 43.60916519165039, 43.55083465576172, 43.49250030517578, 42.834999084472656, 42.27000045776367, 42.775001525878906, 42.537498474121094, 42.52333068847656, 42.5091667175293, 42.494998931884766, 43.28499984741211, 43.7400016784668, 43.741249084472656, 43.74250030517578, 43.669166564941406, 43.59583282470703, 43.522499084472656, 43.26750183105469, 42.369998931884766, 42.962501525878906, 42.76250076293945, 42.65833282470703, 42.554168701171875, 42.45000076293945, 42.40999984741211, 42.252498626708984, 42.33000183105469, 42.342498779296875, 42.61750030517578, 42.89249801635742, 43.16749954223633, 42.92499923706055, 43.067501068115234, 43.05500030517578, 43.49250030517578, 43.6966667175293, 43.90083312988281, 44.10499954223633, 43.6349983215332, 43.587501525878906, 43.752498626708984, 43.752498626708984, 43.474998474121094, 43.19750213623047, 42.92000198364258, 42.64250183105469, 42.650001525878906, 42.77000045776367, 42.307498931884766, 42.49687194824219, 42.686248779296875, 42.87562561035156, 43.064998626708984, 43.057498931884766, 43.25749969482422, 43.75, 43.69583511352539, 43.641666412353516, 43.587501525878906, 43.58250045776367, 43.5724983215332, 43.81999969482422, 44.272499084472656, 44.21624755859375, 44.15999984741211, 44.10375213623047, 44.04750061035156, 44.775001525878906, 44.814998626708984, 44.6150016784668, 44.49333572387695, 44.371665954589844, 44.25, 44.2599983215332, 43.55500030517578, 42.77750015258789, 42.877498626708984, 42.5816650390625, 42.28583526611328, 41.9900016784668, 41.74250030517578, 41.85749816894531, 41.94499969482422, 40.125, 39.79083251953125, 39.456668853759766, 39.122501373291016, 40.75749969482422, 39.8849983215332, 38.787498474121094, 39.102500915527344, 39.62750244140625, 40.15250015258789, 40.6775016784668, 41.084999084472656, 41.842498779296875, 43.247501373291016, 43.10749816894531, 43.071250915527344, 43.03499984741211, 42.998748779296875, 42.962501525878906, 42.76750183105469, 43.125, 43.875, 44.16416549682617, 44.45333480834961, 44.74250030517578, 44.59749984741211, 44.529998779296875, 43.75, 44.0525016784668, 44.103336334228516, 44.15416717529297, 44.20500183105469, 44.16749954223633, 43.75749969482422, 44.23500061035156, 44.994998931884766, 45.13999938964844, 45.28499984741211, 45.43000030517578, 44.99250030517578, 44.61000061035156, 44.662498474121094, 44.505001068115234, 44.27833557128906, 44.051666259765625, 43.82500076293945, 43.810001373291016, 42.817501068115234, 42.212501525878906, 41.23500061035156, 41.88750076293945, 42.540000915527344, 43.192501068115234, 42.084999084472656, 41.619998931884766, 41.94499969482422, 41.876251220703125, 41.807498931884766, 41.738746643066406, 41.66999816894531, 42.09749984741211, 42.90250015258789, 43.20000076293945, 42.095001220703125, 42.234169006347656, 42.37333297729492, 42.51250076293945, 43.3125, 43.11000061035156, 43.53499984741211, 43.682498931884766, 43.77333450317383, 43.864166259765625, 43.95500183105469, 44.560001373291016, 44.459999084472656, 43.20000076293945, 41.43000030517578, 41.38999938964844, 41.35000228881836, 41.310001373291016, 40.73500061035156, 40.912498474121094, 41.05500030517578, 40.58000183105469, 40.82500076293945, 41.06999969482422, 41.314998626708984, 42.275001525878906, 44.14250183105469, 44.22249984741211, 45.95750045776367, 46.06833267211914, 46.179168701171875, 46.290000915527344, 46.51250076293945, 46.84000015258789, 47.5099983215332, 47.147499084472656, 47.11083221435547, 47.07416534423828, 47.037498474121094, 46.61000061035156, 47.04499816894531, 46.747501373291016, 46.57749938964844, 46.6875, 46.79750061035156, 46.907501220703125, 46.790000915527344, 47.09000015258789, 47.037498474121094, 47.14500045776367, 47.102500915527344, 47.05999755859375, 47.01749801635742, 46.974998474121094, 46.875, 46.717498779296875, 47.560001373291016, 47.692501068115234, 47.82500076293945, 47.95750045776367, 48.32749938964844, 48.494998931884766, 48.3650016784668, 47.92499923706055, 47.885833740234375, 47.84666442871094, 47.807498931884766, 48.06999969482422, 47.67499923706055, 47.70000076293945, 47.209999084472656, 47.20166778564453, 47.19333267211914, 47.185001373291016, 46.42250061035156, 46.625, 46.3650016784668, 46.22999954223633, 46.000831604003906, 45.77166748046875, 45.54249954223633, 46.10749816894531, 46.040000915527344, 46.375, 46.27750015258789, 46.45000076293945, 46.62249755859375, 46.79499816894531, 45.97999954223633, 46.165000915527344, 46.349998474121094, 46.99250030517578, 47.209999084472656, 47.4275016784668, 47.64500045776367, 47.587501525878906, 46.970001220703125, 47.75749969482422, 47.83250045776367, 47.79750061035156, 47.76250076293945, 47.727500915527344, 47.86249923706055, 47.599998474121094, 47.970001220703125, 47.86000061035156, 47.874168395996094, 47.88833236694336, 47.90250015258789, 48.25, 48.70500183105469, 48.5525016784668, 47.744998931884766, 47.65583419799805, 47.56666564941406, 47.477500915527344, 47.5724983215332, 50.375, 51.84749984741211, 51.997501373291016, 52.087501525878906, 52.1775016784668, 52.26750183105469, 51.77750015258789, 51.8125, 52.220001220703125, 51.88249969482422, 51.99416732788086, 52.105831146240234, 52.217498779296875, 52.4375, 52.560001373291016, 53.33000183105469, 54.39500045776367, 54.21833419799805, 54.04166793823242, 53.8650016784668, 53.7599983215332, 53.76250076293945, 53.872501373291016, 54.040000915527344, 54.18833541870117, 54.336666107177734, 54.48500061035156, 54.92499923706055, 55.744998931884766, 56.25749969482422, 56.907501220703125, 56.953125, 56.998748779296875, 57.044376373291016, 57.09000015258789, 56.717498779296875, 55.775001525878906, 55.32500076293945, 55.07749938964844, 54.83000183105469, 54.58250045776367, 55.962501525878906, 55.26750183105469, 56.602500915527344, 55.959999084472656, 55.46333312988281, 54.96666717529297, 54.470001220703125, 54.560001373291016, 54.592498779296875, 55.00749969482422, 54.415000915527344, 54.67583465576172, 54.93666458129883, 55.1974983215332, 55.54750061035156, 55.10499954223633, 56.23749923706055, 56.435001373291016, 56.561668395996094, 56.688331604003906, 56.814998626708984, 57.31999969482422, 58.01750183105469, 56.997501373291016, 56.0724983215332, 56.02916717529297, 55.98583221435547, 55.942501068115234, 56.717498779296875, 54.09000015258789, 53.61249923706055, 55.52750015258789, 55.13166809082031, 54.73583221435547, 54.34000015258789, 55.537498474121094, 55.29750061035156, 54.005001068115234, 54.82749938964844, 54.93916702270508, 55.05083084106445, 55.162498474121094, 55.682498931884766, 53.772499084472656, 54.95000076293945, 54.07500076293945, 53.73666763305664, 53.39833450317383, 53.060001373291016, 53.32500076293945, 54.71500015258789, 55.55500030517578, 51.869998931884766, 51.37916564941406, 50.88833236694336, 50.397499084472656, 50.942501068115234, 52.48749923706055, 52.122501373291016, 51.11750030517578, 50.2591667175293, 49.40083312988281, 48.54249954223633, 48.057498931884766, 46.70000076293945, 47.852500915527344, 48.38249969482422, 47.74333190917969, 47.10416793823242, 46.46500015258789, 44.244998931884766, 44.19499969482422, 43.633750915527344, 43.0724983215332, 43.266666412353516, 43.46083068847656, 43.654998779296875, 43.560001373291016, 45.23500061035156, 44.88750076293945, 44.64500045776367, 45.165000915527344, 45.685001373291016, 46.20500183105469, 44.17250061035156, 43.92625045776367, 43.68000030517578, 42.122501373291016, 42.21500015258789, 42.30750274658203, 42.400001525878906, 42.157501220703125, 42.275001525878906, 42.73749923706055, 41.369998931884766, 41.24166488647461, 41.11333465576172, 40.98500061035156, 41.51750183105469, 40.22249984741211, 39.20750045776367, 37.682498931884766, 37.35749816894531, 37.032501220703125, 36.70750045776367, 38.0, 39.29249954223633, 39.037498474121094, 39.057498931884766, 39.18333435058594, 39.309165954589844, 39.435001373291016, 39.45750045776367, 39.47999954223633, 35.54750061035156, 37.064998626708984, 37.037498474121094, 37.0099983215332, 36.98249816894531, 37.6875, 38.32749938964844, 38.45000076293945, 38.0724983215332, 37.88166427612305, 37.690834045410156, 37.5, 38.26750183105469, 38.73500061035156, 38.96500015258789, 39.20500183105469, 38.98500061035156, 38.76499938964844, 38.54500198364258, 38.32500076293945, 38.47999954223633, 38.17499923706055, 39.439998626708984, 39.31833267211914, 39.1966667175293, 39.07500076293945, 38.66999816894531, 41.3125, 41.61000061035156, 41.630001068115234, 42.024166107177734, 42.4183349609375, 42.8125, 43.54499816894531, 43.560001373291016, 42.73500061035156, 42.602500915527344, 42.52083206176758, 42.43916702270508, 42.35749816894531, 42.72249984741211, 42.54499816894531, 42.70000076293945, 42.60499954223633, 42.63687515258789, 42.66874694824219, 42.70062255859375, 42.73249816894531, 43.00749969482422, 42.76499938964844, 43.24250030517578, 43.34749984741211, 43.45249938964844, 43.557498931884766, 43.58250045776367, 43.717498779296875, 43.287498474121094, 43.74250030517578, 43.815834045410156, 43.88916778564453, 43.962501525878906, 43.88249969482422, 43.630001068115234, 43.125, 43.227500915527344, 43.72666549682617, 44.225833892822266, 44.724998474121094, 45.227500915527344, 45.4275016784668, 45.932498931884766, 46.529998779296875, 46.688331604003906, 46.8466682434082, 47.005001068115234, 46.63249969482422, 47.040000915527344, 48.772499084472656, 47.76250076293945, 47.56999969482422, 47.37750244140625, 47.185001373291016, 46.6974983215332, 47.11750030517578, 47.18000030517578, 47.48749923706055, 47.595001220703125, 47.70249938964844, 47.810001373291016, 48.505001068115234, 48.837501525878906, 48.92250061035156, 49.25, 49.50833511352539, 49.766666412353516, 50.025001525878906, 49.875, 50.154998779296875, 49.73749923706055, 49.717498779296875, 49.74749755859375, 49.77750015258789, 49.807498931884766, 49.8125, 50.782501220703125, 50.96500015258789, 51.006874084472656, 51.04875183105469, 51.09062576293945, 51.13249969482422, 51.869998931884766, 51.790000915527344, 51.31999969482422, 51.07500076293945, 51.100833892822266, 51.12666702270508, 51.15250015258789, 50.16749954223633, 52.630001068115234, 52.287498474121094, 52.9375, 52.665000915527344, 52.39249801635742, 52.119998931884766, 50.71500015258789, 50.724998474121094, 50.18000030517578, 49.29499816894531, 48.34000015258789, 47.3849983215332, 46.43000030517578, 47.165000915527344, 47.72999954223633, 47.52000045776367, 47.25, 46.75749969482422, 46.26499938964844, 45.772499084472656, 46.650001525878906, 45.69499969482422, 44.915000915527344, 44.74250030517578, 44.696250915527344, 44.650001525878906, 44.6037483215332, 44.557498931884766, 44.345001220703125, 44.57500076293945, 43.76750183105469, 43.62000274658203, 43.47249984741211, 43.32500076293945, 44.90999984741211, 45.6349983215332, 46.30500030517578, 47.537498474121094, 47.73999786376953, 47.942501068115234, 48.14500045776367, 48.70249938964844, 48.54750061035156, 48.537498474121094, 48.185001373291016, 48.28083419799805, 48.37666702270508, 48.47249984741211, 49.61249923706055, 49.467498779296875, 49.8650016784668, 49.69499969482422, 49.6783332824707, 49.66166687011719, 49.64500045776367, 48.89250183105469, 49.95000076293945, 49.935001373291016, 49.47999954223633, 49.782501220703125, 50.084999084472656, 50.38750076293945, 50.682498931884766, 51.102500915527344, 51.08000183105469, 51.057498931884766, 50.7066650390625, 50.3558349609375, 50.005001068115234, 50.310001373291016, 50.807498931884766, 50.4375, 50.82500076293945, 50.984169006347656, 51.143333435058594, 51.3025016784668, 51.125, 50.837501525878906, 51.415000915527344, 50.647499084472656, 51.03333282470703, 51.419166564941406, 51.80500030517578, 52.209999084472656, 52.16749954223633, 51.755001068115234, 51.935001373291016, 52.0966682434082, 52.258331298828125, 52.41999816894531, 52.19499969482422, 53.2599983215332, 52.10749816894531, 51.005001068115234, 50.1150016784668, 49.224998474121094, 48.334999084472656, 49.25, 49.7599983215332, 50.85749816894531, 50.247501373291016, 50.20500183105469, 50.162498474121094, 50.119998931884766, 52.24250030517578, 50.6875, 50.435001373291016, 51.625, 51.94583511352539, 52.266666412353516, 52.587501525878906, 52.59000015258789, 53.15999984741211, 53.1150016784668, 50.65999984741211, 50.9808349609375, 51.301666259765625, 51.622501373291016, 51.040000915527344, 51.38249969482422, 52.252498626708984, 52.185001373291016, 51.99500274658203, 51.80500030517578, 51.61499786376953, 51.42499923706055, 52.29750061035156, 53.31999969482422, 53.314998626708984, 53.390830993652344, 53.46666717529297, 53.54249954223633, 54.17499923706055, 55.897499084472656, 55.772499084472656, 54.6875, 54.78333282470703, 54.87916564941406, 54.974998474121094, 55.17499923706055, 55.692501068115234, 55.2400016784668, 54.432498931884766, 54.51499938964844, 54.59749984741211, 54.68000030517578, 54.41999816894531, 55.25749969482422, 54.97249984741211, 54.70500183105469, 55.1341667175293, 55.56333541870117, 55.99250030517578, 56.147499084472656, 54.7400016784668, 55.20500183105469, 56.752498626708984, 56.75666427612305, 56.760833740234375, 56.76499938964844, 56.099998474121094, 56.75749969482422, 57.522499084472656, 59.0525016784668, 59.024166107177734, 58.99583435058594, 58.967498779296875, 58.83000183105469, 58.592498779296875, 58.81999969482422, 59.102500915527344, 59.44416809082031, 59.785831451416016, 60.127498626708984, 59.9900016784668, 60.79499816894531, 60.89500045776367, 61.64500045776367, 61.850833892822266, 62.05666732788086, 62.26250076293945, 60.8224983215332, 60.814998626708984, 62.189998626708984, 63.95500183105469, 64.09500122070312, 64.23500061035156, 64.375, 64.28250122070312, 64.30999755859375, 64.85749816894531, 65.03500366210938, 65.20667266845703, 65.37833404541016, 65.55000305175781, 65.48999786376953, 66.11750030517578, 65.66000366210938, 66.44000244140625, 66.55166625976562, 66.66333770751953, 66.7750015258789, 66.57250213623047, 65.79750061035156, 65.50250244140625, 65.44499969482422, 65.82749938964844, 66.20999908447266, 66.59249877929688, 66.07250213623047, 66.95999908447266, 66.88624572753906, 66.8125, 66.55500030517578, 66.29750061035156, 66.04000091552734, 64.86250305175781, 65.43499755859375, 66.3949966430664, 67.67749786376953, 67.36166381835938, 67.04583740234375, 66.7300033569336, 67.12000274658203, 67.69249725341797, 67.86499786376953, 68.7874984741211, 69.18000030517578, 69.57249450683594, 69.96499633789062, 70.10250091552734, 69.93499755859375, 70.00499725341797, 69.86000061035156, 70.23999786376953, 70.62000274658203, 71.0, 71.06749725341797, 71.77249908447266, 72.47750091552734, 72.44999694824219, 72.59333038330078, 72.73666381835938, 72.87999725341797, 73.4124984741211, 74.25, 75.0875015258789, 74.35749816894531, 74.55500030517578, 74.75249481201172, 74.94999694824219, 74.59750366210938, 75.79750061035156, 77.40750122070312, 77.5824966430664, 78.13499450683594, 78.6875, 79.23999786376953, 78.16999816894531, 77.83499908447266, 78.80999755859375, 79.68250274658203, 79.54750061035156, 79.41250610351562, 79.27750396728516, 79.14250183105469, 79.42500305175781, 79.80750274658203, 79.57749938964844, 78.79750061035156, 78.01750183105469, 77.23750305175781, 79.42250061035156, 81.08499908447266, 80.96749877929688, 77.37750244140625, 77.30667114257812, 77.23583221435547, 77.16500091552734, 79.7125015258789, 80.36250305175781, 81.30249786376953, 80.00749969482422, 80.13416290283203, 80.26083374023438, 80.38749694824219, 79.90249633789062, 81.80000305175781, 81.21749877929688, 81.23750305175781, 80.86563110351562, 80.4937515258789, 80.12187194824219, 79.75, 80.90499877929688, 80.07499694824219, 78.26249694824219, 77.02333068847656, 75.78416442871094, 74.54499816894531, 72.0199966430664, 73.1624984741211, 68.37999725341797, 68.33999633789062, 70.46083068847656, 72.5816650390625, 74.70249938964844, 72.33000183105469, 75.68499755859375, 73.2300033569336, 72.25749969482422, 70.35250091552734, 68.44750213623047, 66.5425033569336, 71.33499908447266, 68.85749816894531, 62.057498931884766, 69.49250030517578, 66.51249694824219, 63.532501220703125, 60.5525016784668, 63.21500015258789, 61.66749954223633, 61.19499969482422, 57.310001373291016, 56.90416717529297, 56.49833297729492, 56.092498779296875, 61.720001220703125, 61.380001068115234, 64.61000061035156, 61.935001373291016, 62.524166107177734, 63.11333465576172, 63.70249938964844, 63.5724983215332, 60.227500915527344, 61.23249816894531, 60.352500915527344, 62.10750198364258, 63.86249923706055, 65.61750030517578, 64.85749816894531, 66.51750183105469, 66.99749755859375, 67.32624816894531, 67.65499877929688, 67.98374938964844, 68.3125, 71.76249694824219, 71.10749816894531, 71.67250061035156, 70.69999694824219, 70.21083068847656, 69.72166442871094, 69.23249816894531, 67.09249877929688, 69.0250015258789, 68.75749969482422, 70.74250030517578, 70.75917053222656, 70.77583312988281, 70.7925033569336, 69.6449966430664, 71.93250274658203, 73.44999694824219, 72.26750183105469, 72.60833740234375, 72.94916534423828, 73.29000091552734, 74.38999938964844, 75.15750122070312, 75.93499755859375, 77.53250122070312, 77.93917083740234, 78.34583282470703, 78.75250244140625, 77.85250091552734, 76.9124984741211, 77.38500213623047, 76.92749786376953, 77.53166198730469, 78.13583374023438, 78.73999786376953, 78.28500366210938, 79.80750274658203, 79.2125015258789, 79.72250366210938, 79.5875015258789, 79.45249938964844, 79.3175048828125, 79.18250274658203, 79.52749633789062, 79.5625, 79.48500061035156, 79.81083679199219, 80.13666534423828, 80.4625015258789, 80.83499908447266, 81.27999877929688, 80.58000183105469, 82.875, 83.038330078125, 83.20166778564453, 83.36499786376953, 85.99749755859375, 88.20999908447266, 83.9749984741211, 84.69999694824219, 85.04916381835938, 85.39833068847656, 85.74749755859375, 88.0199966430664, 87.89749908447266, 87.93250274658203, 87.43000030517578, 88.19249725341797, 88.95500183105469, 89.71749877929688, 91.63249969482422, 90.01499938964844, 91.20999908447266, 88.40750122070312, 89.086669921875, 89.76583099365234, 90.44499969482422, 91.19999694824219, 91.02749633789062, 91.02749633789062, 91.63624572753906, 92.2449951171875, 92.85375213623047, 93.4625015258789, 93.17250061035156, 95.34249877929688, 95.75250244140625, 95.91999816894531, 95.77249908447266, 95.625, 95.47750091552734, 97.05750274658203, 97.05750274658203, 97.05750274658203]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"xaxis\": {\"rangeslider\": {\"visible\": true}}, \"yaxis\": {\"autorange\": true, \"fixedrange\": false}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('eea200ec-e6a9-4264-9bdd-b80e12d3a95e');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8CVmrVUCMh5"
      },
      "source": [
        "# Séparation des données de test et d'entrainement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKbWLsWRCMh6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b15f0b1f-d825-4b3b-b0de-bb97f4370260"
      },
      "source": [
        "# Sépare les données en entrainement et tests\n",
        "pourcentage = 0.8\n",
        "temps_separation = int(len(df_etude.values) * pourcentage)\n",
        "date_separation = df_etude.index[temps_separation]\n",
        "\n",
        "serie_entrainement_X = np.array(df_etude.values[:temps_separation],dtype=np.float32)\n",
        "serie_test_X = np.array(df_etude.values[temps_separation:],dtype=np.float32)\n",
        "\n",
        "print(\"Taille de l'entrainement : %d\" %len(serie_entrainement_X))\n",
        "print(\"Taille de la validation : %d\" %len(serie_test_X))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Taille de l'entrainement : 2908\n",
            "Taille de la validation : 727\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsZWwM0-CMh7"
      },
      "source": [
        "**Normalisation des données :**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yniWB2X8CMh8"
      },
      "source": [
        "On normalise les données à l'aide de la fonction [MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emf7MqosCMh8"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "# Constrution des séries\n",
        "serie_entrainement_X_norm = []\n",
        "serie_test_X_norm = []\n",
        "\n",
        "for i in range(0,len(df_etude.columns)):\n",
        "  serie_entrainement_X_norm.append(serie_entrainement_X[:,i])\n",
        "  serie_test_X_norm.append(serie_test_X[:,i])\n",
        "\n",
        "serie_entrainement_X_norm = tf.convert_to_tensor(serie_entrainement_X_norm)\n",
        "serie_entrainement_X_norm = tf.transpose(serie_entrainement_X_norm)\n",
        "serie_test_X_norm = tf.convert_to_tensor(serie_test_X_norm)\n",
        "serie_test_X_norm = tf.transpose(serie_test_X_norm)\n",
        "\n",
        "# Initialisaton du MinMaxScaler\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "min_max_scaler.fit(serie_entrainement_X_norm)\n",
        "\n",
        "# Normalisation des séries\n",
        "serie_entrainement_X_norm = min_max_scaler.transform(serie_entrainement_X_norm)\n",
        "serie_test_X_norm = min_max_scaler.transform(serie_test_X_norm)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoBbMQIICMh9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "216fe952-8925-4258-e202-724cdcc12c45"
      },
      "source": [
        "print(serie_entrainement_X_norm.shape)\n",
        "print(serie_test_X_norm.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2908, 44)\n",
            "(727, 44)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6THNLf2CMh-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "4685fd1f-9aa5-4cf6-f564-d708136d23a0"
      },
      "source": [
        "# Affiche quelques séries\n",
        "fig, ax = plt.subplots(constrained_layout=True, figsize=(15,5))\n",
        "\n",
        "ax.plot(df_etude.index[:temps_separation].values,serie_entrainement_X_norm[:,0:5], label=\"X_Ent\")\n",
        "ax.plot(df_etude.index[temps_separation:].values,serie_test_X_norm[:,0:5], label=\"X_Val\")\n",
        "\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNJjTisMlfgQ"
      },
      "source": [
        "# Création des datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i817Q5rwIL_x"
      },
      "source": [
        "Les datasets sont créés de la manière suivante :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwssikbyIEzc"
      },
      "source": [
        "  <img src='https://github.com/AlexandreBourrieau/FICHIERS/blob/main/Series_Temporelles/Multi/images/ConstructionDataset.png?raw=true' width=500/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoiHptoQyTxL"
      },
      "source": [
        "**1. Exemple de dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQQTRH_5wjrc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7f3579a-5fea-4fc7-c196-e4c0645762a0"
      },
      "source": [
        "X1 = np.linspace(1,100,100)\n",
        "X2 = np.linspace(101,200,100)\n",
        "X3 = np.linspace(201,300,100)\n",
        "Y = np.linspace(301,400,100)\n",
        "\n",
        "X1 = tf.expand_dims(X1,-1)\n",
        "X2 = tf.expand_dims(X2,-1)\n",
        "X3 = tf.expand_dims(X3,-1)\n",
        "Y = tf.expand_dims(Y,-1)\n",
        "\n",
        "Serie_X = tf.concat([X1,X2,X3],axis=1)\n",
        "Serie_Y = Y\n",
        "print(Serie_X.shape)\n",
        "\n",
        "# Fonction permettant de créer un dataset à partir des données de la série temporelle\n",
        "# X = {((X1_1,X1_2,...,X1_T),((X2_1,X2_2,...,X2_T),(X3_1,X3_2,...,X3_T)),\n",
        "#       (Y1,Y2,...,YT-1)}\n",
        "# Y = YT\n",
        "\n",
        "def prepare_dataset_XY(seriesX, serieY, longueur_sequence, longueur_sortie, batch_size,shift):\n",
        "  datasetX = tf.data.Dataset.from_tensor_slices(seriesX)\n",
        "  datasetX = datasetX.window(longueur_sequence+longueur_sortie, shift=shift, drop_remainder=True)\n",
        "  datasetX = datasetX.flat_map(lambda x: x.batch(longueur_sequence + longueur_sortie))\n",
        "  datasetX = datasetX.map(lambda x: (x[0:longueur_sequence][:,:]))\n",
        "  datasetX = datasetX.batch(batch_size,drop_remainder=True).prefetch(1)\n",
        "\n",
        "  datasetY = tf.data.Dataset.from_tensor_slices(serieY)\n",
        "  datasetY = datasetY.window(longueur_sequence+longueur_sortie, shift=shift, drop_remainder=True)\n",
        "  datasetY = datasetY.flat_map(lambda x: x.batch(longueur_sequence + longueur_sortie))\n",
        "  datasetY = datasetY.map(lambda x: (x[0:longueur_sequence][:,:]))\n",
        "  datasetY = datasetY.batch(batch_size,drop_remainder=True).prefetch(1)\n",
        "\n",
        "  datasetYPred = tf.data.Dataset.from_tensor_slices(serieY)\n",
        "  datasetYPred = datasetYPred.window(longueur_sequence+longueur_sortie+1, shift=shift, drop_remainder=True)\n",
        "  datasetYPred = datasetYPred.flat_map(lambda x: x.batch(longueur_sequence + longueur_sortie+1))\n",
        "  datasetYPred = datasetYPred.map(lambda x: (x[0:-1][-1:,:]))\n",
        "  datasetYPred = datasetYPred.batch(batch_size,drop_remainder=True).prefetch(1)\n",
        "\n",
        "\n",
        "  dataset = tf.data.Dataset.zip((datasetX,datasetY))\n",
        "  dataset = tf.data.Dataset.zip((dataset,datasetYPred))\n",
        "\n",
        "  return dataset\n",
        "\n",
        "test_dataset = prepare_dataset_XY(Serie_X,Serie_Y,10,1,1,1)\n",
        "\n",
        "print(len(list(test_dataset.as_numpy_iterator())))\n",
        "for element in test_dataset.take(2):\n",
        "  print(element)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100, 3)\n",
            "89\n",
            "((<tf.Tensor: shape=(1, 10, 3), dtype=float64, numpy=\n",
            "array([[[  1., 101., 201.],\n",
            "        [  2., 102., 202.],\n",
            "        [  3., 103., 203.],\n",
            "        [  4., 104., 204.],\n",
            "        [  5., 105., 205.],\n",
            "        [  6., 106., 206.],\n",
            "        [  7., 107., 207.],\n",
            "        [  8., 108., 208.],\n",
            "        [  9., 109., 209.],\n",
            "        [ 10., 110., 210.]]])>, <tf.Tensor: shape=(1, 10, 1), dtype=float64, numpy=\n",
            "array([[[301.],\n",
            "        [302.],\n",
            "        [303.],\n",
            "        [304.],\n",
            "        [305.],\n",
            "        [306.],\n",
            "        [307.],\n",
            "        [308.],\n",
            "        [309.],\n",
            "        [310.]]])>), <tf.Tensor: shape=(1, 1, 1), dtype=float64, numpy=array([[[311.]]])>)\n",
            "((<tf.Tensor: shape=(1, 10, 3), dtype=float64, numpy=\n",
            "array([[[  2., 102., 202.],\n",
            "        [  3., 103., 203.],\n",
            "        [  4., 104., 204.],\n",
            "        [  5., 105., 205.],\n",
            "        [  6., 106., 206.],\n",
            "        [  7., 107., 207.],\n",
            "        [  8., 108., 208.],\n",
            "        [  9., 109., 209.],\n",
            "        [ 10., 110., 210.],\n",
            "        [ 11., 111., 211.]]])>, <tf.Tensor: shape=(1, 10, 1), dtype=float64, numpy=\n",
            "array([[[302.],\n",
            "        [303.],\n",
            "        [304.],\n",
            "        [305.],\n",
            "        [306.],\n",
            "        [307.],\n",
            "        [308.],\n",
            "        [309.],\n",
            "        [310.],\n",
            "        [311.]]])>), <tf.Tensor: shape=(1, 1, 1), dtype=float64, numpy=array([[[312.]]])>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLEjFxNnyWse"
      },
      "source": [
        "**2. Préparation des datasets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Y67w_LmnpiP"
      },
      "source": [
        "# Fonction permettant de créer un dataset à partir des données de la série temporelle\n",
        "# X = {((X1_1,X1_2,...,X1_T),(X2_1,X2_2,...,X2_T),(X3_1,X3_2,...,X3_T)),\n",
        "#       (Y1,Y2,...,YT)}\n",
        "# Y = YT+1\n",
        "\n",
        "def prepare_dataset_XY(seriesX, serieY, longueur_sequence, longueur_sortie, batch_size,shift):\n",
        "  datasetX = tf.data.Dataset.from_tensor_slices(seriesX)\n",
        "  datasetX = datasetX.window(longueur_sequence+longueur_sortie, shift=shift, drop_remainder=True)\n",
        "  datasetX = datasetX.flat_map(lambda x: x.batch(longueur_sequence + longueur_sortie))\n",
        "  datasetX = datasetX.map(lambda x: (x[0:longueur_sequence][:,:]))\n",
        "  datasetX = datasetX.batch(batch_size,drop_remainder=True).prefetch(1)\n",
        "\n",
        "  datasetY = tf.data.Dataset.from_tensor_slices(serieY)\n",
        "  datasetY = datasetY.window(longueur_sequence+longueur_sortie, shift=shift, drop_remainder=True)\n",
        "  datasetY = datasetY.flat_map(lambda x: x.batch(longueur_sequence + longueur_sortie))\n",
        "  datasetY = datasetY.map(lambda x: (x[0:longueur_sequence][:,:]))\n",
        "  datasetY = datasetY.batch(batch_size,drop_remainder=True).prefetch(1)\n",
        "\n",
        "  datasetYPred = tf.data.Dataset.from_tensor_slices(serieY)\n",
        "  datasetYPred = datasetYPred.window(longueur_sequence+longueur_sortie+1, shift=shift, drop_remainder=True)\n",
        "  datasetYPred = datasetYPred.flat_map(lambda x: x.batch(longueur_sequence + longueur_sortie+1))\n",
        "  datasetYPred = datasetYPred.map(lambda x: (x[0:-1][-1:,:]))\n",
        "  datasetYPred = datasetYPred.batch(batch_size,drop_remainder=True).prefetch(1)\n",
        "\n",
        "\n",
        "  dataset = tf.data.Dataset.zip((datasetX,datasetY))\n",
        "  dataset = tf.data.Dataset.zip((dataset,datasetYPred))\n",
        "\n",
        "  return dataset"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghhUzmxdlj0g"
      },
      "source": [
        "# Définition des caractéristiques du dataset que l'on souhaite créer\n",
        "batch_size = 64*8\n",
        "longueur_sequence = 8\n",
        "longueur_sortie = 1\n",
        "shift=1\n",
        "\n",
        "# Création du dataset\n",
        "dataset = prepare_dataset_XY(serie_entrainement_X_norm[:,0:-1],serie_entrainement_X_norm[:,-1:], longueur_sequence,longueur_sortie,batch_size,shift)\n",
        "dataset_val = prepare_dataset_XY(serie_test_X_norm[:,0:-1],serie_test_X_norm[:,-1:],longueur_sequence,longueur_sortie,batch_size,shift)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mJX_otLmJ7w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68bbf5f1-d034-42b7-b24c-696216321a77"
      },
      "source": [
        "print(len(list(dataset.as_numpy_iterator())))\n",
        "for element in dataset.take(1):\n",
        "  print(element[0][0].shape)            # ((X1),(X2),...) = ((X1_1,X1_2,...,X1_T),(X2_1,X2_2,...,X2_T),...)\n",
        "  print(element[0][1].shape)            # (Y1,Y2,...,YT)\n",
        "  print(element[1].shape)               # YT+1"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "(512, 8, 43)\n",
            "(512, 8, 1)\n",
            "(512, 1, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qKsAMMRn2JI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55a961f2-f991-49fb-eec4-39b125278588"
      },
      "source": [
        "print(len(list(dataset_val.as_numpy_iterator())))\n",
        "for element in dataset_val.take(1):\n",
        "  print(element[0][0].shape)            # ((X1),(X2),...) = ((X1_1,X1_2,...,X1_T),(X2_1,X2_2,...,X2_T),...)\n",
        "  print(element[0][1].shape)            # Y1,Y2,...,YT\n",
        "  print(element[1].shape)               # YT+1"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "(512, 8, 43)\n",
            "(512, 8, 1)\n",
            "(512, 1, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuecK3H6GUeX"
      },
      "source": [
        "**3. Préparation des X/Y**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpCqWrvonaB3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93676fc8-d42d-4d81-dc63-f3a9bce51a19"
      },
      "source": [
        "X1 = []\n",
        "X2 = []\n",
        "\n",
        "# Extrait les X,Y du dataset\n",
        "x,y = tuple(zip(*dataset))              # x=43x((BS,10,3),(BS,9,1))\n",
        "                                        # y=43x(BS,1,1)\n",
        "for i in range(len(x)):\n",
        "  X1.append(x[i][0])          \n",
        "  X2.append(x[i][1])\n",
        "\n",
        "X1 = tf.convert_to_tensor(X1)           # (43,BS,10,3)\n",
        "X2 = tf.convert_to_tensor(X2)           # (43,BS,9,1)\n",
        "\n",
        "X1 = np.asarray(X1,dtype=np.float32)    # (43,BS,10,3)\n",
        "X2 = np.asarray(X2,dtype=np.float32)    # (43,BS,10,3)   \n",
        "\n",
        "# Recombine les données\n",
        "y = np.asarray(y,dtype=np.float32)      # 43x(BS,1,1) => (43xBS,1,1)\n",
        "X1 = np.reshape(X1,(X1.shape[0]*X1.shape[1],X1.shape[2],X1.shape[3]))   # (43,BS,10,3) => (43xBS,10,3)\n",
        "X2 = np.reshape(X2,(X2.shape[0]*X2.shape[1],X2.shape[2],X2.shape[3]))   # (43,BS,9,1) => (43*BS,9,1)\n",
        "\n",
        "x_train = [X1,X2]\n",
        "y_train = np.asarray(tf.reshape(y,shape=(y.shape[0]*y.shape[1],longueur_sortie,y.shape[3])))\n",
        "\n",
        "# Affiche les formats\n",
        "print(x_train[0].shape)\n",
        "print(x_train[1].shape)\n",
        "print(y_train.shape)\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2560, 8, 43)\n",
            "(2560, 8, 1)\n",
            "(2560, 1, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnDnemp8NujA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59da3731-5653-4b39-d365-6d0bc915b7bf"
      },
      "source": [
        "X1 = []\n",
        "X2 = []\n",
        "\n",
        "# Extrait les X,Y du dataset\n",
        "x,y = tuple(zip(*dataset_val))              # x=43x((BS,10,3),(BS,9,1))\n",
        "                                        # y=43x(BS,1,1)\n",
        "for i in range(len(x)):\n",
        "  X1.append(x[i][0])          \n",
        "  X2.append(x[i][1])\n",
        "\n",
        "X1 = tf.convert_to_tensor(X1)           # (43,BS,10,3)\n",
        "X2 = tf.convert_to_tensor(X2)           # (43,BS,9,1)\n",
        "\n",
        "X1 = np.asarray(X1,dtype=np.float32)    # (43,BS,10,3)\n",
        "X2 = np.asarray(X2,dtype=np.float32)    # (43,BS,10,3)   \n",
        "\n",
        "# Recombine les données\n",
        "y = np.asarray(y,dtype=np.float32)      # 43x(BS,1,1) => (43xBS,1,1)\n",
        "X1 = np.reshape(X1,(X1.shape[0]*X1.shape[1],X1.shape[2],X1.shape[3]))   # (43,BS,10,3) => (43xBS,10,3)\n",
        "X2 = np.reshape(X2,(X2.shape[0]*X2.shape[1],X2.shape[2],X2.shape[3]))   # (43,BS,9,1) => (43*BS,9,1)\n",
        "\n",
        "x_val = [X1,X2]\n",
        "y_val = np.asarray(tf.reshape(y,shape=(y.shape[0]*y.shape[1],longueur_sortie,y.shape[3])))\n",
        "\n",
        "# Affiche les formats\n",
        "print(x_val[0].shape)\n",
        "print(x_val[1].shape)\n",
        "print(y_val.shape)\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(512, 8, 43)\n",
            "(512, 8, 1)\n",
            "(512, 1, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNV_5uXS4eaS"
      },
      "source": [
        "# Affichage des séries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9aPVTcDn6TQ"
      },
      "source": [
        "# Affiche la série\n",
        "fig, ax = plt.subplots(constrained_layout=True, figsize=(15,5))\n",
        "\n",
        "ax.plot(np.linspace(0,longueur_sequence,longueur_sequence),x_train[0][0,:,0:3],label=\"X_train (X)\")\n",
        "ax.plot(np.linspace(0,longueur_sequence,longueur_sequence),x_train[1][0,:,:],label=\"X_train (Y)\")\n",
        "\n",
        "ax.plot(np.linspace(longueur_sequence+1,longueur_sequence+2,1),y_train[0,:,:],label=\"Y_train\",marker=\"*\")\n",
        "\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_g3DUl3x0Bm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KvuPUL1nXpX"
      },
      "source": [
        "# Création du modèle HRHN ENC/DEC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBvAzS8KtFlp"
      },
      "source": [
        "Le modèle HRHN est décrit dans ce document de recherche : [Hierarchical Attention-Based Recurrent Highway Networks for Time Series Prediction](https://arxiv.org/pdf/1806.00685)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKq0mqg2ts2w"
      },
      "source": [
        "<img src='https://github.com/AlexandreBourrieau/FICHIERS/blob/main/Series_Temporelles/Multi/images/Mod%C3%A8leHRHN1.png?raw=true' width=700>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrCCnwy8nXp4"
      },
      "source": [
        "**1. Création de l'encodeur**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tn5xnfnuehY"
      },
      "source": [
        "L'encodeur a pour but de créer des représentations cachées des séries exogènes qui prennent en compte les relations spatiales entre ces séries ainsi que les relations temporelles.  \n",
        "Les relations spatiales sont extraitent à l'aide d'un ensemble de réseaux de convolution qui produisent des représentations w1, w2... w(T-1).  \n",
        "Ces représentations sont ensuites codées par un réseau RHN à 3 couches afin d'en extraire les relations temporelles. En sortie de ce réseau RHN, on extrait 3 tenseurs dont chacun contient les (T-1) états cachés de chaque couche du réseau RHN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0mq5BSauQUq"
      },
      "source": [
        "<img src='https://github.com/AlexandreBourrieau/FICHIERS/blob/main/Series_Temporelles/Multi/images/HRHN_Encodeur_VueEnsemble.png?raw=true'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJ-boowSGDp3"
      },
      "source": [
        "***a. Création des CNN parallèlisés***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6dF5Cp9vzWB"
      },
      "source": [
        "La structure d'un réseau de convolution est composée de trois couches CNN-1D + Max-pooling :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jga5_ZzKv6CI"
      },
      "source": [
        "<img src='https://github.com/AlexandreBourrieau/FICHIERS/blob/main/Series_Temporelles/Multi/images/HRHN_Encodeur_CNN1.png?raw=true'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CMXl2tgwJ76"
      },
      "source": [
        "L'intégration de caque réseau dans Keras est parallélisée :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtR-u7ZqwjTL"
      },
      "source": [
        "<img src='https://github.com/AlexandreBourrieau/FICHIERS/blob/main/Series_Temporelles/Multi/images/HRHN_Encodeur_CNN2.png?raw=true'>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ETqqvAIGKLi"
      },
      "source": [
        "# Arguments de la méthode __init__\n",
        "#   dim_filtres_cnn   :   liste dimension des filtres ex: [3,3,3]\n",
        "#   nbr_filtres_cnn   :   liste nbr de filtre sur chaque couche ex: [16,32,64]\n",
        "#   dim_max_pooling   :   liste dimension max pooling après chaque couche ex: [3,3,3]\n",
        "\n",
        "class Encodeur_CNN(tf.keras.layers.Layer):\n",
        "  def __init__(self, dim_filtres_cnn, nbr_filtres_cnn, dim_max_pooling,dim_motif):\n",
        "    self.dim_filtres_cnn = dim_filtres_cnn\n",
        "    self.nbr_filtres_cnn = nbr_filtres_cnn\n",
        "    self.dim_max_pooling = dim_max_pooling\n",
        "    self.dim_motif = dim_motif\n",
        "    super().__init__()                # Appel du __init__() de la classe Layer\n",
        "  \n",
        "  # Création de Tin réseaux de convolution + max_pooling en //\n",
        "  ############################################################\n",
        "  def build(self,input_shape):\n",
        "    convs = []\n",
        "    input_cnns = []\n",
        "\n",
        "    # Création des Tin entrées des réseaux CNN\n",
        "    for i in range(input_shape[1]):\n",
        "        input_cnns.append(tf.keras.Input(shape=(input_shape[2],1)))       # input = Tin*(batch_size,#dim,1)\n",
        "\n",
        "    # Création des Tin réseaux CNN\n",
        "    for i in range(input_shape[1]):\n",
        "      conv = tf.keras.layers.Conv1D(filters=self.nbr_filtres_cnn[0],      # conv : (batch_size,#dim,16)\n",
        "                                    kernel_size=self.dim_filtres_cnn[0],\n",
        "                                    activation='relu',\n",
        "                                    padding='same',\n",
        "                                    strides=1)(input_cnns[i])\n",
        "      conv = tf.keras.layers.MaxPool1D(pool_size=self.dim_max_pooling[0],      # conv : (batch_size,#pooling1,16)\n",
        "                                       padding='same')(conv)\n",
        "      for n in range(1,len(self.dim_filtres_cnn)):\n",
        "        conv = tf.keras.layers.Conv1D(filters=self.nbr_filtres_cnn[n],    # conv : (batch_size,#pooling_x,dim_filtres_cnn[n])\n",
        "                                      kernel_size=self.dim_filtres_cnn[n],\n",
        "                                      activation='relu',\n",
        "                                      padding='same',\n",
        "                                      strides=1)(conv)\n",
        "        conv = tf.keras.layers.MaxPool1D(pool_size=self.dim_max_pooling[n],    # conv : (batch_size,#pooling_x,dim_filtres_cnn[n])\n",
        "                                         padding='same')(conv)\n",
        "      convs.append(conv)\n",
        "    \n",
        "    # Création de la sortie concaténée des Tin réseaux CNN\n",
        "    out = tf.convert_to_tensor(convs)                                     # out : (Tin,batch_size,#pooling,64)\n",
        "    out = tf.transpose(out,perm=[1,0,2,3])                                # out : (batch_size,Tin,#pooling,64)\n",
        "    out = tf.keras.layers.Reshape(                                        # out : (batch_size,Tin,#pooling*64)\n",
        "        target_shape=(out.shape[1],out.shape[2]*out.shape[3]))(out)\n",
        "\n",
        "    if self.dim_motif == 0:\n",
        "      out = tf.keras.layers.Dense(units=out.shape[2])(out)                  # out : (batch_size,Tin,dim_motif = #pooling*64) \n",
        "    else:\n",
        "      out = tf.keras.layers.Dense(units=self.dim_motif)(out)                # out : (batch_size,Tin,dim_motif) \n",
        "\n",
        "    # Création du modèle global\n",
        "    self.conv_model = tf.keras.Model(inputs=input_cnns,outputs=out)\n",
        "\n",
        "    super().build(input_shape)        # Appel de la méthode build()\n",
        "    \n",
        "  # Entrées :\n",
        "  #     input:  Entrée séries exogènes  : (batch_size,Tin,#dim)\n",
        "  # Sorties :\n",
        "  #     w:      Sorties des motifs CNN  : (batch_size,Tin,#dim_motif)\n",
        "  #                                       (taille dernier filtre=64)\n",
        "  def call(self, input):\n",
        "    # Coupes temporelles sur les séries exogènes\n",
        "    # au format : Tin*(batch_size,#dim,1)\n",
        "    input_list = []\n",
        "    for i in range(input.shape[1]):\n",
        "      input_list.append(tf.transpose(input[:,i:i+1,:],perm=[0,2,1]))      # (batch_size,#dim,1)\n",
        "    # Convolutions spatiales des séries exogènes\n",
        "    w = self.conv_model(input_list)                                       # (batch_size,Tin,dim_motif)\n",
        "    return w"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_y68mmiRpR1"
      },
      "source": [
        "***b. Création des cellules RHN***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FQ47zOsxHpx"
      },
      "source": [
        "<img src='https://github.com/AlexandreBourrieau/FICHIERS/blob/main/Series_Temporelles/Multi/images/HRHN_Encodeur_RHN.png?raw=true'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvNrS-wQ1B5C"
      },
      "source": [
        "On crée une cellule RHN en reprenant le code précédent auquel :  \n",
        "- On ajoute la possibilité de retourner tous les états cachés de chaque couche\n",
        "- On ajoute la prise en compte de la dimension d'entrée correspondant à la dimension des motifs en sortie des réseaux CNN (dim_motif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CygD9DXbBTDJ"
      },
      "source": [
        "<img src='https://github.com/AlexandreBourrieau/FICHIERS/blob/main/Series_Temporelles/Multi/images/Structure_RHN4.png?raw=true'>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HldCwl9z3fY"
      },
      "source": [
        "class Cellule_RHN(tf.keras.layers.Layer):\n",
        "  def __init__(self, dim_RHN, nbr_couches, return_all_states = False, dim_input=1):\n",
        "    self.dim_RHN = dim_RHN\n",
        "    self.nbr_couches = nbr_couches\n",
        "    self.dim_input = dim_input\n",
        "    self.return_all_states = return_all_states\n",
        "    super().__init__()                # Appel du __init__() de la classe Layer\n",
        "  \n",
        "  def build(self,input_shape):\n",
        "    self.Wh = self.add_weight(shape=(input_shape[2],self.dim_RHN),initializer=\"normal\",name=\"Wh\")       # (#dim, #RHN)\n",
        "    self.Wt = self.add_weight(shape=(input_shape[2],self.dim_RHN),initializer=\"normal\",name=\"Wt\")       # (#dim, #RHN)\n",
        "    self.Wc = self.add_weight(shape=(input_shape[2],self.dim_RHN),initializer=\"normal\",name=\"Wc\")       # (#dim, #RHN)\n",
        "\n",
        "    self.Rh = self.add_weight(shape=(self.nbr_couches,self.dim_RHN,self.dim_RHN),initializer=\"normal\",name=\"Rh\")      # (n_couches,#RHN, #RHN)\n",
        "    self.Rt = self.add_weight(shape=(self.nbr_couches,self.dim_RHN,self.dim_RHN),initializer=\"normal\",name=\"Rt\")      # (n_couches,#RHN, #RHN)\n",
        "    self.Rc = self.add_weight(shape=(self.nbr_couches,self.dim_RHN,self.dim_RHN),initializer=\"normal\",name=\"Rc\")      # (n_couches,#RHN, #RHN)\n",
        "\n",
        "    self.bh = self.add_weight(shape=(self.nbr_couches,self.dim_RHN,1),initializer=\"normal\",name=\"bh\")        # (n_couches,#RHN, 1)\n",
        "    self.bt = self.add_weight(shape=(self.nbr_couches,self.dim_RHN,1),initializer=\"normal\",name=\"bt\")        # (n_couches,#RHN, 1)\n",
        "    self.bc = self.add_weight(shape=(self.nbr_couches,self.dim_RHN,1),initializer=\"normal\",name=\"bc\")        # (n_couches,#RHN, 1)\n",
        "\n",
        "    super().build(input_shape)        # Appel de la méthode build()\n",
        "\n",
        "    # Initialisation des masques de dropout\n",
        "  def InitMasquesDropout(self,drop=0.0):\n",
        "    self.Wh_ = tf.convert_to_tensor(np.random.binomial(n=1,p=1.0-drop,size=(self.dim_input,1)),dtype=tf.float32)                 # (#dim,1)\n",
        "    self.Wt_ = tf.convert_to_tensor(np.random.binomial(n=1,p=1.0-drop,size=(self.dim_input,1)),dtype=tf.float32)                 # (#dim,1)\n",
        "    self.Wc_ = tf.convert_to_tensor(np.random.binomial(n=1,p=1.0-drop,size=(self.dim_input,1)),dtype=tf.float32)                 # (#dim,1)\n",
        "    self.Rh_ = tf.convert_to_tensor(np.random.binomial(n=1,p=1.0-drop,size=(self.nbr_couches,self.dim_RHN,1)),dtype=tf.float32)  # (n_couches,#RHN,1)\n",
        "    self.Rt_ = tf.convert_to_tensor(np.random.binomial(n=1,p=1.0-drop,size=(self.nbr_couches,self.dim_RHN,1)),dtype=tf.float32)  # (n_couches,#RHN,1)\n",
        "    self.Rc_ = tf.convert_to_tensor(np.random.binomial(n=1,p=1.0-drop,size=(self.nbr_couches,self.dim_RHN,1)),dtype=tf.float32)  # (n_couches,#RHN,1)\n",
        "\n",
        "  # Entrées :\n",
        "  #     input:          Entrées X[t]        : (batch_size,1,#dim)\n",
        "  #     init_hidden:    Etat caché Init.    : (batch_size,#RHN)\n",
        "  # Sorties :\n",
        "  #     sL:             Etat caché de la dernière couche       : (batch_size,#RHN) \n",
        "  #           ou        Etats cachés de chaque couche SL[t]    : (batch_size,nbr_couches,#RHN)\n",
        "  def call(self, input, init_hidden=None):\n",
        "    # Construction d'un vecteur d'état nul si besoin\n",
        "    if init_hidden == None:\n",
        "      init_hidden = tf.matmul(tf.zeros(shape=(self.dim_RHN,input.shape[2])), # (#RHN,#dim)X(batch_size,#dim,1) = (batch_size,#RHN,1)\n",
        "                              tf.transpose(input,perm=[0,2,1]))\n",
        "      init_hidden = tf.squeeze(init_hidden,-1)                               # (batch_size,#RHN,1) => (batch_size,#RHN)\n",
        "  \n",
        "    liste_sl = []                                                            # Liste pour  enregistrer les états cachés de chaque couche\n",
        "    # Calcul de hl, tl et cl\n",
        "    for i in range(self.nbr_couches):\n",
        "      if i==0:\n",
        "        # Applique le masque aux poids\n",
        "        Rh = tf.multiply(self.Rh_[0,:,:],self.Rh[0,:,:])                      # (#RHN,1)_x_(#RHN,#RHN) = (#RHN,#RHN)\n",
        "        Rt = tf.multiply(self.Rt_[0,:,:],self.Rt[0,:,:])\n",
        "        Rc = tf.multiply(self.Rc_[0,:,:],self.Rc[0,:,:])\n",
        "\n",
        "        Wh = tf.multiply(self.Wh_,self.Wh)                                    # (#dim,1)_x_(#dim,#RHN) = (#dim,#RHN)\n",
        "        Wt = tf.multiply(self.Wt_,self.Wt)\n",
        "        Wc = tf.multiply(self.Wc_,self.Wc)\n",
        "   \n",
        "        # Calcul de hl\n",
        "        hl = tf.matmul(Rh,tf.expand_dims(init_hidden,-1))                   # (#RHN,#RHN)X(batch_size,#RHN,1) = (batch_size,#RHN,1)\n",
        "        hl = hl + self.bh[0,:,:]                                            # (batch_size,#RHN,1) + (#RHN,1) = (batch_size,#RHN,1)\n",
        "        hl = hl + tf.matmul(tf.transpose(Wh),\n",
        "                            tf.transpose(input,perm=[0,2,1]))               # (#RHN,#dim)X(batch_size,#dim,1) = (batch_size,#RHN,1)\n",
        "        hl = tf.squeeze(hl,-1)                                              # (batch_size,#RHN)\n",
        "        hl = K.tanh(hl)\n",
        "\n",
        "        # Calcul de tl\n",
        "        tl = tf.matmul(Rt,tf.expand_dims(init_hidden,-1))                   # (#RHN,#RHN)X(batch_size,#RHN,1) = (batch_size,#RHN,1)\n",
        "        tl = tl + self.bt[0,:,:]                                            # (batch_size,#RHN,1) + (#RHN,1) = (batch_size,#RHN,1)\n",
        "        tl = tl + tf.matmul(tf.transpose(Wt),\n",
        "                            tf.transpose(input,perm=[0,2,1]))               # (#RHN,#dim)X(batch_size,#dim,1) = (batch_size,#RHN,1)\n",
        "        tl = tf.squeeze(tl,-1)                                              # (batch_size,#RHN)\n",
        "        tl = tf.keras.activations.sigmoid(tl)\n",
        "\n",
        "        # Calcul de cl\n",
        "        cl = tf.matmul(Rc,tf.expand_dims(init_hidden,-1))                   # (#RHN,#RHN)X(batch_size,#RHN,1) = (batch_size,#RHN,1)\n",
        "        cl = cl + self.bc[0,:,:]                                            # (batch_size,#RHN,1) + (#RHN,1) = (batch_size,#RHN,1)\n",
        "        cl = cl + tf.matmul(tf.transpose(Wc),\n",
        "                            tf.transpose(input,perm=[0,2,1]))               # (#RHN,#dim)X(batch_size,#dim,1) = (batch_size,#RHN,1)\n",
        "        cl = tf.squeeze(cl,-1)                                              # (batch_size,#RHN)\n",
        "        cl = tf.keras.activations.sigmoid(cl)\n",
        "\n",
        "      else:\n",
        "        # Applique le masque aux poids\n",
        "        Rh = tf.multiply(self.Rh_[i,:,:],self.Rh[i,:,:])\n",
        "        Rt = tf.multiply(self.Rt_[i,:,:],self.Rt[i,:,:])\n",
        "        Rc = tf.multiply(self.Rc_[i,:,:],self.Rc[i,:,:])\n",
        "\n",
        "        # Calcul de hl\n",
        "        hl = tf.matmul(Rh,tf.expand_dims(init_hidden,-1))                   # (#RHN,#RHN)X(batch_size,#RHN,1) = (batch_size,#RHN,1)\n",
        "        hl = hl + self.bh[i,:,:]                                            # (batch_size,#RHN,1) + (#RHN,1) = (batch_size,#RHN,1)\n",
        "        hl = tf.squeeze(hl,-1)                                              # (batch_size,#RHN)\n",
        "        hl = K.tanh(hl)\n",
        "\n",
        "        # Calcul de tl\n",
        "        tl = tf.matmul(Rt,tf.expand_dims(init_hidden,-1))                   # (#RHN,#RHN)X(batch_size,#RHN,1) = (batch_size,#RHN,1)\n",
        "        tl = tl + self.bt[i,:,:]                                            # (batch_size,#RHN,1) + (#RHN,1) = (batch_size,#RHN,1)\n",
        "        tl = tf.squeeze(tl,-1)                                              # (batch_size,#RHN)\n",
        "        tl = tf.keras.activations.sigmoid(tl)\n",
        "\n",
        "        # Calcul de cl\n",
        "        cl = tf.matmul(Rc,tf.expand_dims(init_hidden,-1))                   # (#RHN,#RHN)X(batch_size,#RHN,1) = (batch_size,#RHN,1)\n",
        "        cl = cl + self.bc[i,:,:]                                            # (batch_size,#RHN,1) + (#RHN,1) = (batch_size,#RHN,1)\n",
        "        cl = tf.squeeze(cl,-1)                                              # (batch_size,#RHN)\n",
        "        cl = tf.keras.activations.sigmoid(cl)\n",
        "      \n",
        "      # Calcul de sl\n",
        "      sl = tf.keras.layers.multiply([hl,tl])                                # (batch_size,#RHN)\n",
        "      sl = sl + tf.keras.layers.multiply([init_hidden,cl])                  # (batch_size,#RHN)\n",
        "      liste_sl.append(sl)       # Sauvegarde l'état caché de la couche courante\n",
        "      init_hidden = sl\n",
        "    if self.return_all_states == False:\n",
        "      return sl\n",
        "    else:\n",
        "      liste_sl = tf.convert_to_tensor(liste_sl)                             # (nbr_couches,batch_size,#RHN)\n",
        "      liste_sl = tf.transpose(liste_sl,perm=[1,0,2])                        # (batch_size,nbr_couches,#RHN)\n",
        "      return liste_sl"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJY-TY7W55ZF"
      },
      "source": [
        "***c. Création de l'encodeur : Convolutions + RHN***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMT8C8-UVe2O"
      },
      "source": [
        "<img src='https://github.com/AlexandreBourrieau/FICHIERS/blob/main/Series_Temporelles/Multi/images/HRHN_Encodeur_VueEnsemble.png?raw=true'>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYQu67IfBdel"
      },
      "source": [
        "# Arguments de la méthode __init__\n",
        "#   dim_filtres_cnn   :   liste dimension des filtres ex: [3,3,3]\n",
        "#   nbr_filtres_cnn   :   liste nbr de filtre sur chaque couche ex: [16,32,64]\n",
        "#   dim_max_pooling   :   liste dimension max pooling après chaque couche ex: [3,3,3]\n",
        "#   dim_motif         :   dimension du motif en sortie du CNN\n",
        "#   dim_RHN_enc       :   dimension du vecteur caché RHN\n",
        "#   nbr_couches_RHN   :   nombre de couches du RHN\n",
        "#   dropout           :   dropout variationnel pour le RHN ex: [0.1]\n",
        "\n",
        "class Encodeur(tf.keras.layers.Layer):\n",
        "  def __init__(self, dim_filtres_cnn, nbr_filtres_cnn, dim_max_pooling, dim_motif,dim_RHN_enc,nbr_couches_RHN, dropout=0.0):\n",
        "    self.dim_filtres_cnn = dim_filtres_cnn\n",
        "    self.nbr_filtres_cnn = nbr_filtres_cnn\n",
        "    self.dim_max_pooling = dim_max_pooling\n",
        "    self.dim_motif = dim_motif\n",
        "    self.dim_RHN_enc = dim_RHN_enc\n",
        "    self.nbr_couches_RHN = nbr_couches_RHN\n",
        "    self.dropout = dropout\n",
        "    super().__init__()                # Appel du __init__() de la classe Layer\n",
        "  \n",
        "  def build(self,input_shape):\n",
        "    self.encodeur_cnn = Encodeur_CNN(dim_filtres_cnn=self.dim_filtres_cnn,nbr_filtres_cnn=self.nbr_filtres_cnn,dim_max_pooling=self.dim_max_pooling,dim_motif=self.dim_motif)\n",
        "    self.RHN = Cellule_RHN(dim_RHN=self.dim_RHN_enc,nbr_couches=self.nbr_couches_RHN,return_all_states=True,dim_input=self.dim_motif)\n",
        "    super().build(input_shape)        # Appel de la méthode build()\n",
        "    \n",
        "  # Entrées :\n",
        "  #     input:          Entrées X         : (batch_size,Tin,#dim)\n",
        "  # Sorties :\n",
        "  #     hidden_states   Vecteurs cachés   : (batch_size,nbr_couches,Tin,#RHN)\n",
        "  def call(self, input):\n",
        "    # Convolutions spatiales des séries exogènes\n",
        "    w = self.encodeur_cnn(input)      #  (batch_size,Tin,dim_motif)\n",
        "\n",
        "    # Encodage des motifs CNN avec les cellules RHN\n",
        "    sequence = []\n",
        "    hidden = None\n",
        "\n",
        "    # Initialisation des masques de dropout pour tous les pas de temps\n",
        "    self.RHN.InitMasquesDropout(self.dropout)\n",
        "\n",
        "    # Applique la cellule RHN à chaque pas de temps\n",
        "    for i in range(input.shape[1]):\n",
        "      hidden = self.RHN(w[:,i:i+1,:],hidden)          # Envoie (batch_size,1,dim_motif)\n",
        "      sequence.append(hidden)                         # Sauve (batch_size,nbr_couches,#RHN)\n",
        "\n",
        "      # Le premier état caché du prochain instant\n",
        "      # est l'état caché de la dernière couche précédente\n",
        "      hidden = hidden[:,self.nbr_couches_RHN-1,:]       # (batch_size,#RHN)\n",
        "\n",
        "    # Traite le format des vecteurs cachés de l'encodeur\n",
        "    sequence = tf.convert_to_tensor(sequence)               # (Tin,batch_size,nbr_couches,#RHN)\n",
        "    hidden_states = tf.transpose(sequence,perm=[1,2,0,3])   # (batch_size,nbr_couches,Tin,#RHN)  \n",
        "\n",
        "    return hidden_states"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__CJ4O7yJne3"
      },
      "source": [
        "**2. Création du décodeur**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lt2yWQeaJwNn"
      },
      "source": [
        "Le décodeur prend en entrée et à chaque pas de temps :  \n",
        "- Le tenseur en sortie de l'encodeur RHN qui contient l'ensemble des vecteurs cachés des différentes couches : (batch_size,Nbr_couches,Tin,#RHN)\n",
        "- L'état caché de la dernière couche du décodeur RHN précédent : (batch_size,#RHN)\n",
        "- La valeur de la série cible à l'instant courant : (batch_size,1,1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtYLxAoIK8Xn"
      },
      "source": [
        "<img src='https://github.com/AlexandreBourrieau/FICHIERS/blob/main/Series_Temporelles/Multi/images/HRHN_VueEnsembleDecodeur2.png?raw=true'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjHiRZZbLief"
      },
      "source": [
        "**a. Création de la couche d'attention hiérarchique**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JX5hGeWNN8w"
      },
      "source": [
        "<img src='https://github.com/AlexandreBourrieau/FICHIERS/blob/main/Series_Temporelles/Multi/images/HRHN_AttentionHierarchique.png?raw=true'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9p7ylHmY6gS"
      },
      "source": [
        "On commence par créer la fonction permettant de calculer les scores. Cette fonction sera appelée avec la méthode TimeDistributed de Keras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvaGAb0uY1XL"
      },
      "source": [
        "class CalculScore(tf.keras.layers.Layer):\n",
        "  def __init__(self,dim_RHN_dec):\n",
        "    self.dim_RHN_dec = dim_RHN_dec\n",
        "    super().__init__()                # Appel du __init__() de la classe Layer\n",
        "  \n",
        "  def build(self,input_shape):\n",
        "    self.T = self.add_weight(shape=(input_shape[1],self.dim_RHN_dec),initializer=\"normal\",name=\"T\")   # (#RHN_enc, #RHN_dec)\n",
        "    self.U = self.add_weight(shape=(input_shape[1],input_shape[1]),initializer=\"normal\",name=\"U\")     # (#RHN_enc, #RHN_enc)\n",
        "    self.b = self.add_weight(shape=(input_shape[1],1),initializer=\"normal\",name=\"b\")                  # (#RHN_enc, 1)\n",
        "    self.v = self.add_weight(shape=(input_shape[1],1),initializer=\"normal\",name=\"v\")                  # (#RHN_enc, 1)\n",
        "    super().build(input_shape)        # Appel de la méthode build()\n",
        "\n",
        "  #     hid_state:  Etat initial RHN          : (batch_size,#RHN_dec)\n",
        "  def SetInitState(self,hid_state):\n",
        "    self.hid_state = hid_state\n",
        "\n",
        "  def compute_output_shape(self,input_shape):\n",
        "    return(input_shape[0],1)\n",
        "\n",
        "  # Entrées :\n",
        "  #     input:      1 sortie encodeur RHN     : (batch_size,#RHN_enc)\n",
        "  # Sorties :\n",
        "  #     score:      score                     : (batch_size,1,1)\n",
        "  def call(self, input):\n",
        "    score = tf.matmul(self.U,tf.expand_dims(input,-1))                      # (#RHN_enc,#RHN_enc)x(batch_size,#RHN_enc,1) = (batch_size,#RHN_enc,1)\n",
        "    score = score + tf.matmul(self.T,tf.expand_dims(self.hid_state,-1))     # (#RHN_enc,#RHN_dec)(batch_size,#RHN_dec,1) = (batch_size,#RHN_enc,1)\n",
        "    score = score + self.b                                                  # (batch_size,#RHN_enc,1)\n",
        "    score = K.tanh(score)\n",
        "    score = tf.matmul(tf.transpose(self.v),score)                           # (1,#RHN_enc)x(batch_size,#RHN_enc,1) = (batch_size,1,1)\n",
        "    return tf.squeeze(score,-1)                                             # (batch_size,1)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pF02ysdbxWU"
      },
      "source": [
        "On crée maintenant la couche d'attention hiérarchique :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kxnR9fSVXDC"
      },
      "source": [
        "class AttentionHierarchique(tf.keras.layers.Layer):\n",
        "  def __init__(self,dim_RHN_dec):\n",
        "    self.dim_RHN_dec = dim_RHN_dec\n",
        "    super().__init__()                # Appel du __init__() de la classe Layer\n",
        "  \n",
        "  def build(self,input_shape):\n",
        "    self.couche_score = CalculScore(dim_RHN_dec=self.dim_RHN_dec)\n",
        "    super().build(input_shape)        # Appel de la méthode build()\n",
        "    \n",
        "  # Entrées :\n",
        "  #     input:      Sorties d'une couche encodeur RHN       : (batch_size,Tin,#RHN_enc)\n",
        "  #     hid_state:  Etat initial RHN                        : (batch_size,#RHN_dec)\n",
        "  # Sorties :\n",
        "  #     vc:         SousVecteur contexte                    : (batch_size,1,RHN_enc)\n",
        "  def call(self, input, hid_state):\n",
        "    # Calcul des scores\n",
        "    self.couche_score.SetInitState(hid_state)\n",
        "    scores = tf.keras.layers.TimeDistributed(self.couche_score)(input)        # (batch_size,Tin,#RHN_enc) : Timestep = Tin\n",
        "                                                                              # (batch_size,#RHN_enc) envoyé Tin fois\n",
        "                                                                              # (batch_size,Tin,1) retourné\n",
        "    scores = tf.keras.activations.softmax(scores,axis=1)                      # (batch_size,Tin,1)\n",
        "\n",
        "    # Applique les scores aux sorties de la couche RHN\n",
        "    poids = tf.multiply(input,scores)             # (batch_size,Tin,#RHN_enc)_x_(batch_size,Tin,1) = (batch_size,Tin,#RHN_enc)\n",
        "\n",
        "    # Calcul le sous-vecteur contexte\n",
        "    vc = K.sum(poids,axis=1)                      # (batch_size,#RHN_enc)\n",
        "    return tf.expand_dims(vc,1)                   # (batch_size,1,#RHN_enc)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slCSUTmyifEY"
      },
      "source": [
        "**b. Création du décodeur**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_efbOikfRwt"
      },
      "source": [
        "Dans le décodeur, on parallélise autant de couches d'attention que nécessaire afin de créer un modèle d'attention multi-entrées."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCElCxBcnUHj"
      },
      "source": [
        "<img src='https://github.com/AlexandreBourrieau/FICHIERS/blob/main/Series_Temporelles/Multi/images/ParaDecodeur.png?raw=true'>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2nZG3Rrjv3O"
      },
      "source": [
        "class Decodeur(tf.keras.layers.Layer):\n",
        "  def __init__(self,dim_RHN_dec,nbr_couches_RHN,dropout=0.0):\n",
        "    self.dim_RHN_dec = dim_RHN_dec\n",
        "    self.nbr_couches_RHN = nbr_couches_RHN\n",
        "    self.dropout = dropout\n",
        "    super().__init__()                # Appel du __init__() de la classe Layer\n",
        "  \n",
        "  def build(self,input_shape):\n",
        "    attentions = []\n",
        "    inputs_attention = []\n",
        "\n",
        "    # Création des \"nbr_couches\" entrées des attentions\n",
        "    # Chaque entrée est une liste : [input,init_state] = [((batch_size,Tin,#RHN_enc)),((batch_size,#RHN_dec))]\n",
        "    for i in range(input_shape[1]):\n",
        "      inputs_attention.append([tf.keras.Input(shape=(input_shape[2],input_shape[3])),          # input = \"nbr_couches\"*(batch_size,Tin,#RHN_enc)\n",
        "                                 tf.keras.Input(shape=(self.dim_RHN_dec))])                    # init_state = \"nbr_couches\"*(batch_size,#RHN_dec)\n",
        "\n",
        "    # Création des \"nbr_couches\" couches d'attentions hierarchiques\n",
        "    for i in range(input_shape[1]):\n",
        "      att = AttentionHierarchique(dim_RHN_dec=self.dim_RHN_dec)(\n",
        "          inputs_attention[i][0],                 # inputs_attention[i][0] : (batch_size,Tin,#RHN_enc)\n",
        "          inputs_attention[i][1])                 # inputs_attention[i][1] : (batch_size,#RHN_dec)\n",
        "      attentions.append(att)\n",
        "\n",
        "    # Création de la sortie concaténée des \"nbr_couches\" couches d'attentions\n",
        "    out = tf.convert_to_tensor(attentions)                                # out : (nbr_couches,batch_size,1,#RHN_enc)\n",
        "    out = tf.transpose(out,perm=[1,0,2,3])                                # out : (batch_size,nbr_couches,1,#RHN_enc)\n",
        "\n",
        "    # Création du modèle global\n",
        "    self.att_model = tf.keras.Model(inputs=inputs_attention,outputs=out)\n",
        "\n",
        "    # Création des poids\n",
        "    self.Wtilda = tf.keras.layers.Dense(units=1,activation=None,use_bias=None)\n",
        "    self.Vtilda = tf.keras.layers.Dense(units=1,activation=None,use_bias=True)\n",
        "\n",
        "    # Création du décodeur RHN\n",
        "    self.dec_RHN = Cellule_RHN(dim_RHN=self.dim_RHN_dec,nbr_couches=self.nbr_couches_RHN,return_all_states=False,dim_input=1)\n",
        "   \n",
        "    super().build(input_shape)        # Appel de la méthode build()\n",
        "    \n",
        "  # Entrées :\n",
        "  #     input:      Sorties des couches de l'encodeur RHN   : (batch_size,nbr_couches,Tin,#RHN_enc)\n",
        "  #     hid_state:  Etat initial RHN                        : (batch_size,#RHN_dec)\n",
        "  #     Y:          Valeur de la série cible                : (batch_size,1)\n",
        "  #     only_att    Si =True ne calcul que le vecteur ctx   : True/False\n",
        "  # Sorties :\n",
        "  #     d:          Vecteur contexte                        : (batch_size,nbr_couches*RHN_enc)\n",
        "  #     s:          Vecteur caché décodeur RHN              : (batch_size,#RHN_dec)\n",
        "  def call(self, input, hid_state, Y,only_att):\n",
        "    # Initialisation de l'état caché à 0 si besoin\n",
        "    # Construit le tenseur nul au format (batch_size,#RHN)\n",
        "    if hid_state == None:\n",
        "      coef = tf.expand_dims(input[:,0,0,0],-1)                          # (batch_size,1)\n",
        "      coef = tf.expand_dims(coef,-1)                                    # (batch_size,1,1)\n",
        "      hid_state = tf.matmul(coef,tf.zeros(shape=(1,self.dim_RHN_dec)))  # (batch_size,1,1)X(1,#RHN_dec) = (batch_size,1,#RHN_dec)\n",
        "      hid_state = tf.squeeze(hid_state,axis=1)                          # (batch_size,#RHN_dec)\n",
        "\n",
        "    # Construction de l'entrée du modèle\n",
        "    # nbr_couches*[((batch_size,Tin,#RHN_enc)),((batch_size,#RHN_dec))]\n",
        "    input_model = []\n",
        "    for i in range(input.shape[1]):\n",
        "      input_model.append([input[:,i,:,:],hid_state])    # [((batch_size,Tin,#RHN_enc)),((batch_size,#RHN_dec))]\n",
        "    \n",
        "    # Calcul des sous-vecteurs contextes\n",
        "    # avec le modèle d'attention hiérarchique parallélisé\n",
        "    d = self.att_model(input_model)                     # d : (batch_size,nbr_couches,1,#RHN_enc)\n",
        "\n",
        "    # Concaténation des sous-vecteurs contextes\n",
        "    d = tf.squeeze(d,axis=2)                            # (batch_size,nbr_couches,#RHN_enc)\n",
        "    d = tf.keras.layers.Flatten()(d)                    # (batch_size,nbr_couches*RHN_enc)\n",
        "\n",
        "    if only_att == False :\n",
        "      # Calcul de y_tilda\n",
        "      ytilda = self.Wtilda(Y)                             # (batch_size,1)\n",
        "      ytilda = ytilda + self.Vtilda(d)                    # (batch_size,1)\n",
        "\n",
        "      # Initialisation des masques de dropout pour tous les pas de temps\n",
        "      self.dec_RHN.InitMasquesDropout(self.dropout)\n",
        "\n",
        "      # Décodage avec le réseau RHN\n",
        "      s = self.dec_RHN(tf.expand_dims(ytilda,-1),hid_state)                  # (batch_size,#RHN_dec)\n",
        "      return d,s\n",
        "    else:\n",
        "      return d"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYOTdM7fZT65"
      },
      "source": [
        "**3. Création de la couche HRHN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhML2b5bFsZB"
      },
      "source": [
        "<img src='https://github.com/AlexandreBourrieau/FICHIERS/blob/main/Series_Temporelles/Multi/images/Gene_HRHN.png?raw=true'>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PCEHUDEZ1bt"
      },
      "source": [
        "class Net_HRHN(tf.keras.layers.Layer):\n",
        "  def __init__(self,encodeur,decodeur,longueur_sequence, regul=0.0, drop = 0.0):\n",
        "    self.encodeur = encodeur\n",
        "    self.decodeur = decodeur\n",
        "    self.longueur_sequence = longueur_sequence\n",
        "    self.regul = regul\n",
        "    self.drop = drop\n",
        "    super().__init__()                # Appel du __init__() de la classe Layer\n",
        "  \n",
        "  def build(self,input_shape):\n",
        "    self.W = tf.keras.layers.Dense(units=1,activation=None,use_bias=None)\n",
        "    self.V = tf.keras.layers.Dense(units=1,activation=None,use_bias=True)\n",
        "    super().build(input_shape)        # Appel de la méthode build()\n",
        "\n",
        "  # Entrées :\n",
        "  #     input:          Entrées X           : (batch_size,Tin,#dim)\n",
        "  #     output_seq:     Sortie séquence Y   : (batch_size,Tin,1)\n",
        "  # Sorties :\n",
        "  #     sortie:         Prédiction Y        : (batch_size,1,1)\n",
        "  def call(self,input,output_seq):\n",
        "    # Appel de l'encodeur\n",
        "    # Récupère l'ensemble des états cachés de l'encodeur RHN\n",
        "    H = self.encodeur(input)                # (batch_size,nbr_couches,Tin,#RHN_enc)\n",
        "\n",
        "    # Décodage\n",
        "    hidden_state = None\n",
        "    for t in range(input.shape[1]):\n",
        "      vc, hidden_state = self.decodeur(H,hidden_state,output_seq[:,t:t+1,0],only_att = False)\n",
        "    \n",
        "    # Couche d'attention finale\n",
        "    vc = self.decodeur(H,hidden_state,output_seq[:,0,0],only_att=True)    # (batch_size,#RHN_dec)\n",
        "\n",
        "    # Génération de la prédiction\n",
        "    sortie = self.W(hidden_state) + self.V(vc)        # (batch_size,1)\n",
        "    return tf.expand_dims(sortie,-1)                  # (batch_size,1,1)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8_PgjEpdC8z"
      },
      "source": [
        "#Mise en place du générateur"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMgLi7JPdFTq"
      },
      "source": [
        "dim_RHN_enc = 16\n",
        "dim_RHN_dec = 128\n",
        "\n",
        "nbr_filtres_cnn = [2,128,16]\n",
        "dim_filtres_cnn = [3,2,4]\n",
        "dim_max_pooling = [4,3,1]\n",
        "nbr_couches_RHN_enc = 3\n",
        "nbr_couches_RHN_dec = 1\n",
        "\n",
        "dim_motif = Encodeur_CNN(dim_filtres_cnn=dim_filtres_cnn,nbr_filtres_cnn=nbr_filtres_cnn,dim_max_pooling=dim_max_pooling,dim_motif=0)(x_train[0][0:1,:,:]).shape[2]\n",
        "drop=0.000\n",
        "\n",
        "def get_generateur():\n",
        "  entrees_sequences = tf.keras.layers.Input(shape=(longueur_sequence,x_train[0].shape[2]))\n",
        "  sorties_sequence = tf.keras.layers.Input(shape=(longueur_sequence,1))\n",
        "\n",
        "  dim_motif = Encodeur_CNN(dim_filtres_cnn=dim_filtres_cnn,nbr_filtres_cnn=nbr_filtres_cnn,dim_max_pooling=dim_max_pooling,dim_motif=0)(x_train[0][0:1,:,:]).shape[2]\n",
        "\n",
        "  encodeur = Encodeur(dim_filtres_cnn=dim_filtres_cnn,nbr_filtres_cnn=nbr_filtres_cnn,dim_max_pooling=dim_max_pooling,dim_motif=dim_motif,dim_RHN_enc=dim_RHN_enc,nbr_couches_RHN=nbr_couches_RHN_enc,dropout=drop)\n",
        "  decodeur = Decodeur(dim_RHN_dec=dim_RHN_dec,nbr_couches_RHN=nbr_couches_RHN_dec,dropout=drop)\n",
        "\n",
        "  sortie = Net_HRHN(encodeur,decodeur,longueur_sequence=longueur_sequence,drop=drop)(entrees_sequences,sorties_sequence)\n",
        "\n",
        "  model = tf.keras.Model([entrees_sequences,sorties_sequence],sortie)\n",
        "  return model"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKurk3ORkHYx"
      },
      "source": [
        "# Création du discriminateur - ANN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80Gq0X8UlJtX"
      },
      "source": [
        "Entrées : \n",
        "- Séries exogènes : (X1,X2,X3,...,XN), avec Xi=(Xi1,Xi2,...,XiT): (batch_size,T,#N)\n",
        "- Cible : y = (y1,y2,...,yT) : (batch_size,T,1)\n",
        "- Prédiction de la cible : y(T+1) : (batch_size,1,1)\n",
        "  \n",
        "Sortie : Probabilité que la séquence complète soit une vraie séquence. La séquence complète est l'applatissement de la concaténation des séries exogènes avec la cible et la valeur à prédire.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "of04zCU1kLW1"
      },
      "source": [
        "drop = 0.0\n",
        "alpha = 0.0\n",
        "units = 16\n",
        "\n",
        "def get_discriminateur1():\n",
        "  series_exogenes = tf.keras.layers.Input(shape=(longueur_sequence,x_train[0].shape[2]))                      # (BS,T,#N)\n",
        "  cible = tf.keras.layers.Input(shape=(longueur_sequence,1))                                                  # (BS,T,1)\n",
        "  pred_cible = tf.keras.layers.Input(shape=(1,1))                                                             # (BS,1,1)\n",
        "\n",
        "  concat_series_cible = tf.keras.layers.concatenate([series_exogenes,cible],axis=2)                           # (BS,T,#N+1)\n",
        "  entrees_flat = tf.keras.layers.Flatten()(concat_series_cible)                                               # (BS,T*(N+1))\n",
        "\n",
        "  entree_sequence = tf.keras.layers.concatenate([entrees_flat,tf.squeeze(pred_cible,-1)],axis=1)              # (BS,T*(#N+1)+1)\n",
        "\n",
        "\n",
        "  sorties = tf.keras.layers.Dense(units=units)(entree_sequence)                                               # (BS,#units)\n",
        "  sorties = tf.keras.layers.LeakyReLU(alpha)(sorties)\n",
        "  sorties = tf.keras.layers.Dropout(drop)(sorties)\n",
        "  sorties = tf.keras.layers.Dense(units=units)(sorties)                                                       # (BS,#units)\n",
        "  sorties = tf.keras.layers.LeakyReLU(alpha)(sorties)\n",
        "  sorties = tf.keras.layers.Dropout(drop)(sorties)\n",
        "  sorties = tf.keras.layers.Dense(units=1,activation=\"sigmoid\")(sorties)                                      # (BS,1)\n",
        "  \n",
        "  model = tf.keras.Model([series_exogenes,cible,pred_cible],sorties)\n",
        "  return model"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "co25tNp4pH4d"
      },
      "source": [
        "drop = 0.0\n",
        "alpha = 0.0\n",
        "units = 16\n",
        "\n",
        "def get_discriminateur():\n",
        "  series_exogenes = tf.keras.layers.Input(shape=(longueur_sequence,x_train[0].shape[2]))                      # (BS,T,#N)\n",
        "  cible = tf.keras.layers.Input(shape=(longueur_sequence,1))                                                  # (BS,T,1)\n",
        "  pred_cible = tf.keras.layers.Input(shape=(1,1))                                                             # (BS,1,1)\n",
        "\n",
        "  entree_sequence = tf.keras.layers.concatenate([cible,pred_cible],axis=1)                                    # (BS,T+1,1)\n",
        "\n",
        "  sorties = tf.keras.layers.Dense(units=units)(tf.squeeze(entree_sequence,-1))                                # (BS,#units)\n",
        "  sorties = tf.keras.layers.LeakyReLU(alpha)(sorties)\n",
        "  sorties = tf.keras.layers.Dropout(drop)(sorties)\n",
        "  sorties = tf.keras.layers.Dense(units=units)(sorties)                                                       # (BS,#units)\n",
        "  sorties = tf.keras.layers.LeakyReLU(alpha)(sorties)\n",
        "  sorties = tf.keras.layers.Dropout(drop)(sorties)\n",
        "  sorties = tf.keras.layers.Dense(units=1,activation=\"sigmoid\")(sorties)                                      # (BS,1)\n",
        "  \n",
        "  model = tf.keras.Model([series_exogenes,cible,pred_cible],sorties)\n",
        "  return model"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOrW0pYRq2CU"
      },
      "source": [
        "# Entrainement du GAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMtlKcHmq5G-"
      },
      "source": [
        "**1. Erreur : Maximisation du discriminateur**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7gqgJrsq4XR"
      },
      "source": [
        "# Dx      :     D(x)      Discrimination sur les vraies séquences           (batch_size,1)\n",
        "# DGz     :     D[G(z)]   Discrimination sur les séquences générées         (batch_size,1)\n",
        "# Erreur  :     log(Dx) + log(1-D[G(z)])\n",
        "\n",
        "def ErreurMaxDiscriminateur(Dx, DGz):\n",
        "  loss = tf.math.log(Dx)\n",
        "  loss = loss + tf.math.log(tf.math.subtract(tf.ones(shape=(Dx.shape[0],1),dtype=tf.float32),DGz))\n",
        "#  loss = tf.reduce_mean(loss)\n",
        "  return (tf.nn.compute_average_loss(loss))\n"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ev3MKeiJ5jLt"
      },
      "source": [
        "**2. Erreur : Maximisation du générateur**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWvjglvLsnt6"
      },
      "source": [
        "# Dx      :     D(x)      Discrimination sur les vraies séquences           (batch_size,1)\n",
        "# DGz     :     D[G(z)]   Discrimination sur les séquences générées         (batch_size,1)\n",
        "# Erreur  :     log(1-D[G(z)])\n",
        "\n",
        "def ErreurMaxGenerateur(Dx, DGz):\n",
        "  loss = tf.math.log(DGz)\n",
        "  loss = tf.reduce_mean(loss)\n",
        "  return (loss)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gPNpfgRuvCT"
      },
      "source": [
        "**3. Définition de la routine d'entrainement**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30FiTLng03a0"
      },
      "source": [
        "# x : [Séries exogènes, série cible]                  [(batch_size,Tin,#dim), (batch_size,Tin,1)]\n",
        "# y : Y+1                                             (batch_size,1,1)\n",
        "\n",
        "@tf.function\n",
        "def step(x, y,nbr_sequences):\n",
        "  # Optimisation du discriminateur par gradient ascendant\n",
        "  # de l'erreur log(Dx) + log(1-D[G(z)])\n",
        "  with tf.GradientTape() as t:\n",
        "    pred = generateur([x[0],x[1]])                    # (batch_size,1,1)\n",
        "    Dx = discriminateur([x[0],x[1],y])                # Discrimination vraie séquence\n",
        "    Dgz = discriminateur([x[0],x[1],pred])            # Discrimination fausse séquence\n",
        "    loss_D = -ErreurMaxDiscriminateur(Dx, Dgz)\n",
        "  \n",
        "  print(-loss_D)\n",
        "  grads = t.gradient(loss_D, discriminateur.trainable_variables)\n",
        "  tf.distribute.Strategy.run(optimizer_discri.apply_gradients(zip(grads, discriminateur.trainable_variables)))\n",
        "\n",
        "  # Optimisation du générateur par gradient ascendant\n",
        "  # de l'erreur log(D[G(z)])\n",
        "  with tf.GradientTape() as t:\n",
        "    pred = generateur([x[0],x[1]])                    # (batch_size,1,1)\n",
        "    Dx = discriminateur([x[0],x[1],y])                # Discrimination vraie séquence\n",
        "    Dgz = discriminateur([x[0],x[1],pred])            # Discrimination fausse séquence\n",
        "    loss_G = -ErreurMaxGenerateur(Dx, Dgz)\n",
        "\n",
        "  print(-loss_G)\n",
        "  grads = t.gradient(loss_G, generateur.trainable_variables)\n",
        "  optimizer_gene.apply_gradients(zip(grads, generateur.trainable_variables))\n",
        "\n",
        "  time = np.linspace(0,x[1].shape[0]*(1+x[1].shape[1])-1,x[1].shape[0]*(1+x[1].shape[1]))\n",
        "\n",
        "  vraies_sequences = []\n",
        "  for i in range(nbr_sequences):\n",
        "    serie = x[1][i,:,-1]\n",
        "    serie = tf.concat([serie,[y[i,0,0]]],axis=0)\n",
        "    vraies_sequences.append(serie)\n",
        "  vraies_sequences = tf.convert_to_tensor(vraies_sequences)\n",
        "  vraies_sequences = tf.reshape(vraies_sequences,shape=(nbr_sequences*vraies_sequences.shape[1]))\n",
        "  \n",
        "  fausses_sequences = []\n",
        "  for i in range(nbr_sequences):\n",
        "    serie = x[1][i,:,-1]\n",
        "    serie = tf.concat([serie,[pred[i,0,0]]],axis=0)\n",
        "    fausses_sequences.append(serie)\n",
        "  fausses_sequences = tf.convert_to_tensor(fausses_sequences)\n",
        "  fausses_sequences = tf.reshape(fausses_sequences,shape=(nbr_sequences*fausses_sequences.shape[1]))\n",
        "\n",
        "  return (time,vraies_sequences,fausses_sequences)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3flld1vybX13"
      },
      "source": [
        "generateur.compile(optimizer=\"adam\",loss=\"mse\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9tbqPB78slX"
      },
      "source": [
        "def train_step(inputs):\n",
        "  x, y = inputs\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    pred = generateur([x[0],x[1]])                    # (batch_size,1,1)\n",
        "    Dx = discriminateur([x[0],x[1],y])                # Discrimination vraie séquence\n",
        "    Dgz = discriminateur([x[0],x[1],pred])            # Discrimination fausse séquence\n",
        "    loss_D = -ErreurMaxDiscriminateur(Dx, Dgz)\n",
        "    \n",
        "  grads = tape.gradient(loss_D, discriminateur.trainable_variables)\n",
        "  tf.distribute.Strategy.run(optimizer.apply_gradients(zip(grads, discriminateur.trainable_variables)))\n",
        "  return loss_D\n",
        "\n",
        "@tf.function\n",
        "def step_TPU(dist_inputs):\n",
        "  per_replica_losses = strategy.run(train_step, args=(dist_inputs,))\n",
        "  return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses,axis=None)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "1KM7jd_Axb_P",
        "outputId": "52a55ac2-66b0-4e84-ed14-6d6446b2cf6a"
      },
      "source": [
        "nbr_sequences = 1\n",
        "j = 0\n",
        "\n",
        "dist_dataset = strategy.experimental_distribute_dataset(dataset)\n",
        "\n",
        "with strategy.scope():\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "  generateur = get_generateur()\n",
        "  discriminateur = get_discriminateur()\n",
        "  for i in range(0,1000):\n",
        "    j = j+1\n",
        "    for dist_inputs in dist_dataset:\n",
        "      print(step_TPU(dist_inputs))\n",
        "      if j == 10:\n",
        "        j = 0\n",
        "        generateur.evaluate(x=[x_train[0],x_train[1]],y=y_train)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-92016cc420e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdist_inputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdist_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_TPU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    762\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    763\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 764\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3048\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3049\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3050\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3051\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3444\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3287\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3288\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3289\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3290\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    984\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    <ipython-input-69-8b94517d2230>:16 step_TPU  *\n        per_replica_losses = strategy.run(train_step, args=(dist_inputs,))\n    <ipython-input-73-8b94517d2230>:11 train_step  *\n        tf.distribute.Strategy.run(optimizer.apply_gradients(zip(grads, discriminateur.trainable_variables)))\n\n    TypeError: run() missing 1 required positional argument: 'fn'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qbQG9bpYFJ-"
      },
      "source": [
        "nbr = 50\n",
        "t,v,f = step([x_train[0][:,:,:],x_train[1][:,:,:]],y_train[:,:,:],nbr)\n",
        "plt.plot(t[0:nbr],v[0:nbr])\n",
        "plt.plot(t[0:nbr],f[0:nbr])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZWHVAO0auHZ"
      },
      "source": [
        "# Entrainement avec TPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9igsaXY-h7gT"
      },
      "source": [
        "# Définition de la fonction de régulation du taux d'apprentissage\n",
        "def RegulationTauxApprentissage(periode, taux):\n",
        "  return 1e-8*10**(periode/10)\n",
        "\n",
        "strategy = tf.distribute.TPUStrategy(resolver)\n",
        "with strategy.scope():\n",
        "  # Création du modèle\n",
        "  model = get_model()\n",
        "  \n",
        "  # Définition de l'optimiseur à utiliser\n",
        "  optimiseur=tf.keras.optimizers.Adam(learning_rate=1e-8)\n",
        "\n",
        "  # Utilisation de la méthode ModelCheckPoint\n",
        "  CheckPoint = tf.keras.callbacks.ModelCheckpoint(\"poids.hdf5\", monitor='loss', verbose=1, save_best_only=True, save_weights_only = True, mode='auto', save_freq='epoch')\n",
        "\n",
        "  # Compile le modèle\n",
        "  model.compile(loss=\"mse\", optimizer=optimiseur)\n",
        "\n",
        "  # Entraine le modèle en utilisant notre fonction personnelle de régulation du taux d'apprentissage\n",
        "  historique = model.fit(x=[x_train[0],x_train[1]],y=y_train,epochs=100,verbose=1, callbacks=[tf.keras.callbacks.LearningRateScheduler(RegulationTauxApprentissage), CheckPoint])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCS1ho3Vh_YS"
      },
      "source": [
        "# Construit un vecteur avec les valeurs du taux d'apprentissage à chaque période \n",
        "taux = 1e-8*(10**(np.arange(100)/10))\n",
        "\n",
        "# Affiche l'erreur en fonction du taux d'apprentissage\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.semilogx(taux,historique.history[\"loss\"])\n",
        "plt.axis([ taux[30], taux[99], 0, 0.002])\n",
        "plt.title(\"Evolution de l'erreur en fonction du taux d'apprentissage\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkAWNR0jq-90"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "max_periodes = 10000\n",
        "\n",
        "strategy = tf.distribute.TPUStrategy(resolver)\n",
        "with strategy.scope():\n",
        "  # Création du modèle\n",
        "  model = get_model()\n",
        "\n",
        "  # Définition des paramètres liés à l'évolution du taux d'apprentissage\n",
        "  lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
        "      initial_learning_rate=0.001,\n",
        "      decay_steps=50,\n",
        "      decay_rate=0.00)\n",
        "\n",
        "  optimiseur=tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "#  optimiseur=tf.keras.optimizers.SGD(learning_rate=lr_schedule,momentum=0.9)\n",
        "\n",
        "  # Utilisation de la méthode ModelCheckPoint\n",
        "  CheckPoint = tf.keras.callbacks.ModelCheckpoint(\"poids_train.hdf5\", monitor='loss', verbose=1, save_best_only=True, save_weights_only = True, mode='auto', save_freq='epoch')\n",
        "\n",
        "  # Compile le modèle\n",
        "  model.compile(loss=\"mse\", optimizer=optimiseur, metrics=\"mse\")\n",
        "\n",
        "  # Entraine le modèle\n",
        "  historique = model.fit(x=[x_train[0],x_train[1]],y=y_train,validation_data=([x_val[0],x_val[1]],y_val), epochs=max_periodes,verbose=1, callbacks=[CheckPoint,tf.keras.callbacks.EarlyStopping(monitor='loss', patience=1000)],batch_size=batch_size)\n",
        "\n",
        "files.download('poids_train.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJfv3rZfryIO"
      },
      "source": [
        "model.load_weights(\"poids_train.hdf5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkK74TexF-Ou"
      },
      "source": [
        "erreur_entrainement = historique.history[\"loss\"]\n",
        "erreur_validation = historique.history[\"val_loss\"]\n",
        "\n",
        "# Affiche l'erreur en fonction de la période\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(np.arange(0,len(erreur_entrainement)),erreur_entrainement, label=\"Erreurs sur les entrainements\")\n",
        "plt.plot(np.arange(0,len(erreur_entrainement)),erreur_validation, label =\"Erreurs sur les validations\")\n",
        "plt.legend()\n",
        "\n",
        "plt.title(\"Evolution de l'erreur en fonction de la période\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvQ6UIyG5_Zy"
      },
      "source": [
        "erreur_entrainement = historique.history[\"loss\"]\n",
        "erreur_validation = historique.history[\"val_loss\"]\n",
        "\n",
        "# Affiche l'erreur en fonction de la période\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(np.arange(0,len(erreur_entrainement[100:2000])),erreur_entrainement[100:2000], label=\"Erreurs sur les entrainements\")\n",
        "plt.plot(np.arange(0,len(erreur_entrainement[100:2000])),erreur_validation[100:2000], label =\"Erreurs sur les validations\")\n",
        "plt.legend()\n",
        "\n",
        "plt.title(\"Evolution de l'erreur en fonction de la période\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxfFTzSYfyIf"
      },
      "source": [
        "model.evaluate(x=[x_train[0],x_train[1]],y=y_train)\n",
        "model.evaluate(x=[x_val[0],x_val[1]],y=y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfIkATObr8cV"
      },
      "source": [
        "# Prédictions single-step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfA2H5J4S35o"
      },
      "source": [
        "pred_ent = model.predict([x_train[0],x_train[1]],verbose=1)\n",
        "pred_val = model.predict([x_val[0],x_val[1]],verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Q1NA36BFZ4N"
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "decalage = 1\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "# Courbes originales\n",
        "fig.add_trace(go.Scatter(x=df_etude.index,y=serie_entrainement_X_norm[:,-1],line=dict(color='blue', width=1)))\n",
        "fig.add_trace(go.Scatter(x=df_etude.index[temps_separation:],y=serie_test_X_norm[:,-1],line=dict(color='red', width=1)))\n",
        "\n",
        "#Affiche les prédictions sur l'entrainement\n",
        "pred = []\n",
        "\n",
        "max = len(pred_ent)\n",
        "max = max\n",
        "for i in range(0,max):\n",
        "  pred.append(tf.squeeze(pred_ent[i,0:decalage,:],1))\n",
        "pred = tf.convert_to_tensor(pred).numpy()\n",
        "pred = np.reshape(pred,(pred.shape[0]*pred.shape[1]))\n",
        "\n",
        "fig.add_trace(go.Scatter(x=df_etude.index[longueur_sequence:],y=pred, mode='lines', line=dict(color='green', width=1)))\n",
        "\n",
        "#Affiche les prédictions sur les validations\n",
        "pred = []\n",
        "max = len(pred_val)\n",
        "max = max\n",
        "for i in range(0,max):\n",
        "  pred.append(tf.squeeze(pred_val[i,0:decalage,:],1))\n",
        "\n",
        "pred = tf.convert_to_tensor(pred).numpy()\n",
        "pred = np.reshape(pred,(pred.shape[0]*pred.shape[1]))\n",
        "\n",
        "fig.add_trace(go.Scatter(x=df_etude.index[temps_separation+longueur_sequence:],y=pred, mode='lines', line=dict(color='green', width=1)))\n",
        "\n",
        "fig.update_xaxes(rangeslider_visible=True)\n",
        "yaxis=dict(autorange = True,fixedrange= False)\n",
        "fig.update_yaxes(yaxis)\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9wCeoEnMEYv"
      },
      "source": [
        "**Erreurs en single step**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2_ceD69Mju6"
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "decalage = 1\n",
        "pred = []\n",
        "\n",
        "max = len(pred_ent)\n",
        "max = max\n",
        "for i in range(0,max):\n",
        "  pred.append(tf.squeeze(pred_ent[i,0:decalage,:],1))\n",
        "pred = tf.convert_to_tensor(pred).numpy()\n",
        "pred = np.reshape(pred,(pred.shape[0]*pred.shape[1]))\n",
        "\n",
        "fig.add_trace(go.Scatter(x=df_etude.index[longueur_sequence:],y=serie_entrainement_X_norm[longueur_sequence:-(serie_entrainement_X_norm[longueur_sequence:,:].shape[0]-pred.shape[0]),-1],line=dict(color='blue', width=1)))\n",
        "fig.add_trace(go.Scatter(x=df_etude.index[longueur_sequence:],y=pred,line=dict(color='green', width=1)))\n",
        "\n",
        "\n",
        "fig.update_xaxes(rangeslider_visible=True)\n",
        "yaxis=dict(autorange = True,fixedrange= False)\n",
        "fig.update_yaxes(yaxis)\n",
        "fig.show()\n",
        "\n",
        "mse_ent = tf.keras.losses.mse(serie_entrainement_X_norm[longueur_sequence:-(serie_entrainement_X_norm[longueur_sequence:,:].shape[0]-pred.shape[0]),-1],pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WV5JTpnnNApH"
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "decalage = 1\n",
        "pred = []\n",
        "\n",
        "max = len(pred_val)\n",
        "max = max\n",
        "for i in range(0,max):\n",
        "  pred.append(tf.squeeze(pred_val[i,0:decalage,:],1))\n",
        "pred = tf.convert_to_tensor(pred).numpy()\n",
        "pred = np.reshape(pred,(pred.shape[0]*pred.shape[1]))\n",
        "\n",
        "fig.add_trace(go.Scatter(x=df_etude.index[temps_separation+longueur_sequence::],y=serie_test_X_norm[longueur_sequence:-(serie_test_X_norm[longueur_sequence:,:].shape[0]-pred.shape[0]),-1],line=dict(color='blue', width=1)))\n",
        "fig.add_trace(go.Scatter(x=df_etude.index[temps_separation+longueur_sequence::],y=pred,line=dict(color='green', width=1)))\n",
        "\n",
        "\n",
        "fig.update_xaxes(rangeslider_visible=True)\n",
        "yaxis=dict(autorange = True,fixedrange= False)\n",
        "fig.update_yaxes(yaxis)\n",
        "fig.show()\n",
        "\n",
        "mse_test = tf.keras.losses.mse(serie_test_X_norm[longueur_sequence:-(serie_test_X_norm[longueur_sequence:,:].shape[0]-pred.shape[0]),-1],pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FShIaJINHBX"
      },
      "source": [
        "print(mse_ent)\n",
        "print(mse_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgFFtQ_SDDmI"
      },
      "source": [
        "# Prédictions naïves"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fs9qKFYDJRx"
      },
      "source": [
        "Mettons en place un modèle qui effectue des prédictions naïves sur le NASDAQ :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clV7wF6UDmla"
      },
      "source": [
        "class Net_Naif(tf.keras.layers.Layer):\n",
        "  def __init__(self,longueur_sequence):\n",
        "    self.longueur_sequence = longueur_sequence\n",
        "    super().__init__()                # Appel du __init__() de la classe Layer\n",
        "  \n",
        "  def build(self,input_shape):\n",
        "    super().build(input_shape)        # Appel de la méthode build()\n",
        "\n",
        "  # Entrées :\n",
        "  #     input:    Sortie séquence Y   : (batch_size,1,1)\n",
        "  # Sorties :\n",
        "  #     sortie:   Prédiction Y        : (batch_size,1,1)\n",
        "  def call(self,input):\n",
        "    return tf.expand_dims(input[:,-1:,:],-1)                  # (batch_size,1,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69wJ62cFEKzp"
      },
      "source": [
        "def get_model():\n",
        "  sorties_sequence = tf.keras.layers.Input(shape=(longueur_sequence,1))\n",
        "  sortie = Net_Naif(longueur_sequence=longueur_sequence)(sorties_sequence)\n",
        "  model = tf.keras.Model(sorties_sequence,sortie)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rapisky5Ert4"
      },
      "source": [
        "model_naif = get_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7KgbADxEq75"
      },
      "source": [
        "pred_ent = model_naif.predict(x_train[1],verbose=1)\n",
        "pred_val = model_naif.predict(x_val[1],verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kT7jLNNCFV9J"
      },
      "source": [
        "model_naif.compile(loss=\"mse\")\n",
        "model_naif.evaluate(x=x_train[1],y=y_train)\n",
        "model_naif.evaluate(x=x_val[1],y=y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uipadQWdFBaK"
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "decalage = 1\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "# Courbes originales\n",
        "fig.add_trace(go.Scatter(x=df_etude.index,y=serie_entrainement_X_norm[:,-1],line=dict(color='blue', width=1)))\n",
        "fig.add_trace(go.Scatter(x=df_etude.index[temps_separation:],y=serie_test_X_norm[:,-1],line=dict(color='red', width=1)))\n",
        "\n",
        "#Affiche les prédictions sur l'entrainement\n",
        "pred = []\n",
        "\n",
        "max = len(pred_ent)\n",
        "max = max\n",
        "for i in range(0,max):\n",
        "  pred.append(tf.squeeze(pred_ent[i,0:decalage,:],1))\n",
        "pred = tf.convert_to_tensor(pred).numpy()\n",
        "pred = np.reshape(pred,(pred.shape[0]*pred.shape[1]))\n",
        "\n",
        "fig.add_trace(go.Scatter(x=df_etude.index[longueur_sequence:],y=pred, mode='lines', line=dict(color='green', width=1)))\n",
        "\n",
        "#Affiche les prédictions sur les validations\n",
        "pred = []\n",
        "max = len(pred_val)\n",
        "max = max\n",
        "for i in range(0,max):\n",
        "  pred.append(tf.squeeze(pred_val[i,0:decalage,:],1))\n",
        "\n",
        "pred = tf.convert_to_tensor(pred).numpy()\n",
        "pred = np.reshape(pred,(pred.shape[0]*pred.shape[1]))\n",
        "\n",
        "fig.add_trace(go.Scatter(x=df_etude.index[temps_separation+longueur_sequence:],y=pred, mode='lines', line=dict(color='green', width=1)))\n",
        "\n",
        "fig.update_xaxes(rangeslider_visible=True)\n",
        "yaxis=dict(autorange = True,fixedrange= False)\n",
        "fig.update_yaxes(yaxis)\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Nnj-8Sm31Ro"
      },
      "source": [
        "**Erreurs en single step**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QirDorgP31Rp"
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "decalage = 1\n",
        "pred = []\n",
        "\n",
        "max = len(pred_ent)\n",
        "max = max\n",
        "for i in range(0,max):\n",
        "  pred.append(tf.squeeze(pred_ent[i,0:decalage,:],1))\n",
        "pred = tf.convert_to_tensor(pred).numpy()\n",
        "pred = np.reshape(pred,(pred.shape[0]*pred.shape[1]))\n",
        "\n",
        "fig.add_trace(go.Scatter(x=df_etude.index[longueur_sequence:],y=serie_entrainement_X_norm[longueur_sequence:-(serie_entrainement_X_norm[longueur_sequence:,:].shape[0]-pred.shape[0]),-1],line=dict(color='blue', width=1)))\n",
        "fig.add_trace(go.Scatter(x=df_etude.index[longueur_sequence:],y=pred,line=dict(color='green', width=1)))\n",
        "\n",
        "\n",
        "fig.update_xaxes(rangeslider_visible=True)\n",
        "yaxis=dict(autorange = True,fixedrange= False)\n",
        "fig.update_yaxes(yaxis)\n",
        "fig.show()\n",
        "\n",
        "mse_ent = tf.keras.losses.mse(serie_entrainement_X_norm[longueur_sequence:-(serie_entrainement_X_norm[longueur_sequence:,:].shape[0]-pred.shape[0]),-1],pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bb5ivRqh31Rp"
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "decalage = 1\n",
        "pred = []\n",
        "\n",
        "max = len(pred_val)\n",
        "max = max\n",
        "for i in range(0,max):\n",
        "  pred.append(tf.squeeze(pred_val[i,0:decalage,:],1))\n",
        "pred = tf.convert_to_tensor(pred).numpy()\n",
        "pred = np.reshape(pred,(pred.shape[0]*pred.shape[1]))\n",
        "\n",
        "fig.add_trace(go.Scatter(x=df_etude.index[temps_separation+longueur_sequence::],y=serie_test_X_norm[longueur_sequence:-(serie_test_X_norm[longueur_sequence:,:].shape[0]-pred.shape[0]),-1],line=dict(color='blue', width=1)))\n",
        "fig.add_trace(go.Scatter(x=df_etude.index[temps_separation+longueur_sequence::],y=pred,line=dict(color='green', width=1)))\n",
        "\n",
        "\n",
        "fig.update_xaxes(rangeslider_visible=True)\n",
        "yaxis=dict(autorange = True,fixedrange= False)\n",
        "fig.update_yaxes(yaxis)\n",
        "fig.show()\n",
        "\n",
        "mse_test = tf.keras.losses.mse(serie_test_X_norm[longueur_sequence:-(serie_test_X_norm[longueur_sequence:,:].shape[0]-pred.shape[0]),-1],pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nA8NqFUP31Rp"
      },
      "source": [
        "print(mse_ent)\n",
        "print(mse_test)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}